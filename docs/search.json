[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series",
    "section": "",
    "text": "통계학, 머신러닝, 딥러닝 등 공부내용을 기록하는 블로그입니다.\nEmail : star77sa@gmail.com\nLink\n\nGithub : https://github.com/star77sa\nNotion : https://ksko.notion.site\nLinkedin : https://linkedin.com/in/star77sa\n\n이전 블로그\n\nfastpage : https://star77sa.github.io/TIL-Blog\nTistory: https://ksko0424.tistory.com/\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 11, 2024\n\n\n데이터 과학\n\n\n고경수 \n\n\n\n\nSep 14, 2023\n\n\n빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석\n\n\n고경수 \n\n\n\n\nAug 24, 2023\n\n\n[확률론] 1. Probability and counting\n\n\n고경수 \n\n\n\n\nJan 1, 2020\n\n\n2023.08.28 블로그 구축\n\n\n고경수 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nI will post my studies on machine learning, deep learning, and time series analysis on my blog."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Time Series",
    "section": "",
    "text": "import feedparser, datetime, numpy\n\n\nblog_url = \"https://star77sa.github.io/index.xml\"\nfeed = feedparser.parse(blog_url)\nfeed\n\n{'bozo': False,\n 'entries': [{'title': 'Post With Code',\n   'title_detail': {'type': 'text/plain',\n    'language': None,\n    'base': 'https://star77sa.github.io/index.xml',\n    'value': 'Post With Code'},\n   'authors': [{'name': 'Harlow Malloc'}],\n   'author': 'Harlow Malloc',\n   'author_detail': {'name': 'Harlow Malloc'},\n   'links': [{'rel': 'alternate',\n     'type': 'text/html',\n     'href': 'https://star77sa.github.io/posts/post-with-code/index.html'}],\n   'link': 'https://star77sa.github.io/posts/post-with-code/index.html',\n   'summary': '&lt;p&gt;This is a post with executable code.&lt;/p&gt;',\n   'summary_detail': {'type': 'text/html',\n    'language': None,\n    'base': 'https://star77sa.github.io/index.xml',\n    'value': '&lt;p&gt;This is a post with executable code.&lt;/p&gt;'},\n   'tags': [{'term': 'news', 'scheme': None, 'label': None},\n    {'term': 'code', 'scheme': None, 'label': None},\n    {'term': 'analysis', 'scheme': None, 'label': None}],\n   'id': 'https://star77sa.github.io/posts/post-with-code/index.html',\n   'guidislink': False,\n   'published': 'Sat, 26 Aug 2023 15:00:00 GMT',\n   'published_parsed': time.struct_time(tm_year=2023, tm_mon=8, tm_mday=26, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=5, tm_yday=238, tm_isdst=0),\n   'media_content': [{'url': 'https://star77sa.github.io/posts/post-with-code/image.jpg',\n     'medium': 'image',\n     'type': 'image/jpeg'}]},\n  {'title': 'Welcome To My Blog',\n   'title_detail': {'type': 'text/plain',\n    'language': None,\n    'base': 'https://star77sa.github.io/index.xml',\n    'value': 'Welcome To My Blog'},\n   'authors': [{'name': \"Tristan O'Malley\"}],\n   'author': \"Tristan O'Malley\",\n   'author_detail': {'name': \"Tristan O'Malley\"},\n   'links': [{'rel': 'alternate',\n     'type': 'text/html',\n     'href': 'https://star77sa.github.io/posts/welcome/index.html'}],\n   'link': 'https://star77sa.github.io/posts/welcome/index.html',\n   'summary': '&lt;p&gt;This is the first post in a Quarto blog. Welcome!&lt;/p&gt;\\n&lt;p&gt;&lt;img class=\"img-fluid\" src=\"https://star77sa.github.io/posts/welcome/thumbnail.jpg\" /&gt;&lt;/p&gt;\\n&lt;p&gt;Since this post doesn’t specify an explicit &lt;code&gt;image&lt;/code&gt;, the first image in the post will be used in the listing page of posts.&lt;/p&gt;',\n   'summary_detail': {'type': 'text/html',\n    'language': None,\n    'base': 'https://star77sa.github.io/index.xml',\n    'value': '&lt;p&gt;This is the first post in a Quarto blog. Welcome!&lt;/p&gt;\\n&lt;p&gt;&lt;img class=\"img-fluid\" src=\"https://star77sa.github.io/posts/welcome/thumbnail.jpg\" /&gt;&lt;/p&gt;\\n&lt;p&gt;Since this post doesn’t specify an explicit &lt;code&gt;image&lt;/code&gt;, the first image in the post will be used in the listing page of posts.&lt;/p&gt;'},\n   'tags': [{'term': 'news', 'scheme': None, 'label': None}],\n   'id': 'https://star77sa.github.io/posts/welcome/index.html',\n   'guidislink': False,\n   'published': 'Wed, 23 Aug 2023 15:00:00 GMT',\n   'published_parsed': time.struct_time(tm_year=2023, tm_mon=8, tm_mday=23, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=235, tm_isdst=0)}],\n 'feed': {'title': 'Time Series',\n  'title_detail': {'type': 'text/plain',\n   'language': None,\n   'base': 'https://star77sa.github.io/index.xml',\n   'value': 'Time Series'},\n  'links': [{'rel': 'alternate',\n    'type': 'text/html',\n    'href': 'https://star77sa.github.io/index.html'},\n   {'href': 'https://star77sa.github.io/index.xml',\n    'rel': 'self',\n    'type': 'application/rss+xml'}],\n  'link': 'https://star77sa.github.io/index.html',\n  'subtitle': '',\n  'subtitle_detail': {'type': 'text/html',\n   'language': None,\n   'base': 'https://star77sa.github.io/index.xml',\n   'value': ''},\n  'generator_detail': {'name': 'quarto-1.3.450'},\n  'generator': 'quarto-1.3.450',\n  'updated': 'Sat, 26 Aug 2023 15:00:00 GMT',\n  'updated_parsed': time.struct_time(tm_year=2023, tm_mon=8, tm_mday=26, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=5, tm_yday=238, tm_isdst=0)},\n 'headers': {'connection': 'close',\n  'content-length': '763',\n  'server': 'GitHub.com',\n  'content-type': 'application/xml',\n  'permissions-policy': 'interest-cohort=()',\n  'last-modified': 'Mon, 28 Aug 2023 05:42:39 GMT',\n  'access-control-allow-origin': '*',\n  'strict-transport-security': 'max-age=31556952',\n  'etag': 'W/\"64ec33cf-736\"',\n  'expires': 'Mon, 28 Aug 2023 06:01:10 GMT',\n  'cache-control': 'max-age=600',\n  'content-encoding': 'gzip',\n  'x-proxy-cache': 'MISS',\n  'x-github-request-id': '1080:454B:18DE9A:1A4734:64EC35CE',\n  'accept-ranges': 'bytes',\n  'date': 'Mon, 28 Aug 2023 05:51:40 GMT',\n  'via': '1.1 varnish',\n  'age': '29',\n  'x-served-by': 'cache-itm18840-ITM',\n  'x-cache': 'HIT',\n  'x-cache-hits': '1',\n  'x-timer': 'S1693201900.263213,VS0,VE1',\n  'vary': 'Accept-Encoding',\n  'x-fastly-request-id': 'a0ea486a3d3316153b27bc07df6354052423df49'},\n 'etag': 'W/\"64ec33cf-736\"',\n 'updated': 'Mon, 28 Aug 2023 05:42:39 GMT',\n 'updated_parsed': time.struct_time(tm_year=2023, tm_mon=8, tm_mday=28, tm_hour=5, tm_min=42, tm_sec=39, tm_wday=0, tm_yday=240, tm_isdst=0),\n 'href': 'https://star77sa.github.io/index.xml',\n 'status': 200,\n 'encoding': 'utf-8',\n 'version': 'rss20',\n 'namespaces': {'': 'http://www.w3.org/2005/Atom',\n  'media': 'http://search.yahoo.com/mrss/',\n  'content': 'http://purl.org/rss/1.0/modules/content/',\n  'dc': 'http://purl.org/dc/elements/1.1/'}}\n\n\n\nfeed['entries'][0]\n\n{'title': 'Post With Code',\n 'title_detail': {'type': 'text/plain',\n  'language': None,\n  'base': 'https://star77sa.github.io/index.xml',\n  'value': 'Post With Code'},\n 'authors': [{'name': 'Harlow Malloc'}],\n 'author': 'Harlow Malloc',\n 'author_detail': {'name': 'Harlow Malloc'},\n 'links': [{'rel': 'alternate',\n   'type': 'text/html',\n   'href': 'https://star77sa.github.io/posts/post-with-code/index.html'}],\n 'link': 'https://star77sa.github.io/posts/post-with-code/index.html',\n 'summary': '&lt;p&gt;This is a post with executable code.&lt;/p&gt;',\n 'summary_detail': {'type': 'text/html',\n  'language': None,\n  'base': 'https://star77sa.github.io/index.xml',\n  'value': '&lt;p&gt;This is a post with executable code.&lt;/p&gt;'},\n 'tags': [{'term': 'news', 'scheme': None, 'label': None},\n  {'term': 'code', 'scheme': None, 'label': None},\n  {'term': 'analysis', 'scheme': None, 'label': None}],\n 'id': 'https://star77sa.github.io/posts/post-with-code/index.html',\n 'guidislink': False,\n 'published': 'Sat, 26 Aug 2023 15:00:00 GMT',\n 'published_parsed': time.struct_time(tm_year=2023, tm_mon=8, tm_mday=26, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=5, tm_yday=238, tm_isdst=0),\n 'media_content': [{'url': 'https://star77sa.github.io/posts/post-with-code/image.jpg',\n   'medium': 'image',\n   'type': 'image/jpeg'}]}\n\n\n\nrandom = numpy.random.randint(0, 30)\n\nfor i in feed['entries'][:7]:\n    dt = datetime.datetime.strptime(i['published'], \"%a, %d %b %Y %H:%M:%S %z\").strftime(\"%b %d, %Y\")\n    markdown_text += f\"[{i['title']}]({i['link']}) - {dt}&lt;br&gt;\\n\"\n    print(i['link'], i['title'])\n    markdown_text += ' '*random\n\n\nrandom = numpy.random.randint(0, 30)\nmarkdown_text = \"\"\n\nfor i in feed['entries'][:7]:\n    dt = datetime.datetime.strptime(i['published'], \"%a, %d %b %Y %H:%M:%S %Z\").strftime(\"%b %d, %Y\")\n    markdown_text += f\"[{i['title']}]({i['link']}) - {dt}&lt;br&gt;\\n\"\n    print(i['link'], i['title'])\n    markdown_text += ' '*random\n\nmarkdown_text\n\nhttps://star77sa.github.io/posts/post-with-code/index.html Post With Code\nhttps://star77sa.github.io/posts/welcome/index.html Welcome To My Blog\n\n\n'[Post With Code](https://star77sa.github.io/posts/post-with-code/index.html) - Aug 26, 2023&lt;br&gt;\\n                             [Welcome To My Blog](https://star77sa.github.io/posts/welcome/index.html) - Aug 23, 2023&lt;br&gt;\\n                             '\n\n\n\ntistory_blog_url=\"https://ksko0424.tistory.com/\"\nfeed = feedparser.parse(tistory_blog_url+\"/rss\")\n\n\nimport feedparser, datetime, numpy\n\ntistory_blog_url=\"https://ksko0424.tistory.com/\"\nfeed = feedparser.parse(tistory_blog_url+\"/rss\")\n \nmarkdown_text = \"\"\"\n![header](https://capsule-render.vercel.app/api?type=waving&color=0000FF&height=250&section=header&text=Kyeongsoo%20Ko&fontColor=FFFFFF&fontSize=70&fontAlign=50)\n\n\n- Name : 고경수         \n- Email : star77sa@gmail.com \n- Education:\n  - GIST M.S. in AI Graduate School\n  - JBNU B.S. in Statistics & Computer Science Engineering (Double Major)\n  \n- Award:\n  - 2023 위밋 프로젝트 교육부 장관상\n  - 2022 데이터톤 경진대회 대상\n  - 2022 전북대학교 통계학과 빅데이터 분석 경진대회 1회 최우수상\n  - 2022 전북대학교 통계학과 빅데이터 분석 경진대회 2회 우수상\n  - 2021 데이터 크리에이터 캠프 최우수상\n  - 2021 성적우수 총장상\n\n- Scholarships\n  - 전북 차세대 과학인재 장학금\n  - 국가우수장학(이공계)\n  - 성적 우수 장학금 (2018-2, 2021-1)\n\n- Work Experience:\n  - JBNU CV Lab 인턴 (2023.02 ~ 2023.08)\n  - GIST AI Lab 인턴 (2022.01 ~ 2022.02)\n  \n&lt;!--\n[![solved.ac tier](http://mazassumnida.wtf/api/v2/generate_badge?boj=star77sa)](https://solved.ac/star77sa)\n--&gt;\n\n[![Notion Badge](https://img.shields.io/badge/Notion-000000?style=flat-square&title_bg=%235C5F64&logo=Notion&logo_color=%23F0F4F0&link=https://www.notion.so/ksko/Kyeongsoo-Ko-8383246d72ab463daba2b1f49f6486a1?pvs=4)](https://www.notion.so/ksko/Kyeongsoo-Ko-8383246d72ab463daba2b1f49f6486a1?pvs=4)\n[![Tech Blog Badge](http://img.shields.io/badge/-Tech%20blog-black?style=flat-square&logo=github&link=https://ksko0424.tistory.com/)](https://ksko0424.tistory.com/)\n[![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/%EA%B2%BD%EC%88%98-%EA%B3%A0-8b7781206/)](https://www.linkedin.com/in/%EA%B2%BD%EC%88%98-%EA%B3%A0-8b7781206/)\n[![Gmail Badge](https://img.shields.io/badge/Gmail-d14836?style=flat-square&logo=Gmail&logoColor=white&link=mailto:star77sa@gmail.com)](mailto:star77sa@gmail.com)\n\n\n- 🌱 I’m currently learning `Mathematical Statistics`, `Time Series Analysis`\n\n&lt;!--\n[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fstar77sa&count_bg=%234100EA&title_bg=%23555555&icon=github.svg&icon_color=%23E7E7E7&title=VIEW&edge_flat=false)](https://hits.seeyoufarm.com)\n--&gt;\n\n&lt;!--\n**star77sa/star77sa** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.\n\nHere are some ideas to get you started:\n\n- 🔭 I’m currently working on ...\n- 🌱 I’m currently learning ...\n- 👯 I’m looking to collaborate on ...\n- 🤔 I’m looking for help with ...\n- 💬 Ask me about ...\n- 📫 How to reach me: ...\n- 😄 Pronouns: ...\n- ⚡ Fun fact: ...\n--&gt;\n\n## Recent blog posts\n\"\"\" # list of blog posts will be appended here\n \nrandom = numpy.random.randint(0, 30)\n\nfor i in feed['entries'][:7]:\n    dt = datetime.datetime.strptime(i['published'], \"%a, %d %b %Y %H:%M:%S %z\").strftime(\"%b %d, %Y\")\n    markdown_text += f\"[{i['title']}]({i['link']}) - {dt}&lt;br&gt;\\n\"\n    print(i['link'], i['title'])\n    markdown_text += ' '*random\n\nf = open(\"README.md\",mode=\"w\", encoding=\"utf-8\")\nf.write(markdown_text)\nf.close()"
  },
  {
    "objectID": "posts/etc/블로그.html",
    "href": "posts/etc/블로그.html",
    "title": "블로그 구축",
    "section": "",
    "text": "블로그 제작 (Quarto)\n\nQuarto\n참고영상\n\n\n\nRSS 피드\n\nquarto feed\nfeed parser\n날짜 포맷\n\n\n\n블로그 검색엔진 등록\n\n검색엔진 등록\n\n\n\nJupyter Notebook\n\n노트북의 첫 번째 셀은 문서제목, 작성자 및 지정해야하는 기타 옵션이 포함된 RAW Cell이어야 한다. https://quarto.org/docs/tools/jupyter-lab.html\n\n\n\n\nimage-2.png"
  },
  {
    "objectID": "posts/etc/2023-08-28-블로그.html",
    "href": "posts/etc/2023-08-28-블로그.html",
    "title": "2023.08.28 블로그 구축",
    "section": "",
    "text": "왜 옮겼는지?\n깃허브를 이용한 블로그, 네이버 블로그 등 다양한 블로그를 사용해보다가 fastpage 블로그에 정착을 했었습니다.\n주피터노트북 파일을 만들면 그대로 포스팅을 해주어서 용이하였기 때문이었는데,\n해당 블로그의 서비스가 종료되고 Quarto 사용을 권장한다고 하였으나 블로그 개설이 복잡한 것 같아 티스토리를 한동안 사용해보았습니다. 다만 역시 코드 기록이 불편하여 Quarto 블로그를 제작하여 이 블로그로 옮기게 되었습니다.\n다른 블로그들의 포스팅은 복습하는 겸 조금씩 옮길 예정입니다.\n\n\n블로그 제작 (Quarto)\n\nQuarto\n참고영상\n\n\n\n설정가능 icon\n\n\n\nRSS 피드\n\nquarto feed\nfeed parser\n날짜 포맷\n\n\n\n블로그 검색엔진 등록\n\n검색엔진 등록\n\n\n\nJupyter Notebook\n\n노트북의 첫 번째 셀은 문서제목, 작성자 및 지정해야하는 기타 옵션이 포함된 RAW Cell이어야 한다. https://quarto.org/docs/tools/jupyter-lab.html",
    "crumbs": [
      "About",
      "Posts",
      "Etc",
      "2023.08.28 블로그 구축"
    ]
  },
  {
    "objectID": "posts/확률론/2023-08-28-블로그.html",
    "href": "posts/확률론/2023-08-28-블로그.html",
    "title": "[확률론] 1. Probability and counting",
    "section": "",
    "text": "Introduction to Probability Second Edition"
  },
  {
    "objectID": "posts/확률론/2023-08-28-블로그.html#why-study-probability",
    "href": "posts/확률론/2023-08-28-블로그.html#why-study-probability",
    "title": "[확률론] 1. Probability and counting",
    "section": "1.1 Why study probability?",
    "text": "1.1 Why study probability?\n수학은 확실성의 논리이며 확률은 불확실성의 논리이다.\nlist of applications: - statistics : 확률은 통계를 위한 기초이자 언어이다. 데이터를 사용하여 세상에 대해 배울 수 있는 다양한 강력한 방법을 가능하게 한다.\n\ncomputer science: Randomized algorithms은 실행되는 동안 무작위 선택을 하며, 많은 중요한 응용 분야에서 현재 알려진 결정론적 대안(deterministic alternatives)보다 더 간단하고 효율적이다. 확률은 또한 알고리즘의 성능을 연구하는 데 필수적인 역할을 하며, 머신러닝, 인공지능에서 중요한 역할을 한다.\nLife: 인생은 불확실하고 확률은 불확실성의 논리이다. 인생에서 결정되는 모든 결정에 대해 공식적인 확률 계산을 수행하는 것은 실용적이지 않지만, 확률에 대해 열심히 생각하는 것은 우리가 몇 가지 흔한 오류를 피하고, 우연을 조명하고, 더 나은 예측을 하는 데 도움이 될 수 있다.\nPhysics, Biology, Meteorology, Gambling, Finance, Political science, Medicine…."
  },
  {
    "objectID": "posts/확률론/1_probability_and_counting.html",
    "href": "posts/확률론/1_probability_and_counting.html",
    "title": "[확률론] 1. Probability and counting",
    "section": "",
    "text": "Introduction to Probability Second Edition",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "[확률론] 1. Probability and counting"
    ]
  },
  {
    "objectID": "posts/확률론/1_probability_and_counting.html#why-study-probability",
    "href": "posts/확률론/1_probability_and_counting.html#why-study-probability",
    "title": "[확률론] 1. Probability and counting",
    "section": "1.1 Why study probability?",
    "text": "1.1 Why study probability?\n수학은 확실성의 논리이며 확률은 불확실성의 논리이다.\nlist of applications:\n\nstatistics : 확률은 통계를 위한 기초이자 언어이다. 데이터를 사용하여 세상에 대해 배울 수 있는 다양한 강력한 방법을 가능하게 한다.\ncomputer science: Randomized algorithms은 실행되는 동안 무작위 선택을 하며, 많은 중요한 응용 분야에서 현재 알려진 결정론적 대안(deterministic alternatives)보다 더 간단하고 효율적이다. 확률은 또한 알고리즘의 성능을 연구하는 데 필수적인 역할을 하며, 머신러닝, 인공지능에서 중요한 역할을 한다.\nLife: 인생은 불확실하고 확률은 불확실성의 논리이다. 인생에서 결정되는 모든 결정에 대해 공식적인 확률 계산을 수행하는 것은 실용적이지 않지만, 확률에 대해 열심히 생각하는 것은 우리가 몇 가지 흔한 오류를 피하고, 우연을 조명하고, 더 나은 예측을 하는 데 도움이 될 수 있다.\nPhysics, Biology, Meteorology, Gambling, Finance, Political science, Medicine….",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "[확률론] 1. Probability and counting"
    ]
  },
  {
    "objectID": "posts/확률론/1_probability_and_counting.html#sample-spaces-and-pebble-world",
    "href": "posts/확률론/1_probability_and_counting.html#sample-spaces-and-pebble-world",
    "title": "[확률론] 1. Probability and counting",
    "section": "1.2 Sample spaces and Pebble World",
    "text": "1.2 Sample spaces and Pebble World\n\n\n\nFigure 1.1\n\n\n\nsample space S: 실험의 모든 가능한 경우의 집합\nevent A: sample space S의 부분 집합\n표본 공간은 finite, countably infinite, uncountably infinite 할 수 있다. 표본공간이 finite(유한)할 때, 우리는 Pebble World로 시각화 할 수 있으며 Figure 1.1과 같이 나타낼 수 있다. 각각의 pebble은 결과를 나타내며 event는 pebbles의 집합이다.\n만약 모든 pebble이 같은 질량을 가지면 pebble은 동일한 확률로 선택되어진다. 이러한 특별한 경우가 다음 두 Section에서 다뤄지며 Section 1.6에서는 질량이 다른 경우에 대해 다룬다.\n집합 이론은 확률에서 매우 유용하다(각 사건을 표현). 이러한 방식은 사건을 한 가지 이상의 방법으로 표현 가능하게 해준다. 어떠한 한 가지 표현은 다른 표현보다 더 쉽다.\n\n\n\n\nex) De Morgan’s laws",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "[확률론] 1. Probability and counting"
    ]
  },
  {
    "objectID": "posts/확률론/1_probability_and_counting.html#naive-definition-of-probability",
    "href": "posts/확률론/1_probability_and_counting.html#naive-definition-of-probability",
    "title": "[확률론] 1. Probability and counting",
    "section": "1.3 Naive definition of probability",
    "text": "1.3 Naive definition of probability\nNaive definition of probability\n\nA를 사건이라 하고 S를 유한한 표본공간이라 하자. 이때 The naive probability of A는\n\n\n예시로, Figure 1.1의 상황에서\n\n\n\n\nThe naive definition은 매우 제한적. S가 유한해야하며 각각의 pebble들의 질량이 동일해야 한다. 이것은 종종 잘못 적용되는데, justification 없이 그것이 50:50이라고 주장하는 것(예를 들어, 화성에 지적 생명체가 산다를 50:50이라고 함.)\nThe naive difinition이 적용 가능한 중요한 케이스들이 존재한다.\n\n문제에 symmetry(대칭)이 있는 경우 등확률이다. ex) 동전이 50% 확률로 앞면이 나올 수 있다. -&gt; 동전이 물리적으로 symmetry.\n설계에 의한 등확률. ex) N명의 인구 중 설문조사를 위해 n명의 사람을 랜덤하게 뽑는 경우. 성공한다면 나이브한 정의를 적용가능하지만, 다양한 문제로 인해 달성이 어려울 수 있다.\n영가설에서의 모형",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "[확률론] 1. Probability and counting"
    ]
  },
  {
    "objectID": "posts/확률론/1_probability_and_counting.html#how-to-count",
    "href": "posts/확률론/1_probability_and_counting.html#how-to-count",
    "title": "[확률론] 1. Probability and counting",
    "section": "1.4 How to count",
    "text": "1.4 How to count\nMultiplication rule\n\n2개의 하위 실험 A, B로 구성된 복합실험을 생각해보자. 실험 A는 a개 가능한 경우의 수가 있고 실험 B는 b개의 가능한 경우의 수가 있다. 이런 경우 복합 실험은 a*b의 가능한 경우를 갖는다.\n\n\n※ 실험이 시간순서로 진행된다고 생각하기 쉬우나 A가 B보다 먼저 실행된다는 요건은 없다. 주어진 내용이 없으면 순차적으로 실행된다고 생각하지 말 것?",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "[확률론] 1. Probability and counting"
    ]
  },
  {
    "objectID": "posts/확률론/통계 101 X 데이터 분석.html",
    "href": "posts/확률론/통계 101 X 데이터 분석.html",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "",
    "text": "Alt text"
  },
  {
    "objectID": "posts/확률론/통계 101 X 데이터 분석.html#데이터를-분석하다",
    "href": "posts/확률론/통계 101 X 데이터 분석.html#데이터를-분석하다",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "1.1 데이터를 분석하다",
    "text": "1.1 데이터를 분석하다\n\n데이터 분석의 목적\n\n\n데이터를 요약하는 것\n대상을 설명하는 것\n새로 얻을 데이터를 예측하는 것\n\n\n인과관계 : 2가지 중 하나(원인)을 변화시키면, 다른 하나(결과)도 바꿀 수 있는 관계. 인과관계를 알면 곧 원리(메커니즘)에 관한 지식을 얻는 것이기에 깊은 이해라고 할 수 있다.\n상관관계 : 한쪽이 크면 다른 한쪽도 큰(또는 한쪽이 크면 다른 한쪽은 작은) 관계를 말한다. 한쪽을 ’변화시켰다’하더라도 다른 한쪽이 ’변한다’고 단정할 수 없다는 점에서 인과관계와 다르다. 원리에 관련된 몇 가지 가능성을 구별할 수 없으므로, 얕은 이해라 할 수 있다.\n선형관계에는 사람이 다루기 쉽고, 해석하기도 쉽다는 특징. 한편, 해석이 어려운 복잡한 관계를 추출하고 예측하는 기계학습이란 방법도 있다.(12장)"
  },
  {
    "objectID": "posts/확률론/통계 101 X 데이터 분석.html#통계학의-역할",
    "href": "posts/확률론/통계 101 X 데이터 분석.html#통계학의-역할",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "1.2 통계학의 역할",
    "text": "1.2 통계학의 역할\n\n통계학은 데이터 퍼짐 정도가 클수록 힘을 발휘한다.\n데이터 분석에서 통계학의 중요한 역할은, 퍼짐(산포, dispersion) 이 있는 데이터에 대해 설명이나 예측을 하는 것.\n통계학은 이러한 데이터 퍼짐을 ’불확실성’이라 평가하고, 통계학의 목적인 ’대상의 설명과 예측’을 수행\n통계학은 데이터 퍼짐이나 불확실성에 대처하는 방법을 제공. 그 근거가 되는 것이 데이터 퍼짐이나 불확실성을 확률로 나타내는 확률론이다."
  },
  {
    "objectID": "posts/확률론/통계 101 X 데이터 분석.html#통계학의-전체-모습",
    "href": "posts/확률론/통계 101 X 데이터 분석.html#통계학의-전체-모습",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "1.3 통계학의 전체 모습",
    "text": "1.3 통계학의 전체 모습\n- 기술통계와 추론통계\n\n기술통계(descriptive statistics) : 수집한 데이터를 정리하고 요약하는 방법. 확보한 데이터에만 집중하면서, 데이터 자체의 성질을 이해하는 것을 목표로 한다는 점에 주의.\n추론통계(inferential statistics) : 수집한 데이터로부터 데이터의 발생원을 추정하는 방법\n\n- 통계적 추론과 가설검정\n추론통계는 크게 2가지가 있다.\n\n통계적 추론(statistical inference) : 데이터에서 가정한 확률 모형의 성질을 추정하는 방법. 예를 들어, 모서리가 닳아버린 주사위라면 각 눈이 나올 확률이 1/6이 아닐지도 모른다. 이럴 때 통계적 추론을 이용하여, 얻은 데이터로부터 각 눈이 어떤 확률로 나오는 주사위인가를 추정할 수 있다.\n가설검정(statistical test) : 세운 가설과 얻은 데이터가 얼마나 들어맞는지를 평가하여, 가설을 채택할 것인가를 판단하는 방법"
  },
  {
    "objectID": "posts/확률론/통계 101 X 데이터 분석.html#데이터-분석의-목적과-알고자-하는-대상",
    "href": "posts/확률론/통계 101 X 데이터 분석.html#데이터-분석의-목적과-알고자-하는-대상",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "2.1 데이터 분석의 목적과 알고자 하는 대상",
    "text": "2.1 데이터 분석의 목적과 알고자 하는 대상\n\n데이터 분석의 목적을 정하기.\n알고자 하는 대상을 명확히 하기."
  },
  {
    "objectID": "posts/확률론/통계 101 X 데이터 분석.html#모집단",
    "href": "posts/확률론/통계 101 X 데이터 분석.html#모집단",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "2.2 모집단",
    "text": "2.2 모집단\n\n모집단 : 알고자 하는 대상 전체\n\n‘지금 알고자 하는 대상은 무엇인지’, ’무엇을 모집단으로 설정할 것인지’의 문제에는 항상 주의를 기울여야 한다.\n\n유한모집단\n무한모집단"
  },
  {
    "objectID": "posts/확률론/통계 101 X 데이터 분석.html#모집단의-성질을-알다",
    "href": "posts/확률론/통계 101 X 데이터 분석.html#모집단의-성질을-알다",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "2.3 모집단의 성질을 알다",
    "text": "2.3 모집단의 성질을 알다\n\n모집단은 데이터 분석에서 알고자 하는 대상 전체를 가리키기 때문에, 모집단의 성질을 알 수 있다면 대상을 설명하거나 이해할 수 있고, 미지의 데이터를 예측할 수도 있게 된다.\n모집단의 성질이란, 다음과 같이 모집단에 포함된 요소를 특징 짓는 값이다.\n\n\n한국인 남성의 평균 키는 172.5cm이다.\n한국인 여성의 평균 키는 159.6cm이다.\n신약을 복용한 사람의 최고 혈압 평균은 120mmHg이다.\n이 주사위는 모든 눈이 균등하게 나온다.\n이 주사위는 6의 눈이 1/4 확률로 나온다.\n\n\n그렇다면 이러한 모집단의 성질을 알기 위해서는 어떻게 해야 할까?\n\n- 전수조사 : 모집단에 포함된 모든 요소를 조사\n\n모집단에 포함된 요소의 개수가 한정된, 유한모집단일 때 선택할 수 있는 조사 방법.\n전수조사의 경우 ‘분석할 데이터 = 모집단’. 그러므로 획득한 데이터의 특징을 파악하고 기술하기만 해도, 모집단의 성질을 설명하고 이해할 수 있다.\n전수조사의 어려움 : 비용이나 시간 면에서 부담이 막대하여 실현 불가능할 때가 대부분.\n\n- 표본조사 : 모집단의 일부를 분석하여 모집단 전체의 성질을 추정하는 추론통계(inferentail statistics) 라는 분야가 있으며, 이것이야말로 통계학의 참모습이라 할 수 있다.\n\n표본(sample) : 추론통계에서 조사하는 모집단의 일부\n표본추출(sampling) : 모집단에서 표본을 뽑는 것\n표본조사 : 표본을 이용해 모집단의 성질을 조사하는 것\n\n표본을 통해 모집단의 성질을 알 수 있는 잘 알려진 방법으로, 선거 출구조사를 들 수 있다. 일부의 표만으로도 당선확실 여부를 알 수 있다.\n추론통계는 ’추론’이라는 말에서 알 수 있듯이 모집단의 성질을 100% 알아맞힐 수는 없으며, 어느 정도 불확실성을 염두에 두고 평가하게 된다.\n\n대상을 설명(이해)하고 예측하기 위해서는 모집단의 성질을 알아야 한다.\n일반적으로 모집단을 대상으로 한 전수조사는 어렵다.\n표본을 조사하면 모집단의 성질을 추정할 수 있다.\n표본크기 : 표본에 포함된 요소의 개수를 표본크기(sample size)라 부르며, 보통 알파벳 \\(n\\)으로 나타낸다. 예를 들어 표본으로 30개를 추출했다면, \\(n\\)=30이라 표기한다.\n통계학에서 샘플 수라고 하면 표본의 개수를 뜻한다. 예를 들어 20명으로 이루어진 표본A와 이와 별개로 30명으로 이루어진 표본B가 있는 경우, 표본은 A, B 2개이므로 샘플 수는 2가 된다. 이처럼 표본크기와 표본의 개수는 혼동하기 쉬우므로 주의.\n표본크기는 모집단의 성질을 추정할 때의 확실성이나 가설검정의 결과에도 영향을 끼치기 때문에, 통계분석에 있어 중요한 요소 중 하나."
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#데이터를-분석하다",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#데이터를-분석하다",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "1.1 데이터를 분석하다",
    "text": "1.1 데이터를 분석하다\n\n데이터 분석의 목적\n\n\n데이터를 요약하는 것\n대상을 설명하는 것\n새로 얻을 데이터를 예측하는 것\n\n\n인과관계 : 2가지 중 하나(원인)을 변화시키면, 다른 하나(결과)도 바꿀 수 있는 관계. 인과관계를 알면 곧 원리(메커니즘)에 관한 지식을 얻는 것이기에 깊은 이해라고 할 수 있다.\n상관관계 : 한쪽이 크면 다른 한쪽도 큰(또는 한쪽이 크면 다른 한쪽은 작은) 관계를 말한다. 한쪽을 ’변화시켰다’하더라도 다른 한쪽이 ’변한다’고 단정할 수 없다는 점에서 인과관계와 다르다. 원리에 관련된 몇 가지 가능성을 구별할 수 없으므로, 얕은 이해라 할 수 있다.\n선형관계에는 사람이 다루기 쉽고, 해석하기도 쉽다는 특징. 한편, 해석이 어려운 복잡한 관계를 추출하고 예측하는 기계학습이란 방법도 있다.(12장)",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#통계학의-역할",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#통계학의-역할",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "1.2 통계학의 역할",
    "text": "1.2 통계학의 역할\n\n통계학은 데이터 퍼짐 정도가 클수록 힘을 발휘한다.\n데이터 분석에서 통계학의 중요한 역할은, 퍼짐(산포, dispersion) 이 있는 데이터에 대해 설명이나 예측을 하는 것.\n통계학은 이러한 데이터 퍼짐을 ’불확실성’이라 평가하고, 통계학의 목적인 ’대상의 설명과 예측’을 수행\n통계학은 데이터 퍼짐이나 불확실성에 대처하는 방법을 제공. 그 근거가 되는 것이 데이터 퍼짐이나 불확실성을 확률로 나타내는 확률론이다.",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#통계학의-전체-모습",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#통계학의-전체-모습",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "1.3 통계학의 전체 모습",
    "text": "1.3 통계학의 전체 모습\n- 기술통계와 추론통계\n\n기술통계(descriptive statistics) : 수집한 데이터를 정리하고 요약하는 방법. 확보한 데이터에만 집중하면서, 데이터 자체의 성질을 이해하는 것을 목표로 한다는 점에 주의.\n추론통계(inferential statistics) : 수집한 데이터로부터 데이터의 발생원을 추정하는 방법\n\n- 통계적 추론과 가설검정\n추론통계는 크게 2가지가 있다.\n\n통계적 추론(statistical inference) : 데이터에서 가정한 확률 모형의 성질을 추정하는 방법. 예를 들어, 모서리가 닳아버린 주사위라면 각 눈이 나올 확률이 1/6이 아닐지도 모른다. 이럴 때 통계적 추론을 이용하여, 얻은 데이터로부터 각 눈이 어떤 확률로 나오는 주사위인가를 추정할 수 있다.\n가설검정(statistical test) : 세운 가설과 얻은 데이터가 얼마나 들어맞는지를 평가하여, 가설을 채택할 것인가를 판단하는 방법",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#데이터-분석의-목적과-알고자-하는-대상",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#데이터-분석의-목적과-알고자-하는-대상",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "2.1 데이터 분석의 목적과 알고자 하는 대상",
    "text": "2.1 데이터 분석의 목적과 알고자 하는 대상\n\n데이터 분석의 목적을 정하기.\n알고자 하는 대상을 명확히 하기.",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#모집단",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#모집단",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "2.2 모집단",
    "text": "2.2 모집단\n\n모집단 : 알고자 하는 대상 전체\n\n‘지금 알고자 하는 대상은 무엇인지’, ’무엇을 모집단으로 설정할 것인지’의 문제에는 항상 주의를 기울여야 한다.\n\n유한모집단\n무한모집단",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#모집단의-성질을-알다",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#모집단의-성질을-알다",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "2.3 모집단의 성질을 알다",
    "text": "2.3 모집단의 성질을 알다\n\n모집단은 데이터 분석에서 알고자 하는 대상 전체를 가리키기 때문에, 모집단의 성질을 알 수 있다면 대상을 설명하거나 이해할 수 있고, 미지의 데이터를 예측할 수도 있게 된다.\n모집단의 성질이란, 다음과 같이 모집단에 포함된 요소를 특징 짓는 값이다.\n\n\n한국인 남성의 평균 키는 172.5cm이다.\n한국인 여성의 평균 키는 159.6cm이다.\n신약을 복용한 사람의 최고 혈압 평균은 120mmHg이다.\n이 주사위는 모든 눈이 균등하게 나온다.\n이 주사위는 6의 눈이 1/4 확률로 나온다.\n\n\n그렇다면 이러한 모집단의 성질을 알기 위해서는 어떻게 해야 할까?\n\n- 전수조사 : 모집단에 포함된 모든 요소를 조사\n\n모집단에 포함된 요소의 개수가 한정된, 유한모집단일 때 선택할 수 있는 조사 방법.\n전수조사의 경우 ‘분석할 데이터 = 모집단’. 그러므로 획득한 데이터의 특징을 파악하고 기술하기만 해도, 모집단의 성질을 설명하고 이해할 수 있다.\n전수조사의 어려움 : 비용이나 시간 면에서 부담이 막대하여 실현 불가능할 때가 대부분.\n\n- 표본조사 : 모집단의 일부를 분석하여 모집단 전체의 성질을 추정하는 추론통계(inferential statistics) 라는 분야가 있으며, 이것이야말로 통계학의 참모습이라 할 수 있다.\n\n표본(sample) : 추론통계에서 조사하는 모집단의 일부\n표본추출(sampling) : 모집단에서 표본을 뽑는 것\n표본조사 : 표본을 이용해 모집단의 성질을 조사하는 것\n\n표본을 통해 모집단의 성질을 알 수 있는 잘 알려진 방법으로, 선거 출구조사를 들 수 있다. 일부의 표만으로도 당선확실 여부를 알 수 있다.\n추론통계는 ’추론’이라는 말에서 알 수 있듯이 모집단의 성질을 100% 알아맞힐 수는 없으며, 어느 정도 불확실성을 염두에 두고 평가하게 된다.\n\n대상을 설명(이해)하고 예측하기 위해서는 모집단의 성질을 알아야 한다.\n일반적으로 모집단을 대상으로 한 전수조사는 어렵다.\n표본을 조사하면 모집단의 성질을 추정할 수 있다.\n표본크기 : 표본에 포함된 요소의 개수를 표본크기(sample size)라 부르며, 보통 알파벳 \\(n\\)으로 나타낸다. 예를 들어 표본으로 30개를 추출했다면, \\(n\\)=30이라 표기한다.\n통계학에서 샘플 수라고 하면 표본의 개수를 뜻한다. 예를 들어 20명으로 이루어진 표본A와 이와 별개로 30명으로 이루어진 표본B가 있는 경우, 표본은 A, B 2개이므로 샘플 수는 2가 된다. 이처럼 표본크기와 표본의 개수는 혼동하기 쉬우므로 주의.\n표본크기는 모집단의 성질을 추정할 때의 확실성이나 가설검정의 결과에도 영향을 끼치기 때문에, 통계분석에 있어 중요한 요소 중 하나.",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#데이터-유형",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#데이터-유형",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "3.1 데이터 유형",
    "text": "3.1 데이터 유형\n- 모집단과 표본\n- 변수 : 데이터 중 공통의 측정 방법으로 얻은 같은 성질의 값\n예를 들어, 키는 하나의 변수이다. 변수는 각각 다른 값을 취할 수 있으므로 변수라고 불린다.\n변수가 여러 개인 경우, 변수 간의 관계를 밝히고자 데이터를 분석할 수 있다.\n통계학에서 변수의 개수는 ’차원’이라 표현되기도 한다.\n여러 개의 변수를 포함한 데이터는 ’고차원 데이터’라 한다.\n- 다양한 데이터 유형\n변수의 유형마다 분석 방법이 달라지기 때문에, 데이터를 수집할 때나 분석을 실행할 때는 변수가 어떤 유형인지 주의 깊게 고려하는 것이 중요\n\n양적 변수 (수치형 변수)\n\n수치로 나타낼 수 있는 변수를 양적 변수라 한다. 양적 변수는 다시 이산형과 연속형으로 나눌 수 있다.\n\n이산형\n\n얻을 수 있는 값이 점점이 있는 변수를 이산형 양적 변수(이산변수) 라 한다. ex) 주사위의 눈은 나오는 값이 1부터 6까지의 정수\n\n연속형\n\n키 173.4cm나 몸무게 65.8kg 같이 간격 없이 이어지는 값으로 나타낼 수 있는 변수를 연속형 양적 변수 (연속변수) 라 한다.\n이는 정밀도가 높은 측정 방법을 이용하면, 원리상으로는 소수점 아래 몇 자리든 나타낼 수 있다는 점에서 이산형과는 다르다.\n이산형과 연속형의 차이점은 확률분포의 종류와 밀접한 관계가 있으므로, 데이터를 다룰 때는 주의\n\n질적 변수 (범주형 변수)\n\n숫자가 아닌 범주로 변수를 나타낼 때, 이를 질적 변수 또는 범주형 변수라 한다. ex) 설문조사의 예/아니오, 동전의 앞/뒤\n숫자인 양적 변수와 달리, 변수 사이에 대소 관계는 없다.\n또한 범주형 변수는 숫자가 아니므로, 평균값 등의 수치 역시 정의할 수 없다.",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#데이터-분포",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#데이터-분포",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "3.2 데이터 분포",
    "text": "3.2 데이터 분포\n- 그림으로 데이터 분포 표현하기\n’데이터가 어떻게 분포되어 있는지’를 그래프 등으로 시각화하여, 대략적인 데이터 경향을 파악하는 것이 데이터 분석의 첫 단계\n데이터 분포를 그림으로 나타내는 데는 어떤 값이 데이터에 몇 개 포함되어 있는가(도수, 빈도, 횟수)를 나타내는 그래프인 도수분포도(히스토그램) 를 자주 사용\n- 히스토그램은 그림으로 나타낸 것일 뿐\n히스토그램은 대략적인 데이터 구성을 파악하는 것이 목적이지, 무엇인가 결론을 내기 위한 것이 아니라는 점을 명심",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#통계량",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#통계량",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "3.3 통계량",
    "text": "3.3 통계량\n- 데이터 특징 짓기\n수집한 데이터로 이런저런 계산을 수행하여 얻은 값을 일반적으로 통계량 이라 한다.\n데이터 그 자체의 성질을 기술하고 요약하는 통계량을, 기술통계량 또는 요약통계량 이라 부른다.\n\n통계량과 정보\n\n1개 또는 몇 개의 통계량으로 요약한다는 것은, 데이터에 있는 정보 중 버리는 부분이 있다는 것을 뜻한다. 예를 들어 평균값에는 ’어느 정도 데이터가 퍼져 있는지’의 정보는 포함되지 않습니다. 다른 예로 데이터에 포함된 가장 큰 값인 최댓값도 하나의 통계량이지만 여기에는 데이터 전체의 경향을 알 수 있는 정보가 없다. 이처럼 최댓값은 분포의 중심 위치나 분포 형태에 관한 정보가 주어지지 않으므로, 분포를 파악하는 데는 적합한 통계량이 아니다.\n- 다양한 기술통계량\n대략적인 분포 위치를 나타내는 대푯값 : 평균값, 중앙값, 최빈값\n데이터 퍼짐 정도를 나타내는 값 : 분산, 표준편차\n\n평균값(mean)\n\n표본의 평균값은 표본에서 얻었다는 점에서 ’표본평균’이라고도 한다.\n\\[ \\bar{x} = \\frac{1}{n}(x_1+x_2+...+x_n) = \\frac{1}{n}\\sum^n_{i=1} x_i \\]\n평균값은 계산 시 모든 값을 고려하기 때문에 이상값의 영향을 받기 쉽다는 특징이 있다.\n\n중앙값(median)\n\n‘크기 순으로 값을 정렬했을 때 한가운데 위치한 값’\n표본크기 \\(n\\)이 홀수라면 가운데 값은 1개이므로 이 값이 중앙값이다. 한편 표본크기 \\(n\\)이 짝수일 때는 가운데에 있는 값이 2개이므로, 두 값의 평균값을 중앙값으로 한다.\n중앙값은 수치 자체의 정보가 아닌 순서에만 주목하기에, 극단적으로 크거나 작은 값이 있어도 영향을 받지 않는다는 특징이 있다.\n\n최빈값(mode)\n\n‘데이터 중 가장 자주 나타나는 값’\n처음에 히스토그램을 그려 대략적인 파악을 한 다음, 대푯값으로 적절하게 분포를 특징 지을 수 있는지 확인하는 것이 중요한 데이터 분석 작업 순서라는 점을 꼭 기억\n- 분산과 표준편차\n데이터 퍼짐을 평가하기 위해서는 분산(variance) 혹은 표준편차(standard deviation, S.D.) 라는 통계량을 계산.\n표본에서 구하고, 표본을 평가한다는 점을 강조하여 ’표본분산(sample variance)’이나 ’표본표준편차(sample standard deviation)’라 부르기도 한다.\n표본분산 은 표본의 각 값과 표본평균이 어느 정도 떨어져 있는지를 평가하는 것으로, 데이터 퍼짐 상태를 정량화한 통계량이다.\n\\[ s^2 = \\frac{1}{n}\\{(x_1-\\bar{x})^2 + (x_2-\\bar{x})^2+...+(x_n-\\bar{x})^2\\} = \\frac{1}{n}\\sum^n_{i=1}(x_i-\\bar{x})^2 \\]\n\n표본분산의 성질\n\n\n\\(s^2 \\geqq 0\\)\n모든 값이 같다면 0\n데이터 퍼짐 정도가 크면 \\(s^2\\)이 커짐\n\n표본표준편차 \\(s\\)는, 이 표본분산의 제곱근을 취한 값이다.\n계산상 분산과 표준편차에는 제곱근인지 아닌지의 차이만 있으며, 포함하는 정보에는 차이가 없다. 분산 단위는 원래 값 단위의 제곱이 되지만, 표준편차는 제곱근을 취하므로 원래 단위와 일치한다. 따라서 데이터 퍼짐 정도를 정량화한 지표로는 표준편차 쪽이 감각적으로 더 알기 쉽게 느껴진다.\n- 분산을 확인할 수 있는 상자 수염 그림\n이름처럼 상자와 수염으로 구성되며, 각각은 데이터의 분포를 특징 짓는 통계량을 나타낸다.\n제1 사분위수(Q1) : 데이터의 25%가 이 값보다 작거나 같음\n제2 사분위수(Q2) : 중앙값\n제3 사분위수(Q3) : 데이터의 75%가 이 값보다 작거나 같음\n사분위간 범위 : 제1 사분위수와 제3 사분위수 간의 거리(Q3-Q1). 상자로 나타낸 부분.\n수염은 상자 길이(사분위간 범위)의 1.5배 길이를 상자로부터 늘인 범위 안에서, 최댓값 또는 최솟값을 가리킨다.\n이 범위에 포함되지 않은 값은 이상값으로 정의된다.\n상자 수염 그림은 중앙값이나 사분위수, 최댓값, 최솟값 등의 통계량은 나타내는 반면, 히스토그램에서 볼 수 있는 상세한 분포 형태 정보는 포함하지 않는다.\n- 분포를 시각화하는 다양한 방법\n\n막대그래프(평균값) + 오차 막대(S.D. or S.E.)\n바이올린 플롯\n스웜 플롯\n상자 수염 그림 + 스웜 플롯\n\n\n~ 67p. 3장 나머지 정리 必",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#추론통계를-배우기-전에",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#추론통계를-배우기-전에",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "4.1 추론통계를 배우기 전에",
    "text": "4.1 추론통계를 배우기 전에\n- 전수조사와 표본조사\n전수조사 : 모집단의 모든 요소를 조사\n표본조사 : 모집단의 일부인 표본으로 모집단의 성질을 추정\n- 데이터를 얻는다는 것\n” 데이터(표본)를 얻는다는 것은 무엇인가? ” : 모집단에 포함된 전체 값으로 구성된 분포에서 일부를 추출하는 것\n모집단분포를 특징 짓는 양을 모수 또는 파라미터 라 부른다\n확률분포와 실현값의 관계는 모집단과 표본의 관계와 매우 비슷\n‘모집단 = 확률분포, 표본 = 확률분포를 따르는 실현값’ 이라고 생각하자\n” 얻은 실현값으로 이 값을 발생시킨 확률분포를 추정한다 ” 라는 목표로 바꾸어 말할 수 있다.\n\n모집단분포 모형화\n\nex) 성인 남성 키의 분포는 정규분포와 매우 비슷하지만, 엄밀한 의미에서 정규분포가 되는 일은 있을 수 없다.\n그러나 있는 그대로를 바로 수학적으로 다룰 수 없을 때가 잦기 때문에, 3장에서 배운 것과 같은 수식 으로 기술하게 된다.\n그러면 수학적으로 다룰 수 있는 확률분포(모형)에 근사하여 작업을 진행할 수 있게 되어, 모집단의 추정이 용이해진다.\n수학적인 확률분포로 모집단 분포를 근사하는 것을 여기서는 모형화(modeling) 라 부르도록 하자\n예를 들어 정규분포로 근사할 수 있다면, 평균과 표준편차 같은 2가지 파라미터만으로 분포를 기술할 수 있으며, 다룰 수도 있게된다.\n이 장 후반에 등장하는 t분포는, 이와 같이 모집단이 정규분포라는 가정하에 이용할 수 있는 분포이다.\n\n무작위추출\n\n모집단에서 표본을 얻을 때 중요한 것이 무작위추출(random sampling) 이다.\n데이터를 얻을 때 모집단에 포함된 요소를 무작위로 선택하여 추출하는 방식\n독립적이지 않은 선택방식도 적절하지 않다.\n\n무작위추출 방법\n\n이상적인 무작위추출 방법은 표본에 있을 수 있는 모든 요소를 목록으로 만들고, 난수를 이용하여 표본을 정하는 것. 이를 단순무작위추출법 이라 한다.\n실제로 자주 사용하는 방법은 층화추출법 이다. 이는 모집단을 몇개의 층(집단)으로 미리 나눈 뒤, 각 층에서 필요한 수의 조사대상을 무작위로 추출하는 방법이다.\n그 밖에도 계통추출법, 군집추출법 등 다양한 방법이 있다.\n\n편향된 추출로는 올바른 추정이 어려움",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/확률론/통계_101_X_데이터_분석.html#표본오차와-신뢰구간",
    "href": "posts/확률론/통계_101_X_데이터_분석.html#표본오차와-신뢰구간",
    "title": "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석",
    "section": "4.2 표본오차와 신뢰구간",
    "text": "4.2 표본오차와 신뢰구간\n모집단의 평균 \\(\\mu\\)나 \\(\\sigma\\) 등은 고정된 값이지만, 모집단분포에서 얻은 표본 \\(x_1, x_2, ... x_n\\)은 확률적으로 변하는 확률변수라는 사실을 염두에 둘 것\n확률변수의 정확한 의미는?\n일반적으로 표본평균은 모집단평균 \\(\\mu\\)와 일치하지 않는다. 즉 ’정말로 알고 싶은 것’과 ’실제로 손 안에 있는 데이터’에는 어긋남(오차)가 생기는 것. 이런 오차를 표본오차(표집오차, sampling error) 라고 한다.\n표본오차는 표본을 추출할 때의 인위적인 실수나 잘못으로 생기는 오차가 아니라, 데이터 퍼짐이 있는 모집단에서 확률적으로 무작위 표본을 고르는 데서 발생하는, 피할 수 없는 오차라는 점에 주의\n\n큰 수의 법칙\n\n표본평균과 모집단평균의 관계에는 큰 수의 법칙(law of large numbers) 이 성립한다.\n표본크기 \\(n\\)이 커질수록 표본평균 \\(\\bar{x}\\)가 모집단평균 \\(\\mu\\)에 한없이 가까워진다는 법칙.\n다시 말해 표본오차 \\(\\bar{x}-\\mu\\)가 \\(0\\)에 한없이 가까워진다는 뜻이기도 하다.\n- 표본오차의 확률분포\n표본오차의 확률분포를 알면 어느 정도 크기의 오차가, 어느 정도의 확률로 나타나는지를 알 수 있게 된다.\n\n중심극한정리\n\n표본오차의 분포에 관해 중요한 정보를 제공하는 것이 중심극한정리(central limit theorem) 이다.\n모집단이 어떤 분포이든 간에, 표본크기 \\(n\\)이 커질수록 표본평균 \\(\\bar{x}\\)의 분포는 정규분포로 근사할 수 있다는 것을 의미\n’표본평균 \\(\\bar{x}\\)의 분포? : 표본크기 \\(n\\)으로 표본을 추출하고 표본평균 \\(\\bar{x}\\)를 계산하는 작업을 몇 번이고 반복해서, 표본평균을 한데 모아 히스토그램을 그린다는 것.\n표본크기 \\(n\\)이 커질수록 표본평균의 분포는 다음과 같은 정규분포로 근사할 수 있다.\n평균 : 모집단평균 \\(\\mu\\)\n표준편차 : \\(\\frac{\\sigma}{\\sqrt{n}}\\)\n\nChat GPT : 중심극한정리와 대수의 법칙의 차이점이 뭐야?\n\n\n중심극한정리 (Central Limit Theorem):\n\n중심극한정리는 확률론의 기본 개념 중 하나로, 독립적인 확률 변수들의 합 또는 평균이 정규분포에 근사하는 현상을 설명합니다. 중심극한정리는 다음과 같은 특징을 가집니다:\n독립적인 확률 변수들의 합 또는 평균은 표본 크기가 충분히 크면 정규분포에 근사한다.\n중심극한정리는 모집단의 분포에 상관 없이 적용될 수 있으며, 모집단이 어떤 분포를 따르더라도 표본 평균의 분포는 정규분포에 가까워진다.\n\n대수의 법칙 (Law of Large Numbers):\n\n대수의 법칙은 표본 크기가 커질수록 표본 평균이 모집단의 평균에 가까워진다는 원리를 설명합니다. 대수의 법칙은 다음과 같은 특징을 가집니다:\n대수의 법칙은 표본 크기가 커질수록 표본 평균이 모집단 평균에 수렴한다.\n대수의 법칙은 표본 크기가 충분히 크다면 모집단의 분포에 상관 없이 적용될 수 있으며, 모집단이 어떤 분포를 따르더라도 표본 평균은 모집단 평균에 가까워진다.\n차이점:\n중심극한정리는 확률 변수들의 합 또는 평균의 분포에 대한 이론을 다루는 것이며, 주로 정규분포와 관련이 있습니다.\n대수의 법칙은 표본 크기가 커질 때 표본 평균이 모집단 평균으로 수렴하는 원리를 설명하며, 분포에 대한 특별한 가정이 필요하지 않습니다. 이는 큰 표본 크기를 가지고 있는 경우에는 표본의 평균이 모집단 평균과 거의 같아질 것이라는 것을 의미합니다.\n중심극한정리와 대수의 법칙은 통계 분석과 데이터 분석에서 중요한 개념으로 사용되며, 표본 크기와 확률 분포에 대한 이해를 높이는 데 도움을 줍니다.\n\n추정량\n\n모집단의 성질을 추정하는 데 사용하는 통계량을 추정량 이라 한다.\n표본크기 \\(n\\)을 무한대로 했을 때, 모집단의 성질과 일치하는 추정량을 일치추정량 이라 하고, 추정량의 평균값(기댓값)이 모집단의 성질과 일치할 때의 추정량은 비편향추정량 이라 한다.\n비편향추정량은 매번 얻을 때마다 확률적으로 다른 값이 되지만, 평균으로 보면 모집단의 성질을 과대하지도 과소하지도 않게 나타내는 양을 뜻한다.\n모집단의 성질을 추정할 때 편향된 추정은 바람직하지 않다. 그러므로 비편향추정량은 바람직한 추정량이다.\n비편향추정량, 일치추정량 ??\n추정량 하나하나는 모집단의 성질(여기서는 \\(\\mu\\))에서 벗어나지만, 이를 모아 구한 평균값이 \\(\\mu\\)와 일치하는 경우 이를 비편향추정량이라 부른다.\n중심극한정리에서 본 것 처럼 표본평균의 분포의 평균은 모집단의 성질인 \\(\\mu\\)와 일치하므로, 표본평균은 모집단평균 \\(\\mu\\)를 편향되지 않게 추정하는 비편향추정량이다.\n한편 표본표준편차 \\(s\\)(또는 표본분산 \\(s^2\\))는 사정이 조금 다르다.\n표본표준편차 \\(s\\)의 정의에서 루트 안의 분모는 \\(n\\)이었다. 기술통계에서 데이터 퍼짐 정도를 평가할 때는 문제가 없지만, 모집단의 표준편차 \\(\\sigma\\)를 과소평가한다는 문제가 있다.\n올바르게는 \\(n-1\\)로 나눈 다음 식이, 모집단 표준편차 \\(\\sigma\\)의 비편향추정량이 된다.\n\\(s = \\sqrt{s^2} = \\sqrt{\\frac{1}{n-1}\\sum^n_{i=1}(x_i-\\bar{x})^2}\\)\n\n\\(n\\)으로 나누면 왜 과소평가가 되는가?\n\n각 값 \\(x_i\\)와 표본평균 \\(\\bar{x}\\)의 차이를 제곱하여 값이 얼마나 퍼졌는지를 측정하지만 원래 \\((x_i-\\mu)^2\\)로 계산해야 하는 것을 \\(\\mu\\)가 미지수이므로 \\((x_i-\\bar{x})^2\\)로 바꾼 것이다.\n\\(\\bar{x}\\)는 \\(\\mu\\)와 일치하지 않으며, 각 값 \\(x_i\\)와 \\(\\mu\\)의 위치 관계 또는 각 값 \\(x_i\\)와 \\(\\bar{x}\\)의 위치 관계를 생각하면 \\(x_i\\)는 \\(\\mu\\)보다도 \\(\\bar{x}\\)에 가까이 있을 것이다.\n그러므로 \\((x_i-\\bar{x})^2\\)의 합은 \\((x_i-\\mu)^2\\)보다도 작은 값이 된다.\n따라서 \\(n\\)으로 나누지 않고 \\(n-1\\)로 나누어 과소평가를 보정하는 것\n\n표본오차의 분포\n\n표본크기 \\(n\\)이 커질수록 표본오차 \\(\\bar{x}-\\mu\\)의 분포는 다음 정규분포로 근사할 수 있다.\n평균 : 0\n표준편차 : \\(\\frac{\\sigma}{\\sqrt{n}}\\)\n표본오차 \\(\\bar{x}-\\mu\\)의 분포는 모집단의 표준편차 \\(\\sigma\\)와 표본크기 \\(n\\) 등 2개의 값만 정해지면 알 수 있다는 것. 이 \\(\\frac{\\sigma}{\\sqrt{n}}\\)을 표준오차(standard error) 라 한다.\n\\(\\sigma\\)는 모집단의 성질이므로 보통 우리로선 알 수 없는 미지의 숫자이다. 그러므로 앞서 살펴본 표본에서 추정한 비편향표준편차 \\(s\\)를 \\(\\sigma\\) 대신 사용한 \\(\\frac{s}{\\sqrt{n}}\\)를 표준오차로 삼는다.\n이때 표본오차(단 \\(\\frac{s}{\\sqrt{n}}\\)으로 나눔)는 정규분포가 아니라 정규분포와 매우 닮은 t분포를 따르게 된다.\n- 신뢰구간이란?\n표본오차의 확률분포는 얼마나 큰 오차가 어느 정도의 확률로 나타나는가를 알 수 있다.\n간단하게 오차를 정량화하기 위해서, 신뢰구간(confidence interval) 이라는 개념을 도입\n\n정규분포의 성질에서 \\(평균값 \\pm\\) 2 \\(\\times 표준편차\\) 범위에 약 95%의 값을 포함하고 있었다. 즉, 정규분포에서 하나의 값을 무작위로 꺼내면 95%의 확률로 그 범위에 포함된다는 뜻\n\n이 개념을 그대로 표본오차의 정규분포에 적용해보면\n표본오차의 약 95%는 \\(0-2\\times \\frac{s}{\\sqrt{n}} \\leq \\bar{x} - \\mu \\leq 0 + 2 \\times \\frac{s}{\\sqrt{n}}\\)\n\\(\\bar{x}\\) 에서 \\(\\mu\\) 를 알고 싶기 때문에 이항하고 음수를 곱하면 \\(\\bar{x} - 2 \\times \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{x} + 2 \\times \\frac{s}{\\sqrt{n}}\\)\n\n신뢰구간의 해석\n\nOO% 신뢰구간을 해석하면 “OO%의 확률로 이 구간에 모집단평균 \\(\\mu\\)가 있다.” 가 된다.\n단, 확률변수는 모집단평균 \\(\\mu\\)가 아니라 표본평균 \\(\\bar{x}\\)(또는 신뢰구간)이다.\n\n즉 \\(\\mu\\)가 확률적으로 변화하여 그 구간에 포함되는 것이 아니라, 모집단에서 표본을 추출하여 OO% 신뢰구간을 구하는 작업을 100번 반복했을 때 평균적으로 그 구간에 \\(\\mu\\)가 포함되는 것이 OO번이란 뜻.\n\n하나의 표본에서 얻은 신뢰구간은 \\(\\mu\\)를 포함하거나 포함하지 않거나 둘 중 하나이다.\n신뢰구간은 표본에서 구한 모집단 \\(\\mu\\)의 추정값을 어느 정도 신뢰할 수 있는지를 나타낸다고 할 수 있다.\n신뢰구간이 좁다면 추정값 가까이에 \\(\\mu\\)가 있다고 생각할 수 있으므로, 추정값은 신뢰할 수 있는 값이다. 반대로 신뢰구간이 넓다면 추정값과 모집단평균 \\(\\mu\\)사이의 오차는 커지는 경향이 있으므로 신뢰도는 낮다.\nOO% 신뢰구간에서 ’OO%’에는 일반적으로 95%를 사용한다. 이 숫자는 과학계에서 관례로 사용되어 온 것으로, 필연성은 없다.\n가설검정에서 유의수준 5%는 95% 신뢰구간과 동전의 양면과 같은 관계이다.\n95% 신뢰구간이란 평균적으로 20번 중 1번 정도 벗어난다는, 달리 말하면 20번 중 19번은 구간에 모집단평균을 포함한다는 뜻이다.\n- t분포와 95% 신뢰구간\n정규분포의 성질을 “\\(평균값\\pm 2\\times 표준편차\\)”안에 95%라고 대략적으로 말해왔지만 정확하게는 “\\(평균값\\pm 1.96\\times 표준편차\\)”의 범위가 95%가 된다.\n문제가 되는 것은 중심극한정리는 표본크기 \\(n\\)이 커질수록 근사적으로 성립하기에 실제 데이터 분석에서 볼 수 있는 작은 표본크기의 경우 표본오차가 정규분포를 따른다고 말할 수 없다는 것과 모집단의 \\(\\sigma\\) 대신 \\(s\\)를 써야만 한다는 것.\n이때 활약하는 것이 \\(t\\)분포\n\\(t\\)분포는 모집단이 정규분포라는 가정하에 미지의 모집단 표준편차 \\(\\sigma\\)를 표본으로 계산한 비편향표준편차 \\(s\\)로 대용했을 때, \\(\\bar{x}-\\mu\\)를 표준오차 \\(\\frac{s}{\\sqrt{n}}\\)로 나누어 표준화한 값이 따르는 분포이다.\n\\[\\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}}\\]\n이 값은 표준오차 \\(\\frac{s}{\\sqrt{n}}\\)를 단위로 표본오차 \\(\\bar{x}-\\mu\\)가 몇 개분인지를 나타낸다.(3장의 표준화와 마찬가지)\n복잡하다고 느낄 수도 있겠으나, \\(t\\)분포 자체는 정규분포와 매우 비슷한 형태이며 표본크기 \\(n\\)에 따라 모양이 조금 달라질 뿐, 신뢰구간을 구하는 논리는 그대로이다.\n95%라는 엄밀한 값을 얻고자 미세 조정하는 것으로 생각하면 된다.\n아울러 표본크기 \\(n\\)이 커짐에 따라, \\(t\\)분포는 정규분포에 가까워진다.\n\\(t\\)분포에서 표본크기 \\(n=10\\)인 경우에는 평균 0, 표준편차 1인 정규분포보다 조금 넓어져 하위 2.5%, 상위 2.5%인 지점이 -2.26과 +2.26이 된다 (정규분포는 -1.96, +1.96)\n그러므로 신뢰구간을 구하는 식에서는 \\(\\pm 2\\)나 \\(\\pm 1.96\\)이 아닌 \\(\\pm 2.26\\)을 \\(\\frac{s}{\\sqrt{n}}\\)에 곱해 계산한다.\n\n정밀도를 높이려면\n\n보다 신뢰 가능한 평균값을 추정하고 싶을 때는 어떻게 할까?\n오차분포의 너비를 나타내는 표준오차 에 주목해보면 이를 작게 만들기 위해서는 분자인 비편향표준편차 \\(s\\)를 작게 하거나, 분모인 표본크기 \\(n\\)을 크게 하는 두 가지 방법이 있다.\n\\(s\\)(또는 \\(\\sigma\\))는 모집단 데이터 퍼짐이라는 모집단 그 자체의 성질에서 유래하기에 작게 만들기 어렵지만, 측정한 데이터 퍼짐(변동) 정도를 줄일 수는 있다. 데이터 퍼짐이 증가하면 결과적으로 \\(s\\)(또는 \\(\\sigma\\))가 커지기 때문에, 측정을 한층 정밀하게 실시하는 식으로 대처 가능한 경우도 있다.\n표본크기 \\(n\\)에 관해서는, \\(n\\)을 크게 만듦으로써 더 높은 정밀도로 추정할 수 있다.\n\n\\(t\\)분포를 사용할 때 주의할 점\n\n표본크기 \\(n\\)이 작아도 적용 가능한 %t$분포에는 ’정규분포에서 얻은 데이터’라는 가정이 필요하다. 즉, \\(t\\)분포는 데이터 \\(x_1, x_2, ... , x_n\\)을 정규분포라는 모형에서 얻었을 때의 (표준화된) 표본오차가 따르는 분포이다. 데이터의 배경에 잇는 모집단분포가 완벽한 정규분포일 수는 없으므로, 얻은 95% 신뢰구간은 정확한 95%가 아니라는 점에 주의.\n특히 문제가 되는 것은 정규분포와 현저하게 다른 분포에서 데이터를 얻었을 때이다. 이 경우 95% 신뢰구간을 구해도 95%에서 벗어날 수 있어 주의해야 한다.\n단, 표본크기 \\(n\\)이 클 때는 중심극한정리에 따라 모집단이 정규분포가 아니더라도 표본평균을 정규분포로 근사할 수 있으므로 신뢰구간은 정확해진다.",
    "crumbs": [
      "About",
      "Posts",
      "확률론",
      "빅데이터 시대, 올바른 인사이트를 위한 통계 101 X 데이터분석"
    ]
  },
  {
    "objectID": "posts/데이터_분석.html",
    "href": "posts/데이터_분석.html",
    "title": "데이터 과학",
    "section": "",
    "text": "데이터 과학 : 데이터를 사용하여 질문에 합리적인 답을 내릴 수 있게 해주는 활동\n\n데이터 분석에 있어 기초통계, 선형모형(회귀·분산 분석 포함)은 제대로 배울 것을 권장.\n중요한 요소 : 협업할 수 있는 태도, 소통능력, 폭넓은 독서(논픽션 양서)\n데이터 획득 : UCI, 머신러닝 리포, 캐글, 위키피디아 데이터 세트 리스트 등…\n분석 순서 : 데이터 취득·데이터 정리 → 탐색적 자료 분석 EDA : 시각화·기초통계량 계산(데이터의 패턴, 이상치 탐색) → 확증적 자료 분석 CDA : 통계적 가설·가설검정·신뢰구간(통계적 모형화 statistical modeling)\n\n\n\n특별한 이유를 제외하고는 양측검정 하는 것이 좋다.\np-value가 크다는 것은 귀무가설에 반하는 증거가 불충분하다는 것이지 귀무가설을 증명하는 증거가 있다는 것이 아니다.\n\n\n\nGapminder(http://www.gapminder.org/) :스웨덴의 비영리 통계 분석 서비스. 틈새주의(mind the gap)라는 지하철 경고문에서 영감을 얻은 이름은 세계관과 사실/데이터 간의 간극을 조심하고 좁히자는 이상을 반영\n더미 변수 :\nSQL\n유닉스 쉘\n파이썬 코딩 스타일 : PEP 0008 (도움을 주는 pylint)\nt값 : $ $\n\nsss",
    "crumbs": [
      "About",
      "Posts",
      "데이터 과학"
    ]
  },
  {
    "objectID": "posts/데이터_분석.html#통계",
    "href": "posts/데이터_분석.html#통계",
    "title": "데이터 과학",
    "section": "",
    "text": "특별한 이유를 제외하고는 양측검정 하는 것이 좋다.\np-value가 크다는 것은 귀무가설에 반하는 증거가 불충분하다는 것이지 귀무가설을 증명하는 증거가 있다는 것이 아니다.\n\n\n\nGapminder(http://www.gapminder.org/) :스웨덴의 비영리 통계 분석 서비스. 틈새주의(mind the gap)라는 지하철 경고문에서 영감을 얻은 이름은 세계관과 사실/데이터 간의 간극을 조심하고 좁히자는 이상을 반영\n더미 변수 :\nSQL\n유닉스 쉘\n파이썬 코딩 스타일 : PEP 0008 (도움을 주는 pylint)\nt값 : $ $\n\nsss",
    "crumbs": [
      "About",
      "Posts",
      "데이터 과학"
    ]
  }
]