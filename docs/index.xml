<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Time Series</title>
<link>https://star77sa.github.io/</link>
<atom:link href="https://star77sa.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.4.540</generator>
<lastBuildDate>Thu, 18 Jan 2024 15:00:00 GMT</lastBuildDate>
<item>
  <title>성능 평가 지표(회귀모델, 분류모델)</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/etc/모델_성능평가지표_정리.html</link>
  <description><![CDATA[ 





<section id="포스팅-예정" class="level1">



</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/etc/모델_성능평가지표_정리.html</guid>
  <pubDate>Thu, 18 Jan 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[논문 리뷰] Machine learning driven smart electric power system: Current trends and new perspectives(2020)</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/Paper/smartgrid1.html</link>
  <description><![CDATA[ 





<hr>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0306261920307492">Machine learning driven smart electric power system: Current trends and new perspectives (2020)</a></p>
<hr>
<section id="abstract" class="level1">
<h1>Abstract</h1>
<ul>
<li><p>이 연구는 다양한 측면으로부터 스마트 그리드의 기술적 문제에 성공적으로 접근하기 위해 머신러닝 기술 사용의 증가하는 관심과 빠른 확장에 대해 쓰여졌다.</p></li>
<li><p>현재의 전력 시스템은 보다 능동적이고 유연하며 지능적인 스마트 그리드로 빠르게 전환되고 있으며 이는 많은 영역에서 도전을 야기한다. (다양하게 분배된 재사용가능한 에너지들의 통합, 사이버 보안, 수요측면관리, 시스템 계획 및 운영에 관한 의사결정)</p></li>
<li><p>스마트그리드에서 고급 기능의 실현은 기본적인 정보 통신 인프라와 다양한 소스(smart meter, phasor measurement units, and various forms of sensors)에서 생성된 방대한 양의 데이터를 효율적으로 처리하는 데 크게 의존한다.</p></li>
<li><p>몇몇 이슈는 여전히 열리고 더 연구할 가치가 있는 채로 남겨졌다. (high-performance data processing and analysis for intelligent decision-making in large-scale complex multi-energy systems, lightweight machine learning-based solutions, and so forth)</p>
<p>더하여 진보된 컴퓨팅, 통신기술(edge computing, ubiquitous internet of things and 5G wireless networks, in the smart grid are also highlighted.)을 활용하는 미래관점에서 스마트그리드는 주목받을 것이다.</p></li>
<li><p>머신러닝은 미래 스마트 전력 시스템을 이끄는 주요한 방법 중 하나가 될 것이다.</p></li>
</ul>
</section>
<section id="conclusion" class="level1">
<h1>6. Conclusion</h1>
<ul>
<li><p>스마트 그리드 - 전통적 power grid와 반대로 더 효율적이고 데이터에 의존하고 사용자 중심적이다.</p></li>
<li><p>인공지능 맥락에서 머신러닝 기술은 스마트그리드의 다양한 측면의 단순하지 않은 기술적 도전에 접근하기 위한 효율적이고 진보된 도구로 고려된다.</p>
<p>머신러닝 툴 사용의 빠른 확장에도 불구하고 몇몇 문제들은 남아있고 더욱 연구할 가치가 있다.</p></li>
<li><p>200개가 넘는 2014~2019 high impact journal들을 광범위하게 리뷰하고 보고하였다. 간단한 신경망부터 세련된 강화학습과 딥러닝 방법도 관측되었다. 더 구체적으로 55개가 machine learning based forecasting 문제, 23개가 machine learning based fault analysis, 42개가 machine leanring driven DSM 문제, 35개가 cyberspace security issues였다.</p></li>
</ul>
</section>
<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<ul>
<li><p>AC(Alternating current), DC(Direct current) system</p></li>
<li><p>conventional energy system → more efficient next-generation smart grid system.</p></li>
<li><p><strong>conventional energy system</strong></p>
<ul>
<li>few centralized and large power generation sources</li>
<li>mainly hydropower or fossil fuel based power generation system to the consumers via a distribution system</li>
<li>uni-directional(단방향) power and communication flow ⇒ passive</li>
</ul></li>
<li><p><strong>smart grid</strong></p>
<ul>
<li>integration and contribution of every distributed and renewable energy resource</li>
<li>two-way power and information flow ⇒ active —</li>
<li>bi-directional flow of power and communication은 reliability, security, efficiency of power systems를 향상시킬 수 있다.</li>
</ul></li>
<li><p>스마트 그리드는 더 좋은 energy efficiency, cost-effectiveness, controlled <img src="https://latex.codecogs.com/png.latex?CO_2"> emission, reduced cost, improved utility로 인해 미래의 전력망으로 일컬어지고 있다.</p></li>
<li><p>스마트 그리드는 conventional power grid와 비교하여 넓은 범위의 작업들을 수행한다. 많은 수의 기기 연결은 에너지 관련 작업을 특정 방식으로 수행하기 위한 명령과 정보 교환을 가능케 한다.</p></li>
<li><p>grid infrastructure로의 IoT 기기들의 통합은 미래 스마트그리드로 향한 첫걸음이다.</p>
<ul>
<li>Smart meter는 실시간에서 에너지 소비를 측정할 수 있을 뿐만 아니라 양방향 통신을 통해 고객이 전력 유틸리티와 상호작용하고 advanced demand-side management operations를 수행할 수 있도록 한다.</li>
<li>스마트그리드에서 IoT의 통합은 스마트그리드들의 관리에 추가적인 challenge들을 가져온다. 예를들어 the timely delivery of critical operational information, the efficient process of the vat amount of field data, and cyberspace security issues. 이러한 문제들은 적절한 접근 및 기술 사용이 필요 e.g., the phasor measurement unit placement, advanced analytical tools, and machine learning-based solutions.</li>
</ul></li>
<li><p>This paradigm-shift(conventional grid → smart grid) has equipped the power grid with many distributed generation(DG) systems, such as photovoltic(PV), wind energy, and electric vehicles(EV). 다시말해 스마트그리드는 processes, technologies, and distributed and renewable generation systems that makes the conventional power grid more intelligent and efficient의 통합이다.</p></li>
<li><p>다양한 DGs의 통합은 수많은 challenge들을 소개한다. 예를들어 load forecast, fault and failure analysis, demand-side management, non-intrusive load monitoring(NILM), cyberspace security, electricity theft detection, and islanding detection among others.</p></li>
<li><p>최근 몇년간 스마트 그리드에 독보적인 문제에 접근하는 머신러닝 기반 기술의 사용이 관측되는 트렌드이다.</p></li>
<li><p>이 연구는 스마트 그리드에서 머신러닝 기술의 응용의 최근 진보 overview와 다양한 기술들의 한계점에 대해 토론하는것에 더해 future practice을 위한 가능한 솔루션에 초점을 맞춘다.</p></li>
</ul>
</section>
<section id="an-overview-of-machine-learning" class="level1">
<h1>2. An overview of machine learning</h1>
<ul>
<li><p>특히 IoT를 포함한 고급 정보 및 통신 기술을 전력 그리드 인프라에 통합하는 것은 스마트 그리드로 나아가는 주요 단계 중 하나이다.</p></li>
<li><p>스마트 그리드의 다양한 응용 분야에서 발생하는 challenge에 대처하기 위해 기계 학습 및 딥 러닝 기반 솔루션을 탐색하는 데 많은 연구 노력이 기울여졌다.</p></li>
<li><p>머신러닝 기술은 넓게 4가지 카테고리로 분류된다.</p>
<ol type="1">
<li>Supervised learning : 학습을 위해 인풋과 아웃풋 사이에 맵핑이 되어있고 많은 트레이닝 샘플들 인풋과 아웃풋 페어에 라벨이 주어진다.</li>
<li>Unsupervised learning : 라벨이 없을 뿐만 아니라 분류도 되어있지 않다. similarity 나 difference를 기준으로 그룹핑한다. supervised보다 복잡한 task. 흔한 방식은 cluster analysis이며 이는 숨겨진 패턴 또는 데이터를 그룹핑할때 EDA를 사용한다.</li>
<li>Reinforcement learning(RL) : <strong>agent</strong>가 환경과 상호작용 하고 action에 응답하여 받은 자극에 기반하여 액션을 수정한다. RL은 input/output 페어의 라벨을 요구하지 않고 환경에서 액션에 응답하여 에이전트에 reward or penalty를 받는다는점에서 supervised learning과 다르다. RL는 행동을 자동적으로 결정하는것이 가능하다. 인간이나 동물의 행동과 가장 유사한 방법</li>
<li>Ensemble methods : 몇몇 머신러닝 알고리즘을 사용하여 한개의 알고리즘을 쓸때보다 성능을 향상시키기 위해 만든다. 싱글보다 일반화된 성능을 가짐.</li>
</ol></li>
<li><p>전통적인 계산 기술의 부족함과 한계는 다양한 스마트 그리드 도전 과제에 대한 대응으로 기계 학습 기술을 사용하는 동기를 제시한다.</p></li>
<li><p><strong>Limitations of existing solutions</strong></p>
<ul>
<li>Unable to handle large amounts of data</li>
<li>Lacking robustness against uncertainty</li>
<li>Lacking better optimization in the presence of constraints</li>
<li>Lacking adaptive and autonomous operations</li>
<li>Lacking intelligent decision making</li>
<li>Lacking real-time processing</li>
<li>Lacking complex systems modeling capability</li>
<li>Unable to handle non-linear systems</li>
</ul></li>
<li><p><strong>Benefits of ML techniques</strong></p>
<ul>
<li>Mostly data-driven</li>
<li>Feature selection and feature extraction ability</li>
<li>Autonomous, adaptive, and intelligent operations and decision making</li>
<li>Can perform real-time and/or near realtime operations</li>
<li>Can effectively deal with non-linear systems</li>
<li>Complex system modeling</li>
</ul></li>
</ul>
</section>
<section id="machine-learning-applications-in-smart-grid" class="level1">
<h1>3. Machine learning applications in smart grid</h1>
<section id="forecasting-in-smart-grid" class="level2">
<h2 class="anchored" data-anchor-id="forecasting-in-smart-grid"><em>3.1. Forecasting in smart grid</em></h2>
<section id="electric-load-and-price-forecasting" class="level3">
<h3 class="anchored" data-anchor-id="electric-load-and-price-forecasting"><em>3.1.1. Electric load and price forecasting</em></h3>
<ul>
<li><p>Electric load forecasting is divided into three categories based on the forecasting horizons.</p>
<ol type="1">
<li>Short-term Load Forecasting</li>
</ol>
<ul>
<li><p>short : generally involves load forecasting of a few minutes up to a few days</p></li>
<li><p>…</p>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-12-1-image.png" class="img-fluid"></p></li>
</ul>
<ol start="2" type="1">
<li>General (Medium-term and long-term) Load Forecasting</li>
</ol>
<ul>
<li><p>medium : forecast of a few days up to a few months</p></li>
<li><p>long : forecast of a few months up to a year</p></li>
<li><p>…</p>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-12-1-image.png" class="img-fluid"></p></li>
</ul>
<ol start="3" type="1">
<li>Electricity Price Forecast</li>
</ol>
<ul>
<li><p>…</p>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-12-1-image.png" class="img-fluid"></p></li>
</ul></li>
</ul>
</section>
<section id="renewable-power-generation-prediction" class="level3">
<h3 class="anchored" data-anchor-id="renewable-power-generation-prediction"><em>3.1.2. Renewable power generation prediction</em></h3>
<ul>
<li><p>The integration of renewable energy systems poses many challenges due to their variable generation patterns caused by their <strong>geographical location, weather, and other factors</strong> which can impact the <strong>power quality and stability</strong>.</p></li>
<li><p>…</p>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-13-1-image.png" class="img-fluid"></p></li>
</ul>
</section>
</section>
<section id="machine-learning-in-fault-and-failure-analysis" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-in-fault-and-failure-analysis"><em>3.2. Machine learning in fault and failure analysis</em></h2>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-14-1-image.png" class="img-fluid"></p>
</section>
<section id="machine-learning-in-demand-side-management" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-in-demand-side-management"><em>3.3. Machine learning in demand-side management</em></h2>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-15-1-image.png" class="img-fluid"></p>
</section>
<section id="machine-learning-in-cyberspace-security" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-in-cyberspace-security"><em>3.4. Machine learning in cyberspace security</em></h2>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-16-1-image.png" class="img-fluid"></p>
</section>
<section id="others" class="level2">
<h2 class="anchored" data-anchor-id="others"><em>3.5. Others</em></h2>
<ul>
<li>…</li>
</ul>
</section>
</section>
<section id="discussion-and-remarks" class="level1">
<h1>4. Discussion and remarks</h1>
<section id="observations" class="level2">
<h2 class="anchored" data-anchor-id="observations"><em>4.1. Observations</em></h2>
<ul>
<li>광범위한 문헌 조사는 다양한 smart grid challenges에 접근하는 머신러닝, 딥러닝 기법의 사용 증가를 보여준다.</li>
</ul>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-19-1-image.png" class="img-fluid"></p>
<ul>
<li><p>Based on the comprehensive review of the literature, a collection of observations and insights are summarized as follows:</p>
<ul>
<li><p><strong>Electric Load Forecasting</strong> : 상대적으로 성숙한 분야. 머신러닝 기법이 중요한 역할을 하였다. 기상 데이터의 활용 및 다양한 지역의 계층적 예측을 활용하였다. 게다가, 기계학습 기반 단기 예측은 수요를 충족시키고 간헐적이고 재생 가능한 분산 발전 예측에도 크게 기여하였다.</p>
<p>유명한 기계학습 기반 electric load forecast algorithms는 supervised neural networks, LSTM RNN, and Random forest among others를 포함한다</p></li>
<li><p><strong>Fault diagnosis and detection :</strong> 머신러닝 기법은 고장 감지 및 진단에서 뛰어난 성과를 보인다. 이는 고장에 대한 깊은 이해나 전문 지식이 필요하지 않고, 데이터의 패턴에 민감하며, 필수적인 변수가 누락되어도 효율적으로 동작할 수 있다는 특성 때문이다. 반면에 베이지안 네트워크와 같은 지식 주도 방법(Knowledge-Driven Approach (↔︎ Data Driven Approach))은 도메인 및 전문 지식의 도입으로 불완전한 정보에 대한 문제를 해결할 수 있다.</p></li>
<li><p><strong>Load management / demand-side management(DSM)</strong> : DSM frameworks or demand response programs are mainly based on classification where machine learning tools such as SVM, MLP, and RNN have shown promising performance.</p></li>
<li><p><strong>NILM :</strong> use of deep learning and advanced multi-label classification methods such as ML-KNN and SVM where the need of prior feature extraction is diminished due to the automatic feature extraction ability of such methods, which was one of the challanges for the classic machine learning techniques.</p></li>
<li><p><strong>Cyber-attack detection</strong> : 머신러닝 기반 방법은 flexibility towards scalability 때문에 높은 분류 정확도를 보인다. + dominance of supervised learning methods in attack detection.</p></li>
<li><p><strong>Energy and economic dispatch :</strong> 대부분의 문헌들은 multi-agent theory를 사용. 이는 정확한 cost function의 수학적 모델을 요구하는 반면 최근의 몇 연구에서는 이 문제를 해결하기 위해 강화학습 알고리즘과 같은 머신러닝을 사용하는 경향이 있다.</p></li>
</ul></li>
<li><p>기존의 그리드에서 스마트 그리드로 전환하고 기존의 생산 시스템을 탈탄소화 하기 위해서는 현재의 전력망에 친환경적이고 재사용가능한 생산시스템의 더 많이 침투해야한다. 이러한 시스템의 침투는 최적의 전력 흐름과 수급 균형을 유지하면서 효과적이고 효율적인 계획 전략이 필요하며 이는 SVM, Q-learning, Decision trees 같은 기계 학습 도구가 효과적으로 사용될 수 있는 복잡한 비선형 문제로 모델링될 수 있다.</p>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-20-1-image.png" class="img-fluid"></p></li>
<li><p>다양한 머신러닝 알고리즘(SVM, LSTM, DBN and CNN)이 많은 스마트 그리드 문제 해결에 사용되곤 한다.</p>
<p>Neural network가 가장 많이 사용되고 높은 정확도를 보이며 non-linear mapping ability.</p>
<p>Deep learning 은 forecasting과 cyberspace security에서 인기있는 기술이다.</p>
<p>LSTM과 같은 RNN은 forecasting문제에서 사용이 증가하고있다.</p>
<p><img src="https://star77sa.github.io/posts/Paper/smartgrid1_files/figure-html/cell-21-1-image.png" class="img-fluid"></p></li>
</ul>
</section>
<section id="technical-challenges" class="level2">
<h2 class="anchored" data-anchor-id="technical-challenges"><em>4.2. Technical challenges</em></h2>
<p>다양한 스마트 그리드 응용 분야에서 기계 학습 알고리즘 및 기술의 구현을 위한 몇 가지 도전요소와 권장 사항:</p>
<ul>
<li>Smart Grid Data Preprocessing:
<ul>
<li><p>데이터 전처리는 일반적으로 데이터 통합, 데이터 정제, 데이터 변환 세 가지 주요 단계로 이루어짐.</p></li>
<li><p>스마트 그리드의 데이터 전처리 사이클은 다양한 데이터 소스로 인해 도전적이다.</p>
<p>주요 데이터 소스에는</p>
<ol type="1">
<li><p>real and reactive powers, DR capacity, voltage 등의 operational data</p></li>
<li><p>전력 품질 및 신뢰성과 관련된 non-operational data</p></li>
<li><p>하루 중 시간, 평균, 최대 수요 값, 전력 사용과 관련된 스마트 미터 데이터</p></li>
<li><p>voltage loss, fault detection event, security breach event를 포함하는 스마트 그리드 event data</p></li>
<li><p>다른 유형의 데이터를 조직하고 해석하는 데 사용되는 메타데이터</p></li>
</ol></li>
<li><p>스마트 그리드의 데이터 전처리는 다양한 유형의 데이터 소스와 이에 따른 데이터로 인해 도전적이다.</p></li>
</ul></li>
<li>Data Availability:
<ul>
<li>load forecasting 문제에서의 기계 학습 기반 모델은 효율적인 예측 결과를 보이며 이러한 모델은 전통적인 방법보다 더 유연하다. 그러나 기계학습 기반의 예측 모델은 대량의 대표적인(representative) 데이터에 크게 의존하며, 이러한 데이터 없이는 모델이 일반성을 가지지 못한다. 또한 예측 시계열에 대한 예측 기간에 상관없이 정확한 예측을 수행하고 다양한 제약 조건에 대한 트레이드오프를 하지 않고도 작동할 수 있는 표준적이고 견고한(robust) 예측 방법이 필요하다.</li>
</ul></li>
<li>Load Transfer Detection(부하 이전 감지?):
<ul>
<li>대부분의 문헌 검토에서는 강조되지 않았음. 다만 정확하고 효율적인 예측을 달성하기 위한 주요 도전 중 하나이다.</li>
<li>이 도전은 utility or distribution 운영자가 주로 유지보수 또는 신뢰성 이유로 계절적, 임시 또는 영구적인 기준으로 다른 회로로 부하를 이전할 때 발생한다. 기계 학습 방법은 부하 예측에서 이러한 도전을 효과적으로 식별하고 해결하는 데 중요한 역할을 할 수 있다.</li>
</ul></li>
<li>Extrapolation of Faults:
<ul>
<li>fault diagnosis와 fault detection을 위한 데이터 기반 모델은 유망한 결과를 보여주었지만 이러한 기계학습 모델은 훈련 데이터의 경계를 넘어 추론할 수 없다. 따라서 베이지안 방법, 퍼지 기반 방법과 같은 지식 기반 방법과 데이터 기반 기계학습 기반 방법을 결합한 하이브리드 접근 방식은 상기한 문제를 효과적으로 해결할 수 있다.</li>
</ul></li>
<li>Machine Learning-based Planning Framework:
<ul>
<li>스마트 그리드 기획 및 운영 문제에 대한 기계학습을 통한 추가적인 연구 가능성이 여전히 많이 남아있다.</li>
</ul></li>
<li>Deep Learning-based Multi-label Classification Approaches:
<ul>
<li><p>NILM 문제에서 표준 딥 러닝 방법(SAE 및 DBN과 같은)의 한계로 인해 딥 러닝 기반 다중 레이블 분류의 탐색과 개발이 필요하다.</p>
<p>로지스틱 회귀 및 소프트맥스가 훈련에 자주 사용되는 경우, 로지스틱 회귀 및 소프트맥스 기반의 딥 러닝 모델 훈련은 단일 클래스로 이어진다. 따라서 다른 혁신적인 딥 러닝 기반 다중 레이블 분류 접근 방식은 NILM 문제를 효과적으로 해결할 수 있다.</p>
<p><code>=&gt; 다중 레이블 분류와 다중 클래스 분류(다중분류)는 다르다. 다중분류는 각 샘플이 하나의 클래스에만 속할 수 있는 분류 문제를 의미. 다중 레이블 분류는 각 샘플이 여러 개의 클래스에 속할 수 있는 분류 문제를 의미한다. 즉, 각 샘플은 여러 개의 레이블을 가질 수 있으며 각 레이블은 클래스를 나타낸다.</code></p></li>
</ul></li>
<li>Post-Attack Resilience Frameworks(사이버 공간에서의 공격 후 회복 프레임 워크):
<ul>
<li>사이버 공간 보안과 관련된 대부분의 문헌은 기계학습 기반의 공격 탐지 및 예방 메커니즘에 중점을 두지만, 공격 이후의 상황에 중점을 둔 출판물은 소수이다. 따라서 사이버 위협의 탐지 및 예방뿐만 아니라 완화에 중점을 둔 보안 알고리즘이 필요하다.</li>
</ul></li>
<li>Lightweight Machine Learning Solutions:
<ul>
<li>미래의 IoT 기반 스마트 디바이스에 구현하기 위해 빠르면서도 계산 비용이 적은 기계 학습 및 딥 러닝 알고리즘이 필요하다. 이는 계산 요구 사항이 제한된 스마트 디바이스에서 사용될 것이다.</li>
</ul></li>
<li>Smart Grid Reliability Requirements:
<ul>
<li><p>스마트 그리드에 대규모로 통합되는 재생 가능한 power sources, 특히 풍력 및 태양광 발전 시스템은</p>
<ol type="1">
<li><p>일반적인 예측 기간에서의 큰 예측 오류,</p></li>
<li><p>대규모 설치로 인한 송전 혼잡,</p></li>
<li><p>전압 및 주파수 안정성과 관련된 전력 품질 문제,</p></li>
<li><p>지리적으로 분산된 자원으로 인한 관련 전력 분배 시스템의 challenge</p></li>
</ol>
<p>로 스마트 그리드의 신뢰성 요구 사항을 강조한다. 이러한 시스템의 불확실성 및 신뢰성 요구 사항은 스마트 그리드에서 기계 학습 기반 기술을 다양한 측면에서 활용하는 데 명백한 challenge를 제공한다. 예를 들면 효율적인 운영 상태 모니터링 및 분석, 정확한 상태 예측 및 이상 징후 감지, 그리고 합리적인 의사 결정 등이 있다.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="new-perspectives" class="level1">
<h1>5. New perspectives</h1>
<ul>
<li>컴퓨터 분야에서의 기술적 발전과 고급 컴퓨팅 시스템의 가용성은 복잡하고 계산 비용이 많이 드는 알고리즘을 활용하여 다양한 과학 및 공학적 도전에 효과적인 해결책을 제공하고 있다.</li>
</ul>
<section id="new-perspectives-in-smart-energy-systems-application-domain" class="level2">
<h2 class="anchored" data-anchor-id="new-perspectives-in-smart-energy-systems-application-domain"><em>5.1. New perspectives in smart energy systems application domain</em></h2>
<ul>
<li><p>스마트 그리드는 다양한 성격의 에너지 원천과 소비자들 간의 복잡한 네트워크로, 여기에서 기계 학습 기술이 유망한 기여를 보여주고 있다.</p></li>
<li><p>기계 학습 모델의 적용은 에너지 시스템에서 운영 계획, 소비자 수요 관리, 재생 에너지 시스템 통합 등에 유용</p></li>
<li><p>단위 할당 및 에너지 경제 배치와 같은 전력 시장 거래 운영이 기계 학습 도구를 사용하여 더 깊이 탐구될 수 있다</p></li>
<li><p>DSM은 스마트 그리드의 핵심 촉진 요소 중 하나로, 소비자들이 유틸리티 자체 외에도 전력 관리에 적극적으로 참여할 수 있는 환경을 제공</p></li>
<li><p>DR에 대한 기존 연구가 이미 수행되었음에도 불구하고, 기계 학습이 소비자 행동 예측을 통해 전력 공급 관리를 더욱 향상시킬 수 있다는 전망</p></li>
<li><p>소비자 행동 및 전력 소비 패턴을 학습함으로써 부하 예측, 전기 요금 개발, 그리고 차량-그리드 및 차량-가정 모델, 전기 자동차 충전 일정에 큰 기여를 할 수 있습니다</p></li>
</ul>
</section>
<section id="new-perspectives-in-emerging-technologies-integration-with-smart-energy-systems" class="level2">
<h2 class="anchored" data-anchor-id="new-perspectives-in-emerging-technologies-integration-with-smart-energy-systems"><em>5.2. New perspectives in emerging technologies integration with smart energy systems</em></h2>
<ul>
<li><p>인공 지능 및 컴퓨팅 기술의 발전에도 불구하고, 스마트 디바이스의 급증, 복잡한 기계 학습 및 딥 러닝 알고리즘의 진화, 그리고 이에 따른 컴퓨팅 수요의 증가로 인해 필요한 컴퓨팅 리소스의 즉각적인 가용성이 요구된다.</p></li>
<li><p>기존의 스마트 그리드 네트워크는 주로 IoT 및 클라우드 기반 네트워크로, 데이터 처리 및 저장은 일반적으로 클라우드 서버에서 수행된다. 그러나 클라우드 컴퓨팅 기반 시스템은 효율적인 컴퓨팅 및 저장 리소스를 제공하며 복잡한 계산 부담을 완화하는 데 도움이 될 수 있지만, 클라우드 컴퓨팅은 고지연성과 실시간 응용 프로그램에 제약 사항이 있으며 대역폭 이용도가 증가하는 등의 한계가 있다. 더구나, 클라우드 컴퓨팅 패러다임은 이동성을 지원하지 않는 문제도 가지고 있다.</p></li>
<li><p>앞서 언급한 문제를 해결하기 위해 <strong>에지 컴퓨팅</strong>을 스마트 그리드 네트워크에 클라우드 컴퓨팅과 함께 중간 컴퓨팅 및 저장 시스템으로 통합할 수 있다. 에지 컴퓨팅 기술은 주로 <strong>포그 컴퓨팅</strong>, <strong>모바일 에지 컴퓨팅</strong> 및 <strong>클라우드렛 컴퓨팅</strong>을 포함.</p></li>
<li><p>미래의 연구 전망에는 IoT 및 에지 컴퓨팅 기반 스마트 그리드 인프라에 정교한 기계 학습 도구를 도입하여 예측 분석, 데이터 필터링, 사이버 공격 탐지, 단기 예측, 에지에서의 부하 분해 등과 같은 다양한 기능을 수행하는 것이 포함될 수 있다. 클라우드에서 풍부한 양의 기록 데이터를 기반으로 훈련된 기계 학습 모델은 에지 디바이스에서의 실시간 추론을 통해 실현될 수 있다.</p></li>
<li><p>에지 컴퓨팅 패러다임 외에도 통신 네트워크의 최근 발전 및 <strong>5G 네트워크</strong>의 진화는 DSM, 그리드 모니터링, 그리드 제어 및 전기차 충전 및 방전 조정과 같은 다양한 스마트 그리드 서비스에 대한 네트워크 가상화 및 소프트웨어 정의 네트워크와 같은 혁신적인 5G 개념의 사용을 촉진하고 있다. 5G를 활용한 IoT의 스마트 그리드 적용은 높은 통신 속도, 동적인 특성, 저전력 소비, 견고한 보안 및 다양한 연결 기능으로 인해 더 나은 통신 인프라를 제공할 수 있다.</p></li>
<li><p>기계 학습 기술은 이러한 기술들이 제공하는 탁월한 예측 능력에 따라 5G를 지원하는 스마트 그리드 시스템에서 라디오 자원 할당의 최적화에 기여할 수 있다.</p></li>
</ul>
</section>
</section>
<section id="논문-정리-중-생략한-내용" class="level1">
<h1>논문 정리 중 생략한 내용</h1>
<ul>
<li><p>에지 컴퓨팅</p>
<ul>
<li>포그 컴퓨팅</li>
<li>모바일 에지 컴퓨팅</li>
<li>클라우드렛 컴퓨팅</li>
</ul></li>
</ul>
<p>정리하기.</p>
<p>전통적 방식은 - 단방향, passive - 수력, 화석연료 베이스</p>
<p>스마트 그리드는 - 양방향, 정보의 흐름 active - 재사용 가능한 에너지 베이스</p>
<ul>
<li>더 좋은 에너지 효율, 비용 효율, 적은 비용, 향상된 기능 등등 ..</li>
</ul>
<p>최근 몇 년간 스마트 그리드에 독보적인 문제에 접근하는 머신러닝 기반 기술 사용이 관측되는 트렌드</p>


</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/Paper/smartgrid1.html</guid>
  <pubDate>Thu, 18 Jan 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>2024 GIST-NVAITC Korea 강연 내용</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/etc/NVIDIA초청강연.html</link>
  <description><![CDATA[ 





<ul>
<li>TinyLlama
<ul>
<li>A compact 1.1B language model (↔︎ 거대 언어 모델) pretrained on around 1 trillion tokens for approximately 3 epochs.</li>
</ul></li>
<li>PEFT
<ul>
<li>PEFT: huggingface.co/docs/transformers/main/en/peft</li>
<li>Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware</li>
<li>문제점 1 : 모델이 점점 커짐에 따라 시판 그래픽카드로 모델 전체를 파인튜닝하는것은 불가능해져가고있다.</li>
<li>문제점 2 : 파인튜닝된 모델이 파인튜닝하기 이전의 사전학습된 모델과 똑같은 크기이기 때문에 파인튜닝된 모델을 사용하는 것 또한 (시간, 경제적으로) 비용이 많이 드는 일</li>
<li>대부분의 파라미터를 프리징하고 일부의 파라미터만을 파인튜닝함으로써 저장공간과 계산을 대폭 줄였다. 파인튜닝할때 발생하는 문제점 중 하나인 catastrophic forgetting 또한 극복</li>
<li>적은 데이터 체제(low-data-regime)에서 파인튜닝할때나 도메인 밖의 데이터(out-of-domain scenario)를 일반화할때 더욱 좋은 성능</li>
<li><strong>PEFT는 적은 수의 파라미터를 학습하는것만으로 모델 전체를 파인튜닝하는 것과 유사한 효과를 누릴 수 있도록 해준다.</strong></li>
</ul></li>
</ul>
<section id="library" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="library">Library</h3>
<ul class="page-columns page-full">
<li><p>bitsandbytes</p>
<ul>
<li>model을 8-bit 포맷으로 set up하여 큰 gpu가 필요하지 않음.</li>
<li>행렬 곱을 연산할 때 각 벡터를 독립적으로 처리하는 Vector-wise Quantization 방법을 적용하고 중요한 벡터는 16-bit로 표현하여 손실을 최소화 하는 등 8-bit와 16-bit를 혼용하는 기법을 통해 모델의 성능은 유지하면서 크기는 줄이는 성과를 보였다.</li>
</ul></li>
<li><p>accelerate</p>
<ul>
<li><p>기본 pytorch 코드를 통해 multi gpu를 사용하면 (DDP) 0번 gpu만 100% 사용되고 나머지 gpu는 예를 들어 60% 정도씩 덜 활용된다.</p>
<p>각 gpu에서 loss를 계산하고 각 결과를 합해서 최종 loss를 구해야 하는데 합하는 연산을 0번 device에서 하기 때문에 0번의 소모만 커지기 때문.</p>
<p>accelerate를 사용하면 이러한 문제를 해결할 수 있다.</p></li>
</ul></li>
<li><p>DeepSpeed</p>
<ul>
<li>스케일링 등을 통해 학습 속도를 가속화하는 라이브러리</li>
<li>floating point를 32에서 16으로 줄이는 등의 스케일을 적용하여 학습 속도를 줄이지만 성능이 저하된다. 예를 들어 하루종일 걸리는 학습을 30분 정도(stage 3)로 단축하지만 성능도 그만큼 감수해야 한다. 때문에 분류 문제처럼 acc가 중요한 문제에는 DeepSpeed를 덜 사용하거나 사용하지 않는게 좋고, 텍스트 생성모델처럼 정량적 평가가 크게 중요하지 않은 문제(정성적 평가의 비중이 큰 문제)에는 DeepSpeed를 써도 감수할 만 하다</li>
</ul></li>
<li><p>from transformers import pipeline</p>
<ul>
<li>여러 모델을 묶어준다.</li>
</ul>
<pre><code>pipe = pipeline("text-generation",
            model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
            torch_dtype=torch.bfloat16,
            device_map="auto")</code></pre></li>
<li class="page-columns page-full"><p>bf16: brainfloat16</p>
<ul>
<li>장점:넓은 수의 표현 범위 / 단점 : 표현 정밀도가 떨어지기 때문에 예를 들어 0에 가까운 수가 모조리 0으로 표현될 수 있음. 이 단점은 단지 숫자가 0이 되는것보다도 어떤 수를 0으로 나누는 상황이 생길 가능성을 높여서 문제이다.</li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://star77sa.github.io/posts/etc/NVIDIA초청강연_files/figure-html/cell-4-1-image.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">image.png</figcaption>
</figure>
</div></li>
<li><p>chatgpt guidance 공개 안해줌.</p></li>
<li><p>causal을 사용하기에 prompt를 유저에게 보여주지 않기 위해 삭제 replace(prompt, “”)</p></li>
<li><p>chatgpt에서는 사용자와의 대화 history까지 input으로 들어가 마치 기억하는 것처럼 보임. 여기서는 아니기 때문에 과거에 예시를 새로운 것으로 착각하여 중복된 output을 낼 가능성이 있음. 때문에 input을 할 때 token에 과거의 output을 넣어주어야 하는데 token에 넣을 수 있는 메모리가 가득 차면 더 이상 생성할 수 없는 limitation이 있음.</p></li>
<li><p>dp: import data_parallel as dp</p>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>DataParallel</th>
<th>DistributedDataParallel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>More overhead; model is replicated and destroyed at each forward pass</td>
<td>Model is replicated only once</td>
</tr>
<tr class="even">
<td>Only supports single-node parallelism</td>
<td>Supports scaling to multiple machines</td>
</tr>
<tr class="odd">
<td>Slower; uses multithreading on a single process and runs into Global Interpreter Lock (GIL) contention</td>
<td>Faster (no GIL contention) because it uses multiprocessing</td>
</tr>
</tbody>
</table></li>
<li><p>multi_node는 accelerater가 해줌.</p></li>
<li><p><strong>tinyllama로 peft를 켜서 모델을 생성 후 open dataset으로 실행 -&gt; instruction dataset으로 실행, dp, ddp 사용</strong></p></li>
<li><p>AICA, GIST, nipa 등 연구원 전용 지원 혜택 받기</p></li>
<li><p>colab은 multi gpu가 안됨</p></li>
<li><p>colab pro + peft정도면 논문에 쓸 데이터 정도는 학습 가능</p></li>
<li><p>파운데이션 모델 끝단 변경(파인튜닝) + AI로 데이터 생성 =&gt; 논문채택 ↑</p>
<ul>
<li>사전학습 X</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/etc/NVIDIA초청강연.html</guid>
  <pubDate>Tue, 16 Jan 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>데이터 과학</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/Statistics/데이터_분석.html</link>
  <description><![CDATA[ 





<section id="데이터-분석" class="level1">
<h1>데이터 분석</h1>
<ul>
<li>데이터 과학 : 데이터를 사용하여 질문에 합리적인 답을 내릴 수 있게 해주는 활동</li>
</ul>
<p>데이터 분석에 있어 기초통계, 선형모형(회귀·분산 분석 포함)은 제대로 배울 것을 권장.</p>
<p>중요한 요소 : 협업할 수 있는 태도, 소통능력, 폭넓은 독서(논픽션 양서)</p>
<p>데이터 획득 : UCI, 머신러닝 리포, 캐글, 위키피디아 데이터 세트 리스트 등…</p>
<p>분석 순서 : 데이터 취득·데이터 정리 → 탐색적 자료 분석 EDA : 시각화·기초통계량 계산(데이터의 패턴, 이상치 탐색) → 확증적 자료 분석 CDA : 통계적 가설·가설검정·신뢰구간(통계적 모형화 statistical modeling)</p>
<section id="통계" class="level2">
<h2 class="anchored" data-anchor-id="통계">통계</h2>
<ul>
<li><p>특별한 이유를 제외하고는 양측검정 하는 것이 좋다.</p></li>
<li><p>p-value가 크다는 것은 귀무가설에 반하는 증거가 불충분하다는 것이지 귀무가설을 증명하는 증거가 있다는 것이 아니다.</p></li>
<li><p>1종 오류 : 귀무가설을 잘못 기각</p></li>
<li><p>2종 오류 : 대립가설을 잘못 기각</p></li>
<li><p>“유의수준 5%에서 유의하다” 라고만 하지말고 p-value 그 자체의 값도 알려야 한다.</p></li>
<li><p>모수는 상수다.(빈도주의자 관점)</p></li>
<li><p><code>높은 p-value를 귀무가설이 옳다는 증거로 이해하는 오류</code> : 높은 p-value는 대립가설을 입증하는 증거가 불충분함을 의미한다. 효과가 아주 강해도 데이터 관측치가 적으면 p-value가 높을 수 있다. 즉, 높은 p-value는 증거/데이터 불충분으로 이해해야 한다.</p></li>
<li><p><code>낮은 p-value가 항상 의미있다고 이해하는 오류</code> : 만약 표본크기가 너무 크고, 표본평균의 증가값 자체가 너무 적다면 낮은 p-value 자체로는 의미가 없다.</p></li>
<li><p>95% 신뢰구간의 정의 : 같은 모형에서 반복해서 표본을 얻고 신뢰구간을 얻을 때 신뢰구간이 참 모수값을 포함할 확률이 95%가 되도록 만들어진 구간</p></li>
<li><p>중심극한정리 : 어떤 분포든 표본평균은 대략 종모양을 따른다. 정규분포에 기반.</p></li>
<li><p>95% 신뢰구간의 크기는 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7D"> 이다. 즉, 표본의 크기가 커지면 커질수록 신뢰구간의 크기는 줄어들고 그 줄어드는 속도는 <img src="https://latex.codecogs.com/png.latex?%5Csqrt%7Bn%7D"> 이다.</p></li>
</ul>
<section id="통계-인터뷰-질문" class="level3">
<h3 class="anchored" data-anchor-id="통계-인터뷰-질문">통계 인터뷰 질문</h3>
<ul>
<li>p-value를 정의하라 : 귀무가설 하에서, 관찰된 통계량만큼 극단적인 값이 관찰될 확률</li>
<li>비전문가들이 이해하기 쉽게 p-value를 설명하라.</li>
</ul>
<hr>
</section>
<section id="모집단-모수-표본" class="level3">
<h3 class="anchored" data-anchor-id="모집단-모수-표본">모집단, 모수, 표본</h3>
<ul>
<li><p>모집단(population) : 데이터가 (랜덤하게) 표본화되었다고 가정하는 분포/집단</p></li>
<li><p>모수(population parameter) : 모집단을 정의하는 값을 모르는 상수</p></li>
<li><p>표본(sample) : 모집단으로부터 (랜덤하게) 추출된 일부 관측치</p></li>
<li><p>통계량(statistics) : 모수를 추정하기 위해 데이터로부터 계산된 값</p></li>
<li><p>귀무가설(null hypothesis) : 모수에 대한 기존(status quo)의 사실 혹은 디폴트 값</p></li>
<li><p>대립가설(alternative hypothesis) : 모수에 대해 귀무가설과 대립하여 증명하고 싶은 사실</p></li>
<li><p>가설검정(hypothesis testing) : 통계량을 사용해 귀무가설을 기각하는 절차</p></li>
<li><p>타입 1 오류(Type 1 error) : 가설검정 절차가 참인 귀무가설을 기각하는 사건</p></li>
<li><p>타입 2 오류(Type 2 error) : 가설검정 절차가 거짓인 귀무가설을 기각하지 않는 사건</p></li>
<li><p>유의수준(significance level) : 타입 1 오류를 범할 확률의 허용치</p></li>
<li><p>P-value : 만약 귀무가설이 참일 때 데이터가 보여준 정도로 특이한 값이 관측될 확률</p></li>
<li><p>더미 변수 : 통계 및 회귀 분석에서 사용되는 용어. 범주형 데이터를 처리하거나 특정 변수의 상태를 나타내기 위해 사용되는 가상의 이진 변수. 일반적으로, 머신 러닝 모델이나 통계 모델은 숫자형 데이터를 다루는 데 효과적. 그러나 범주형 데이터(예: 성별, 국적, 색상 등)는 이진 변수로 변환해야 한다. 이를 위해 더미 변수를 사용. 더미 변수는 원래 범주형 변수의 각 범주에 대해 0 또는 1의 값을 가지는 새로운 이진 변수. 예를 들어, 성별이라는 범주형 변수가 있을 때, 이를 더미 변수로 나타내려면 남성인 경우에는 1로, 여성인 경우에는 0으로 표현하거나 그 반대로 할 수 있다. 더미 변수를 사용하면 범주형 데이터를 포함한 모델에서 계산이 용이해지며, 해당 변수가 모델에 미치는 영향을 측정할 수 있다. 또한, 더미 변수를 사용함으로써 모델이 범주 간의 상대적인 영향을 학습할 수 있다.</p></li>
<li><p>t값 : <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cbar%7Bx%7D-%5Cmu_0%7D%7B%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D%7D"></p></li>
<li><p>PCA : 주성분 분석(Principal Component Analysis, PCA)는 다차원 데이터를 저차원으로 차원 축소하는 기술 중 하나다. 주로 데이터의 분산을 최대한 보존하면서 차원을 축소하는 데 사용된다. PCA의 목표는 데이터의 주성분(principal components)을 찾는 것인데, 주성분은 데이터의 분산이 최대가 되도록 하는 방향이 된다. 즉, 첫 번째 주성분은 데이터의 분산이 가장 큰 방향이며, 두 번째 주성분은 첫 번째 주성분과 직교하면서 데이터의 분산을 최대한 보존하는 방향이 된다. 이런 식으로 주성분은 데이터의 분산을 차례로 최대화하는 방향으로 정의된다. PCA를 통해 얻은 주성분들은 기존 변수들의 선형 조합으로 표현된다. 이를 통해 데이터를 표현하는 데 필요한 변수의 수를 줄일 수 있다. 이는 차원 축소의 효과를 가져오며, 중요한 정보를 유지하면서 데이터의 복잡성을 낮춘다. PCA는 주로 데이터 시각화, 노이즈 제거, 특성 추출 등 다양한 분야에서 활용된다. 또한, 다중공선성 문제를 해결하거나 머신러닝 모델의 학습 속도를 향상시키는 데에도 사용될 수 있다.</p></li>
<li><p>랜덤 변수(Random Variable)는 확률적인 실험 또는 현상의 결과를 수치적으로 나타내는 변수를 의미한다. 랜덤 변수는 표본 공간의 각 원소를 실수 값으로 매핑하는 함수로 정의되며, 확률 분포에 따라 그 값을 취합니다. 랜덤 변수는 확률 이론과 통계학에서 핵심 개념 중 하나이며, 확률 분포를 통해 랜덤 변수의 특성과 동작을 설명하고 예측하는 데 사용된다. 확률 변수를 이용하면 확률적인 현상을 수학적으로 모델링하고, 이를 통해 다양한 통계적 추론 및 예측을 수행할 수 있다.</p></li>
<li><p>랜덤프로세스 : 확률 변수의 시퀀스 또는 함수로, 시간 또는 공간에 따라 확률적으로 변하는 프로세스를 나타낸다. 랜덤 프로세스는 시간에 따른 랜덤한 변동을 모델링하거나 시공간에서의 랜덤한 현상을 분석하는 데 사용된다. 이는 확률론과 통계학, 시계열 분석, 통신 이론, 제어 이론 등 다양한 분야에서 응용된다.</p>
<p>랜덤 프로세스는 다음과 같은 주요 특징을 갖는다:</p>
<ul>
<li><p>확률 변수의 집합: 랜덤 프로세스는 각각의 시간 또는 위치에 대해 하나 이상의 확률 변수를 갖는다. 이 확률 변수들은 시간 또는 위치에 따라 변하는 값들을 나타낸다.</p></li>
<li><p>시간 또는 위치의 집합: 랜덤 프로세스는 정의된 시간 또는 위치의 집합에서 정의된다. 시간의 경우, 이를 시계열(random time series)이라고 부르기도 한다.</p></li>
<li><p>확률 분포의 변화: 랜덤 프로세스의 특정 시간 또는 위치에서의 값은 확률 분포를 따른다. 이 분포는 시간이나 위치에 따라 변할 수 있다.</p></li>
</ul>
<p>랜덤 프로세스의 예시로는 브라운 운동(Brownian motion), 마코프 체인(Markov chain), 확률 과정(Stochastic process) 등이 있다. 이러한 랜덤 프로세스는 자연 현상, 금융 모델링, 통신 시스템 등에서 모델링과 분석에 활용된다.</p></li>
<li><p>포아송 프로세스 :</p></li>
<li><p>포아송 어라이블 :</p></li>
<li><p>마르코프 과정 :</p></li>
<li><p>정보이론 :</p></li>
<li><p>신호 및 시스템 :</p></li>
<li><p>표준화(Standardization) : 표준화는 데이터의 평균을 0으로, 표준 편차를 1로 만드는 변환을 의미. 표준화된 값은 Z 점수 또는 표준 점수로 불리며 다음의 공식으로 계산 <img src="https://latex.codecogs.com/png.latex?z=%5Cfrac%7Bx-%5Cmu%7D%7B%5Csigma%7D"></p></li>
<li><p>정규화(Normalization) : 정규화는 데이터의 범위를 [0, 1] 또는 [-1, 1]로 조정하는 변환을 의미. Min-Max 정규화는 가장 일반적인 형태로 다음의 공식으로 계산 <img src="https://latex.codecogs.com/png.latex?x_%7Bnormalized%7D%20=%20%5Cfrac%7Bx-%5Cmin(X)%7D%7B%5Cmax(X)-%5Cmin(X)%7D"> 정규화는 다양한 변수 간의 스케일을 맞추어줌으로써 경사 하강법과 같은 최적화 알고리즘의 수렴 속도를 향상시키고, 학습 과정을 안정화 시킨다.</p></li>
</ul>
<p>*** <code>표준 정규 분포에서 정규와 정규화는 관련이 없음.. 정규분포인 데이터에 표준화를 해주면 그게 표준 정규분포!! 표준정규분포 = 평균이 0이고 표준편차가 1인 정규분포</code></p>
<ul>
<li><p>중심 극한 정리 :</p></li>
<li><p>부트스트랩 : 부트스트랩(Bootstrap)은 통계학과 머신 러닝에서 사용되는 샘플링 방법 중 하나로, 주어진 데이터로부터 중복을 허용하여 샘플을 추출하는 과정을 말한다. 일반적으로 데이터셋에서 일부를 무작위로 추출하는 과정에서는 원래 데이터셋에 존재하는 정보의 일부가 누락될 수 있다. 부트스트랩은 이러한 문제를 완화하기 위해 중복을 허용하여 여러 번의 샘플링을 수행한다.</p></li>
<li><p>iid(Independent and Identically Distributed) : 독립 동일 분포. 통계적 가정과 머신러닝 모델의 일부에서 사용된다. 예를 들어, 통계적 가설 검정에서 독립 동일 분포 가정은 검정 결과의 신뢰성을 보장하는 데 중요하다. 머신러닝에서는 iid 가정이 모델의 일반화 성능을 평가하는 데 사용된다. 훈련 데이터셋과 테스트 데이터셋이 iid를 만족한다면, 모델이 새로운 데이터에 대해 더 잘 일반화될 것으로 기대할 수 있다.</p>
<ul>
<li>Independent : 데이터 샘플들이 서로 독립적. 하나의 데이터 포인트나 관측치가 다른 것과 상관없이 독립적으로 발생했다는 것을 나타낸다. 예를 들어, 동일한 데이터셋에서 뽑은 두 개의 관측치는 서로 영향을 주지 않고 독립적으로 존재한다.</li>
<li>Identically Distributed : 데이터 샘플들이 같은 확률 분포에서 추출되었다는 것을 의미한다. 모든 데이터 포인트가 동일한 특성을 가지며, 동일한 확률 분포를 따르는 것을 의미한다.</li>
</ul></li>
<li><p>통계적 패턴인식 : 데이터에서 통계적 구조나 패턴을 추출하고 이를 활용하여 패턴을 인식하거나 분류하는 기술. 이는 주로 통계학, 머신 러닝, 인공 지능 분야에서 활용되며, 다양한 응용 분야에서 패턴을 감지하고 이해하는 데 사용된다.</p></li>
<li><p>Class imbalance를 고려한 모델 학습 방법 (Chat-GPT 답변)</p>
<ul>
<li>가중치 조절 : 적은 수의 클래스에 대해 더 높은 가중치를 부여하여 모델이 이러한 클래스에 더 집중하도록 유도</li>
<li>샘플링 기법 : 1. Under-sampling 다수 클래스의 데이터를 일부 제거하여 클래스간의 균형을 맞춘다. 하지만 정보 손실이 발생할 수 있다. // 2. Over-sampling 소수 클래스의 데이터를 복제하거나 합성하여 데이터를 늘린다. SMOTE(Synthetic Minority Over-sampling Technique)와 같은 기술을 사용할 수 있다.</li>
<li>앙상블 방법 : 다양한 모델을 조합하여 앙상블을 형성하는 것도 클래스 불균형을 해소하는데 도움이 될 수 있다. 예를 들어, 다수결 투표를 통해 예측을 결합할 수 있다.</li>
<li>평가 지표의 선택 : 정확도(accuracy)만을 평가 지표로 사용하지 말고, 클래스 불균형을 고려한 평가 지표를 선택. 정밀도(precision), 재현율(recall), F1-score 등이 유용할 수 있다.</li>
<li>다단계 학습(?) : 다단계 분류기를 사용하여 클래스 간의 계층적인 학습을 수행할 수 있다. 이를 통해 클래스 간의 계층 구조를 고려할 수 있다.</li>
<li>클래스 가중치 설정 : 일부 모델은 클래스에 대한 가중치를 설정할 수 있는 매개변수를 제공한다. 이를 조절하여 클래스 불균형을 고려할 수 있다.</li>
<li>사전 훈련된 모델 사용 : 사전 훈련된 모델을 사용하여 초기 가중치를 설정하면 클래스 불균형에 민감한 초기화 문제를 완화할 수 있다.</li>
<li>클래스 결합 : 비슷한 클래스를 하나로 결합하거나, 다수 클래스의 몇 개를 합쳐서 클래스의 수를 줄일 수도 있다.</li>
<li>전이학습</li>
<li>데이터 증강</li>
</ul></li>
<li><p>다단계 분류기(multi-class classifier) : 데이터를 둘 이상의 클래스로 분류하는 머신러닝 모델. 일대일/일대다/다중출력분류</p></li>
<li><p>SQL</p></li>
<li><p>유닉스 쉘</p></li>
<li><p>파이썬 코딩 스타일 : PEP 0008 (도움을 주는 pylint)</p></li>
<li><p>정보이론, 엔트로피</p></li>
<li><p>평가지표</p></li>
<li><p>손실함수</p></li>
<li><p>한계효용체감</p></li>
<li><p>Gapminder(http://www.gapminder.org/) :스웨덴의 비영리 통계 분석 서비스. 틈새주의(mind the gap)라는 지하철 경고문에서 영감을 얻은 이름은 세계관과 사실/데이터 간의 간극을 조심하고 좁히자는 이상을 반영</p></li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/Statistics/데이터_분석.html</guid>
  <pubDate>Wed, 10 Jan 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>논문 읽다가 모르는 영단어 정리</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/etc/논문_영단어.html</link>
  <description><![CDATA[ 





<section id="영단어" class="level3">
<h3 class="anchored" data-anchor-id="영단어">영단어</h3>
<p><code>stimuli</code> 자극</p>
<p><code>intermittent</code> 간헐적</p>
<p><code>countermeasures</code> 대책</p>
<p><code>diffusion</code> 어떤 현상이나 개념이 시간이 지남에 따라 널리 퍼져나가거나 확산되는 과정</p>
<p><code>encompass</code> 포함하다</p>
<p><code>hence</code> 이런 이유로</p>
<p><code>massive</code> 거대한</p>
<p><code>inadequacy</code> 불충분함</p>
<p><code>extrapolate</code> 추론하다</p>
<p><code>exploitation</code> 착취, (부당한)이용, 개발</p>
<p><code>resilience</code> 회복력, 탄력, 복원력</p>


</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/etc/논문_영단어.html</guid>
  <pubDate>Sun, 31 Dec 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>논문 읽다가 모르겠거나 복습할 개념 정리</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/etc/논문_개념.html</link>
  <description><![CDATA[ 





<section id="성능-평가-지표-정리" class="level1">
<h1>성능, 평가 지표 정리</h1>
<p>AUC</p>
<p>ROC Curve</p>
<p>precision - recall</p>
</section>
<section id="개념-정리-2" class="level1">
<h1>개념 정리 2</h1>
<p>SMOTE</p>
<hr>
<p><code>시멘틱 커뮤니케이션</code></p>
</section>
<section id="machine-learning-driven-smart-electric-power-system-current-trends-and-new-perspectives2020" class="level1">
<h1>Machine learning driven smart electric power system: Current trends and new perspectives(2020)</h1>
<section id="challenge" class="level2">
<h2 class="anchored" data-anchor-id="challenge">challenge</h2>
<ul>
<li><p>load forecast</p>
<ul>
<li>short-term load forecasting</li>
<li>general (medium-term, long-term) load forecasting</li>
</ul></li>
<li><p>electricity price forecast</p></li>
<li><p>renewable power generation prediction</p></li>
<li><p>fault and failure analysis</p></li>
<li><p>demand-side management(DSM)</p></li>
<li><p>non-intrusive load monitoring(NILM)</p></li>
<li><p>NIALM(Non-intrusive appliance load monitoring)</p></li>
<li><p>electricity theft detection</p></li>
<li><p>islanding detection</p></li>
</ul>
<p><code>방법론</code> - Bayesian Methods - HMM(Hidden Markov model) - Q-learning - DBN</p>
<ul>
<li>LASSO</li>
<li>LDA(Linear discriminant analysis)</li>
<li>MDA(Multiple discriminant analysis)</li>
<li>QDA(Quadratic discriminant analysis)</li>
<li>KNN</li>
<li>LSTM</li>
<li>MAPE(Mean absolute percentage error)</li>
</ul>
<p><strong>network</strong> - BPNN(Back propagation neural network) - FFNN(Feed Forward neural network) - RBFNN(Radial basis function neural network) - DBN(Deep belief network)</p>
<p><strong>Boltzmann machine</strong> 볼츠만이 계속 나오네 확인해볼것 - CRBM(Conditional restricted Boltzmann machine) - DBM(Deep Boltzmann machine) - FCRBM(Factored conditional resticted Boltzmann machine) - RBM(Restricted Boltzmann machine)</p>
<hr>
<ul>
<li><p>ELM(Extreme learning machine)</p></li>
<li><p>LSM(Liquid state machine)</p></li>
<li><p>FDI(False data injection)</p></li>
<li><p>GRU(Gated recurrent unit)</p></li>
<li><p>MARS(Multivariate adaptive regression splines)</p></li>
<li><p>PICP(Prediction interval coverage probability)</p></li>
<li><p>PINC(Prediction interval nominal confidence)</p></li>
<li><p>PSO(Particle swarm optimization)</p></li>
<li><p>SAE(Stacked auto-encoder)</p></li>
<li><p>SVR(Support vector regression)</p></li>
<li><p>ACE(Average coverage error)</p></li>
<li><p>AMI(Advanced metering infrastructure)</p></li>
<li><p>AC(Alternating current), DC(Direct current) system</p></li>
<li><p>DG(distributed generation)</p></li>
<li><p>PV(photovoltic)</p></li>
<li><p>5G (+6G?)</p></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/etc/논문_개념.html</guid>
  <pubDate>Sun, 31 Dec 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>통계 101 X 데이터분석</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/Statistics/통계_101_X_데이터_분석.html</link>
  <description><![CDATA[ 





<p><img src="https://star77sa.github.io/posts/Statistics/image.png" class="img-fluid"></p>
<section id="통계학이란" class="level1">
<h1>1. 통계학이란?</h1>
<section id="데이터를-분석하다" class="level2">
<h2 class="anchored" data-anchor-id="데이터를-분석하다">1.1 데이터를 분석하다</h2>
<ul>
<li>데이터 분석의 목적</li>
</ul>
<ol type="1">
<li>데이터를 <strong>요약</strong>하는 것</li>
<li>대상을 <strong>설명</strong>하는 것</li>
<li>새로 얻을 데이터를 <strong>예측</strong>하는 것</li>
</ol>
<ul>
<li><p>인과관계 : 2가지 중 하나(원인)을 변화시키면, 다른 하나(결과)도 바꿀 수 있는 관계. 인과관계를 알면 곧 원리(메커니즘)에 관한 지식을 얻는 것이기에 깊은 이해라고 할 수 있다.</p></li>
<li><p>상관관계 : 한쪽이 크면 다른 한쪽도 큰(또는 한쪽이 크면 다른 한쪽은 작은) 관계를 말한다. 한쪽을 ’변화시켰다’하더라도 다른 한쪽이 ’변한다’고 단정할 수 없다는 점에서 인과관계와 다르다. 원리에 관련된 몇 가지 가능성을 구별할 수 없으므로, 얕은 이해라 할 수 있다.</p></li>
<li><p>선형관계에는 사람이 다루기 쉽고, 해석하기도 쉽다는 특징. 한편, 해석이 어려운 복잡한 관계를 추출하고 예측하는 <strong>기계학습</strong>이란 방법도 있다.(12장)</p></li>
</ul>
</section>
<section id="통계학의-역할" class="level2">
<h2 class="anchored" data-anchor-id="통계학의-역할">1.2 통계학의 역할</h2>
<ul>
<li>통계학은 데이터 퍼짐 정도가 클수록 힘을 발휘한다.</li>
<li>데이터 분석에서 통계학의 중요한 역할은, <strong>퍼짐(산포, dispersion)</strong> 이 있는 데이터에 대해 설명이나 예측을 하는 것.</li>
<li>통계학은 이러한 데이터 퍼짐을 ’불확실성’이라 평가하고, 통계학의 목적인 ’대상의 설명과 예측’을 수행</li>
<li>통계학은 데이터 퍼짐이나 불확실성에 대처하는 방법을 제공. 그 근거가 되는 것이 데이터 퍼짐이나 불확실성을 확률로 나타내는 <strong>확률론</strong>이다.</li>
</ul>
</section>
<section id="통계학의-전체-모습" class="level2">
<h2 class="anchored" data-anchor-id="통계학의-전체-모습">1.3 통계학의 전체 모습</h2>
<p><code>-</code> 기술통계와 추론통계</p>
<ul>
<li><p><strong>기술통계(descriptive statistics)</strong> : 수집한 데이터를 정리하고 요약하는 방법. 확보한 데이터에만 집중하면서, 데이터 자체의 성질을 이해하는 것을 목표로 한다는 점에 주의.</p></li>
<li><p><strong>추론통계(inferential statistics)</strong> : 수집한 데이터로부터 데이터의 발생원을 추정하는 방법</p></li>
</ul>
<p><code>-</code> 통계적 추론과 가설검정</p>
<p>추론통계는 크게 2가지가 있다.</p>
<ol type="1">
<li><p>통계적 추론(statistical inference) : 데이터에서 가정한 확률 모형의 성질을 추정하는 방법. 예를 들어, 모서리가 닳아버린 주사위라면 각 눈이 나올 확률이 1/6이 아닐지도 모른다. 이럴 때 통계적 추론을 이용하여, 얻은 데이터로부터 각 눈이 어떤 확률로 나오는 주사위인가를 추정할 수 있다.</p></li>
<li><p>가설검정(statistical test) : 세운 가설과 얻은 데이터가 얼마나 들어맞는지를 평가하여, 가설을 채택할 것인가를 판단하는 방법</p></li>
</ol>
<hr>
</section>
</section>
<section id="모집단과-표본" class="level1">
<h1>2. 모집단과 표본</h1>
<section id="데이터-분석의-목적과-알고자-하는-대상" class="level2">
<h2 class="anchored" data-anchor-id="데이터-분석의-목적과-알고자-하는-대상">2.1 데이터 분석의 목적과 알고자 하는 대상</h2>
<ol type="1">
<li>데이터 분석의 목적을 정하기.</li>
<li>알고자 하는 대상을 명확히 하기.</li>
</ol>
</section>
<section id="모집단" class="level2">
<h2 class="anchored" data-anchor-id="모집단">2.2 모집단</h2>
<ul>
<li>모집단 : 알고자 하는 대상 전체</li>
</ul>
<p>‘지금 알고자 하는 대상은 무엇인지’, ’무엇을 모집단으로 설정할 것인지’의 문제에는 항상 주의를 기울여야 한다.</p>
<ul>
<li>유한모집단</li>
<li>무한모집단</li>
</ul>
</section>
<section id="모집단의-성질을-알다" class="level2">
<h2 class="anchored" data-anchor-id="모집단의-성질을-알다">2.3 모집단의 성질을 알다</h2>
<ul>
<li>모집단은 데이터 분석에서 알고자 하는 대상 전체를 가리키기 때문에, <strong>모집단의 성질</strong>을 알 수 있다면 대상을 설명하거나 이해할 수 있고, 미지의 데이터를 예측할 수도 있게 된다.</li>
<li>모집단의 성질이란, 다음과 같이 모집단에 포함된 요소를 특징 짓는 값이다.</li>
</ul>
<ol type="1">
<li>한국인 남성의 평균 키는 172.5cm이다.</li>
<li>한국인 여성의 평균 키는 159.6cm이다.</li>
<li>신약을 복용한 사람의 최고 혈압 평균은 120mmHg이다.</li>
<li>이 주사위는 모든 눈이 균등하게 나온다.</li>
<li>이 주사위는 6의 눈이 1/4 확률로 나온다.</li>
</ol>
<ul>
<li>그렇다면 이러한 모집단의 성질을 알기 위해서는 어떻게 해야 할까?</li>
</ul>
<p><code>-</code> 전수조사 : 모집단에 포함된 모든 요소를 조사</p>
<ul>
<li><p>모집단에 포함된 요소의 개수가 한정된, 유한모집단일 때 선택할 수 있는 조사 방법.</p></li>
<li><p>전수조사의 경우 ‘분석할 데이터 = 모집단’. 그러므로 획득한 데이터의 특징을 파악하고 기술하기만 해도, 모집단의 성질을 설명하고 이해할 수 있다.</p></li>
<li><p>전수조사의 어려움 : 비용이나 시간 면에서 부담이 막대하여 실현 불가능할 때가 대부분.</p></li>
</ul>
<p><code>-</code> 표본조사 : 모집단의 일부를 분석하여 모집단 전체의 성질을 추정하는 <strong>추론통계(inferential statistics)</strong> 라는 분야가 있으며, 이것이야말로 통계학의 참모습이라 할 수 있다.</p>
<ul>
<li><p>표본(sample) : 추론통계에서 조사하는 모집단의 일부</p></li>
<li><p>표본추출(sampling) : 모집단에서 표본을 뽑는 것</p></li>
<li><p>표본조사 : 표본을 이용해 모집단의 성질을 조사하는 것</p></li>
</ul>
<p>표본을 통해 모집단의 성질을 알 수 있는 잘 알려진 방법으로, 선거 출구조사를 들 수 있다. 일부의 표만으로도 당선확실 여부를 알 수 있다.</p>
<p>추론통계는 ’추론’이라는 말에서 알 수 있듯이 모집단의 성질을 100% 알아맞힐 수는 없으며, 어느 정도 불확실성을 염두에 두고 평가하게 된다.</p>
<ul>
<li><p>대상을 설명(이해)하고 예측하기 위해서는 모집단의 성질을 알아야 한다.</p></li>
<li><p>일반적으로 모집단을 대상으로 한 전수조사는 어렵다.</p></li>
<li><p>표본을 조사하면 모집단의 성질을 추정할 수 있다.</p></li>
<li><p>표본크기 : 표본에 포함된 요소의 개수를 표본크기(sample size)라 부르며, 보통 알파벳 <img src="https://latex.codecogs.com/png.latex?n">으로 나타낸다. 예를 들어 표본으로 30개를 추출했다면, <img src="https://latex.codecogs.com/png.latex?n">=30이라 표기한다.</p></li>
<li><p>통계학에서 샘플 수라고 하면 표본의 개수를 뜻한다. 예를 들어 20명으로 이루어진 표본A와 이와 별개로 30명으로 이루어진 표본B가 있는 경우, 표본은 A, B 2개이므로 샘플 수는 2가 된다. 이처럼 표본크기와 표본의 개수는 혼동하기 쉬우므로 주의.</p></li>
<li><p>표본크기는 모집단의 성질을 추정할 때의 확실성이나 가설검정의 결과에도 영향을 끼치기 때문에, 통계분석에 있어 중요한 요소 중 하나.</p></li>
</ul>
<hr>
</section>
</section>
<section id="통계분석의-기초" class="level1">
<h1>3. 통계분석의 기초</h1>
<section id="데이터-유형" class="level2">
<h2 class="anchored" data-anchor-id="데이터-유형">3.1 데이터 유형</h2>
<p><code>-</code> 모집단과 표본</p>
<p><code>-</code> 변수 : 데이터 중 공통의 측정 방법으로 얻은 같은 성질의 값</p>
<p>예를 들어, 키는 하나의 변수이다. 변수는 각각 다른 값을 취할 수 있으므로 변수라고 불린다.</p>
<p>변수가 여러 개인 경우, 변수 간의 관계를 밝히고자 데이터를 분석할 수 있다.</p>
<p>통계학에서 변수의 개수는 ’차원’이라 표현되기도 한다.</p>
<p>여러 개의 변수를 포함한 데이터는 ’고차원 데이터’라 한다.</p>
<p><code>-</code> 다양한 데이터 유형</p>
<p>변수의 유형마다 분석 방법이 달라지기 때문에, 데이터를 수집할 때나 분석을 실행할 때는 변수가 어떤 유형인지 주의 깊게 고려하는 것이 중요</p>
<ol type="1">
<li>양적 변수 (수치형 변수)</li>
</ol>
<p>수치로 나타낼 수 있는 변수를 양적 변수라 한다. 양적 변수는 다시 이산형과 연속형으로 나눌 수 있다.</p>
<ul>
<li>이산형</li>
</ul>
<p>얻을 수 있는 값이 점점이 있는 변수를 <strong>이산형 양적 변수(이산변수)</strong> 라 한다. ex) 주사위의 눈은 나오는 값이 1부터 6까지의 정수</p>
<ul>
<li>연속형</li>
</ul>
<p>키 173.4cm나 몸무게 65.8kg 같이 간격 없이 이어지는 값으로 나타낼 수 있는 변수를 <strong>연속형 양적 변수 (연속변수)</strong> 라 한다.</p>
<p>이는 정밀도가 높은 측정 방법을 이용하면, 원리상으로는 소수점 아래 몇 자리든 나타낼 수 있다는 점에서 이산형과는 다르다.</p>
<p>이산형과 연속형의 차이점은 확률분포의 종류와 밀접한 관계가 있으므로, 데이터를 다룰 때는 주의</p>
<ol start="2" type="1">
<li>질적 변수 (범주형 변수)</li>
</ol>
<p>숫자가 아닌 범주로 변수를 나타낼 때, 이를 질적 변수 또는 범주형 변수라 한다. ex) 설문조사의 예/아니오, 동전의 앞/뒤</p>
<p>숫자인 양적 변수와 달리, 변수 사이에 대소 관계는 없다.</p>
<p>또한 범주형 변수는 숫자가 아니므로, 평균값 등의 수치 역시 정의할 수 없다.</p>
</section>
<section id="데이터-분포" class="level2">
<h2 class="anchored" data-anchor-id="데이터-분포">3.2 데이터 분포</h2>
<p><code>-</code> 그림으로 데이터 분포 표현하기</p>
<p>’데이터가 어떻게 분포되어 있는지’를 그래프 등으로 시각화하여, 대략적인 데이터 경향을 파악하는 것이 데이터 분석의 첫 단계</p>
<p>데이터 분포를 그림으로 나타내는 데는 어떤 값이 데이터에 몇 개 포함되어 있는가(도수, 빈도, 횟수)를 나타내는 그래프인 <strong>도수분포도(히스토그램)</strong> 를 자주 사용</p>
<p><code>-</code> 히스토그램은 그림으로 나타낸 것일 뿐</p>
<p>히스토그램은 대략적인 데이터 구성을 파악하는 것이 목적이지, 무엇인가 결론을 내기 위한 것이 아니라는 점을 명심</p>
</section>
<section id="통계량" class="level2">
<h2 class="anchored" data-anchor-id="통계량">3.3 통계량</h2>
<p><code>-</code> 데이터 특징 짓기</p>
<p>수집한 데이터로 이런저런 계산을 수행하여 얻은 값을 일반적으로 <strong>통계량</strong> 이라 한다.</p>
<p>데이터 그 자체의 성질을 기술하고 요약하는 통계량을, <strong>기술통계량</strong> 또는 <strong>요약통계량</strong> 이라 부른다.</p>
<ul>
<li>통계량과 정보</li>
</ul>
<p>1개 또는 몇 개의 통계량으로 요약한다는 것은, 데이터에 있는 정보 중 버리는 부분이 있다는 것을 뜻한다. 예를 들어 평균값에는 ’어느 정도 데이터가 퍼져 있는지’의 정보는 포함되지 않습니다. 다른 예로 데이터에 포함된 가장 큰 값인 최댓값도 하나의 통계량이지만 여기에는 데이터 전체의 경향을 알 수 있는 정보가 없다. 이처럼 최댓값은 분포의 중심 위치나 분포 형태에 관한 정보가 주어지지 않으므로, 분포를 파악하는 데는 적합한 통계량이 아니다.</p>
<p><code>-</code> 다양한 기술통계량</p>
<p>대략적인 분포 위치를 나타내는 대푯값 : 평균값, 중앙값, 최빈값</p>
<p>데이터 퍼짐 정도를 나타내는 값 : 분산, 표준편차</p>
<ul>
<li>평균값(mean)</li>
</ul>
<p>표본의 평균값은 표본에서 얻었다는 점에서 ’표본평균’이라고도 한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbar%7Bx%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D(x_1+x_2+...+x_n)%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum%5En_%7Bi=1%7D%20x_i%20"></p>
<p>평균값은 계산 시 모든 값을 고려하기 때문에 이상값의 영향을 받기 쉽다는 특징이 있다.</p>
<ul>
<li>중앙값(median)</li>
</ul>
<p>‘크기 순으로 값을 정렬했을 때 한가운데 위치한 값’</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 홀수라면 가운데 값은 1개이므로 이 값이 중앙값이다. 한편 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 짝수일 때는 가운데에 있는 값이 2개이므로, 두 값의 평균값을 중앙값으로 한다.</p>
<p>중앙값은 수치 자체의 정보가 아닌 순서에만 주목하기에, 극단적으로 크거나 작은 값이 있어도 영향을 받지 않는다는 특징이 있다.</p>
<ul>
<li>최빈값(mode)</li>
</ul>
<p>‘데이터 중 가장 자주 나타나는 값’</p>
<p>처음에 히스토그램을 그려 대략적인 파악을 한 다음, 대푯값으로 적절하게 분포를 특징 지을 수 있는지 확인하는 것이 중요한 데이터 분석 작업 순서라는 점을 꼭 기억</p>
<p><code>-</code> 분산과 표준편차</p>
<p>데이터 퍼짐을 평가하기 위해서는 <strong>분산(variance)</strong> 혹은 <strong>표준편차(standard deviation, S.D.)</strong> 라는 통계량을 계산.</p>
<p>표본에서 구하고, 표본을 평가한다는 점을 강조하여 ’표본분산(sample variance)’이나 ’표본표준편차(sample standard deviation)’라 부르기도 한다.</p>
<p><strong>표본분산</strong> 은 표본의 각 값과 표본평균이 어느 정도 떨어져 있는지를 평가하는 것으로, 데이터 퍼짐 상태를 정량화한 통계량이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20s%5E2%20=%20%5Cfrac%7B1%7D%7Bn%7D%5C%7B(x_1-%5Cbar%7Bx%7D)%5E2%20+%20(x_2-%5Cbar%7Bx%7D)%5E2+...+(x_n-%5Cbar%7Bx%7D)%5E2%5C%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum%5En_%7Bi=1%7D(x_i-%5Cbar%7Bx%7D)%5E2%20"></p>
<ul>
<li>표본분산의 성질</li>
</ul>
<ol type="1">
<li><p><img src="https://latex.codecogs.com/png.latex?s%5E2%20%5Cgeqq%200"></p></li>
<li><p>모든 값이 같다면 0</p></li>
<li><p>데이터 퍼짐 정도가 크면 <img src="https://latex.codecogs.com/png.latex?s%5E2">이 커짐</p></li>
</ol>
<p>표본표준편차 <img src="https://latex.codecogs.com/png.latex?s">는, 이 표본분산의 제곱근을 취한 값이다.</p>
<p>계산상 분산과 표준편차에는 제곱근인지 아닌지의 차이만 있으며, 포함하는 정보에는 차이가 없다. 분산 단위는 원래 값 단위의 제곱이 되지만, 표준편차는 제곱근을 취하므로 원래 단위와 일치한다. 따라서 데이터 퍼짐 정도를 정량화한 지표로는 표준편차 쪽이 감각적으로 더 알기 쉽게 느껴진다.</p>
<p><code>-</code> 분산을 확인할 수 있는 상자 수염 그림</p>
<p>이름처럼 상자와 수염으로 구성되며, 각각은 데이터의 분포를 특징 짓는 통계량을 나타낸다.</p>
<p>제1 사분위수(Q1) : 데이터의 25%가 이 값보다 작거나 같음</p>
<p>제2 사분위수(Q2) : 중앙값</p>
<p>제3 사분위수(Q3) : 데이터의 75%가 이 값보다 작거나 같음</p>
<p>사분위간 범위 : 제1 사분위수와 제3 사분위수 간의 거리(Q3-Q1). 상자로 나타낸 부분.</p>
<p>수염은 상자 길이(사분위간 범위)의 1.5배 길이를 상자로부터 늘인 범위 안에서, 최댓값 또는 최솟값을 가리킨다.</p>
<p>이 범위에 포함되지 않은 값은 이상값으로 정의된다.</p>
<p>상자 수염 그림은 중앙값이나 사분위수, 최댓값, 최솟값 등의 통계량은 나타내는 반면, 히스토그램에서 볼 수 있는 상세한 분포 형태 정보는 포함하지 않는다.</p>
<p><code>-</code> 분포를 시각화하는 다양한 방법</p>
<ul>
<li><p>막대그래프(평균값) + 오차 막대(S.D. or S.E.)</p></li>
<li><p>바이올린 플롯</p></li>
<li><p>스웜 플롯</p></li>
<li><p>상자 수염 그림 + 스웜 플롯</p></li>
</ul>
<section id="p.-3장-나머지-정리-必" class="level3">
<h3 class="anchored" data-anchor-id="p.-3장-나머지-정리-必">~ 67p. 3장 나머지 정리 必</h3>
<hr>
</section>
</section>
</section>
<section id="추론통계-신뢰구간" class="level1">
<h1>4. 추론통계 ~ 신뢰구간</h1>
<ul>
<li>데이터로 모집단의 성질을 추정한다.</li>
</ul>
<section id="추론통계를-배우기-전에" class="level2">
<h2 class="anchored" data-anchor-id="추론통계를-배우기-전에">4.1 추론통계를 배우기 전에</h2>
<p><code>-</code> 전수조사와 표본조사</p>
<p>전수조사 : 모집단의 모든 요소를 조사</p>
<p>표본조사 : 모집단의 일부인 표본으로 모집단의 성질을 추정</p>
<p><code>-</code> 데이터를 얻는다는 것</p>
<p>” 데이터(표본)를 얻는다는 것은 무엇인가? ” : 모집단에 포함된 전체 값으로 구성된 분포에서 일부를 추출하는 것</p>
<p>모집단분포를 특징 짓는 양을 <strong>모수</strong> 또는 <strong>파라미터</strong> 라 부른다</p>
<p>확률분포와 실현값의 관계는 모집단과 표본의 관계와 매우 비슷</p>
<p>‘모집단 = 확률분포, 표본 = 확률분포를 따르는 실현값’ 이라고 생각하자</p>
<p>” 얻은 실현값으로 이 값을 발생시킨 확률분포를 추정한다 ” 라는 목표로 바꾸어 말할 수 있다.</p>
<ul>
<li>모집단분포 모형화</li>
</ul>
<p>ex) 성인 남성 키의 분포는 정규분포와 매우 비슷하지만, 엄밀한 의미에서 정규분포가 되는 일은 있을 수 없다.</p>
<p>그러나 있는 그대로를 바로 수학적으로 다룰 수 없을 때가 잦기 때문에, 3장에서 배운 것과 같은 <strong>수식</strong> 으로 기술하게 된다.</p>
<p>그러면 수학적으로 다룰 수 있는 확률분포(모형)에 근사하여 작업을 진행할 수 있게 되어, 모집단의 추정이 용이해진다.</p>
<p>수학적인 확률분포로 모집단 분포를 근사하는 것을 여기서는 <strong>모형화(modeling)</strong> 라 부르도록 하자</p>
<p>예를 들어 정규분포로 근사할 수 있다면, 평균과 표준편차 같은 2가지 파라미터만으로 분포를 기술할 수 있으며, 다룰 수도 있게된다.</p>
<p>이 장 후반에 등장하는 t분포는, 이와 같이 모집단이 정규분포라는 가정하에 이용할 수 있는 분포이다.</p>
<ul>
<li>무작위추출</li>
</ul>
<p>모집단에서 표본을 얻을 때 중요한 것이 <strong>무작위추출(random sampling)</strong> 이다.</p>
<p>데이터를 얻을 때 모집단에 포함된 요소를 무작위로 선택하여 추출하는 방식</p>
<p>독립적이지 않은 선택방식도 적절하지 않다.</p>
<ul>
<li>무작위추출 방법</li>
</ul>
<p>이상적인 무작위추출 방법은 표본에 있을 수 있는 모든 요소를 목록으로 만들고, 난수를 이용하여 표본을 정하는 것. 이를 <strong>단순무작위추출법</strong> 이라 한다.</p>
<p>실제로 자주 사용하는 방법은 <strong>층화추출법</strong> 이다. 이는 모집단을 몇개의 층(집단)으로 미리 나눈 뒤, 각 층에서 필요한 수의 조사대상을 무작위로 추출하는 방법이다.</p>
<p>그 밖에도 계통추출법, 군집추출법 등 다양한 방법이 있다.</p>
<ul>
<li>편향된 추출로는 올바른 추정이 어려움</li>
</ul>
</section>
<section id="표본오차와-신뢰구간" class="level2">
<h2 class="anchored" data-anchor-id="표본오차와-신뢰구간">4.2 표본오차와 신뢰구간</h2>
<p>모집단의 평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">나 <img src="https://latex.codecogs.com/png.latex?%5Csigma"> 등은 고정된 값이지만, 모집단분포에서 얻은 표본 <img src="https://latex.codecogs.com/png.latex?x_1,%20x_2,%20...%20x_n">은 확률적으로 변하는 확률변수라는 사실을 염두에 둘 것</p>
<p><code>확률변수의 정확한 의미는?</code></p>
<p>일반적으로 표본평균은 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">와 일치하지 않는다. 즉 ’정말로 알고 싶은 것’과 ’실제로 손 안에 있는 데이터’에는 어긋남(오차)가 생기는 것. 이런 오차를 <strong>표본오차(표집오차, sampling error)</strong> 라고 한다.</p>
<p>표본오차는 표본을 추출할 때의 인위적인 실수나 잘못으로 생기는 오차가 아니라, 데이터 퍼짐이 있는 모집단에서 확률적으로 무작위 표본을 고르는 데서 발생하는, 피할 수 없는 오차라는 점에 주의</p>
<ul>
<li>큰 수의 법칙</li>
</ul>
<p>표본평균과 모집단평균의 관계에는 <strong>큰 수의 법칙(law of large numbers)</strong> 이 성립한다.</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">가 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">에 한없이 가까워진다는 법칙.</p>
<p>다시 말해 표본오차 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">가 <img src="https://latex.codecogs.com/png.latex?0">에 한없이 가까워진다는 뜻이기도 하다.</p>
<p><code>-</code> 표본오차의 확률분포</p>
<p>표본오차의 확률분포를 알면 어느 정도 크기의 오차가, 어느 정도의 확률로 나타나는지를 알 수 있게 된다.</p>
<ul>
<li>중심극한정리</li>
</ul>
<p>표본오차의 분포에 관해 중요한 정보를 제공하는 것이 <strong>중심극한정리(central limit theorem)</strong> 이다.</p>
<p>모집단이 어떤 분포이든 간에, 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">의 분포는 정규분포로 근사할 수 있다는 것을 의미</p>
<p>’표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">의 분포? : 표본크기 <img src="https://latex.codecogs.com/png.latex?n">으로 표본을 추출하고 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">를 계산하는 작업을 몇 번이고 반복해서, 표본평균을 한데 모아 히스토그램을 그린다는 것.</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 표본평균의 분포는 다음과 같은 정규분포로 근사할 수 있다.</p>
<p>평균 : 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu"></p>
<p>표준편차 : <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D"></p>
<blockquote class="blockquote">
<p>Chat GPT : 중심극한정리와 대수의 법칙의 차이점이 뭐야?</p>
</blockquote>
<ol type="1">
<li>중심극한정리 (Central Limit Theorem):</li>
</ol>
<p>중심극한정리는 확률론의 기본 개념 중 하나로, 독립적인 확률 변수들의 합 또는 평균이 정규분포에 근사하는 현상을 설명합니다. 중심극한정리는 다음과 같은 특징을 가집니다:</p>
<p>독립적인 확률 변수들의 합 또는 평균은 표본 크기가 충분히 크면 정규분포에 근사한다.</p>
<p>중심극한정리는 모집단의 분포에 상관 없이 적용될 수 있으며, 모집단이 어떤 분포를 따르더라도 표본 평균의 분포는 정규분포에 가까워진다.</p>
<ol start="2" type="1">
<li>대수의 법칙 (Law of Large Numbers):</li>
</ol>
<p>대수의 법칙은 표본 크기가 커질수록 표본 평균이 모집단의 평균에 가까워진다는 원리를 설명합니다. 대수의 법칙은 다음과 같은 특징을 가집니다:</p>
<p>대수의 법칙은 표본 크기가 커질수록 표본 평균이 모집단 평균에 수렴한다.</p>
<p>대수의 법칙은 표본 크기가 충분히 크다면 모집단의 분포에 상관 없이 적용될 수 있으며, 모집단이 어떤 분포를 따르더라도 표본 평균은 모집단 평균에 가까워진다.</p>
<p>차이점:</p>
<p>중심극한정리는 확률 변수들의 합 또는 평균의 분포에 대한 이론을 다루는 것이며, 주로 정규분포와 관련이 있습니다.</p>
<p>대수의 법칙은 표본 크기가 커질 때 표본 평균이 모집단 평균으로 수렴하는 원리를 설명하며, 분포에 대한 특별한 가정이 필요하지 않습니다. 이는 큰 표본 크기를 가지고 있는 경우에는 표본의 평균이 모집단 평균과 거의 같아질 것이라는 것을 의미합니다.</p>
<p>중심극한정리와 대수의 법칙은 통계 분석과 데이터 분석에서 중요한 개념으로 사용되며, 표본 크기와 확률 분포에 대한 이해를 높이는 데 도움을 줍니다.</p>
<ul>
<li>추정량</li>
</ul>
<p>모집단의 성질을 추정하는 데 사용하는 통계량을 <strong>추정량</strong> 이라 한다.</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">을 무한대로 했을 때, 모집단의 성질과 일치하는 추정량을 <strong>일치추정량</strong> 이라 하고, 추정량의 평균값(기댓값)이 모집단의 성질과 일치할 때의 추정량은 <strong>비편향추정량</strong> 이라 한다.</p>
<p>비편향추정량은 매번 얻을 때마다 확률적으로 다른 값이 되지만, 평균으로 보면 모집단의 성질을 과대하지도 과소하지도 않게 나타내는 양을 뜻한다.</p>
<p>모집단의 성질을 추정할 때 편향된 추정은 바람직하지 않다. 그러므로 비편향추정량은 바람직한 추정량이다.</p>
<p><code>비편향추정량, 일치추정량 ??</code></p>
<p>추정량 하나하나는 모집단의 성질(여기서는 <img src="https://latex.codecogs.com/png.latex?%5Cmu">)에서 벗어나지만, 이를 모아 구한 평균값이 <img src="https://latex.codecogs.com/png.latex?%5Cmu">와 일치하는 경우 이를 비편향추정량이라 부른다.</p>
<p>중심극한정리에서 본 것 처럼 표본평균의 분포의 평균은 모집단의 성질인 <img src="https://latex.codecogs.com/png.latex?%5Cmu">와 일치하므로, 표본평균은 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">를 편향되지 않게 추정하는 비편향추정량이다.</p>
<p>한편 표본표준편차 <img src="https://latex.codecogs.com/png.latex?s">(또는 표본분산 <img src="https://latex.codecogs.com/png.latex?s%5E2">)는 사정이 조금 다르다.</p>
<p>표본표준편차 <img src="https://latex.codecogs.com/png.latex?s">의 정의에서 루트 안의 분모는 <img src="https://latex.codecogs.com/png.latex?n">이었다. 기술통계에서 데이터 퍼짐 정도를 평가할 때는 문제가 없지만, 모집단의 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">를 과소평가한다는 문제가 있다.</p>
<p>올바르게는 <img src="https://latex.codecogs.com/png.latex?n-1">로 나눈 다음 식이, 모집단 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">의 비편향추정량이 된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?s%20=%20%5Csqrt%7Bs%5E2%7D%20=%20%5Csqrt%7B%5Cfrac%7B1%7D%7Bn-1%7D%5Csum%5En_%7Bi=1%7D(x_i-%5Cbar%7Bx%7D)%5E2%7D"></p>
<blockquote class="blockquote">
<p><img src="https://latex.codecogs.com/png.latex?n">으로 나누면 왜 과소평가가 되는가?</p>
</blockquote>
<p>각 값 <img src="https://latex.codecogs.com/png.latex?x_i">와 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">의 차이를 제곱하여 값이 얼마나 퍼졌는지를 측정하지만 원래 <img src="https://latex.codecogs.com/png.latex?(x_i-%5Cmu)%5E2">로 계산해야 하는 것을 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 미지수이므로 <img src="https://latex.codecogs.com/png.latex?(x_i-%5Cbar%7Bx%7D)%5E2">로 바꾼 것이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">는 <img src="https://latex.codecogs.com/png.latex?%5Cmu">와 일치하지 않으며, 각 값 <img src="https://latex.codecogs.com/png.latex?x_i">와 <img src="https://latex.codecogs.com/png.latex?%5Cmu">의 위치 관계 또는 각 값 <img src="https://latex.codecogs.com/png.latex?x_i">와 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">의 위치 관계를 생각하면 <img src="https://latex.codecogs.com/png.latex?x_i">는 <img src="https://latex.codecogs.com/png.latex?%5Cmu">보다도 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">에 가까이 있을 것이다.</p>
<p>그러므로 <img src="https://latex.codecogs.com/png.latex?(x_i-%5Cbar%7Bx%7D)%5E2">의 합은 <img src="https://latex.codecogs.com/png.latex?(x_i-%5Cmu)%5E2">보다도 작은 값이 된다.</p>
<p>따라서 <img src="https://latex.codecogs.com/png.latex?n">으로 나누지 않고 <img src="https://latex.codecogs.com/png.latex?n-1">로 나누어 과소평가를 보정하는 것</p>
<ul>
<li>표본오차의 분포</li>
</ul>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 표본오차 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">의 분포는 다음 정규분포로 근사할 수 있다.</p>
<p>평균 : 0</p>
<p>표준편차 : <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D"></p>
<p>표본오차 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">의 분포는 모집단의 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">와 표본크기 <img src="https://latex.codecogs.com/png.latex?n"> 등 2개의 값만 정해지면 알 수 있다는 것. 이 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D">을 <strong>표준오차(standard error)</strong> 라 한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma">는 모집단의 성질이므로 보통 우리로선 알 수 없는 미지의 숫자이다. 그러므로 앞서 살펴본 표본에서 추정한 비편향표준편차 <img src="https://latex.codecogs.com/png.latex?s">를 <img src="https://latex.codecogs.com/png.latex?%5Csigma"> 대신 사용한 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">를 표준오차로 삼는다.</p>
<p>이때 표본오차(단 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">으로 나눔)는 정규분포가 아니라 정규분포와 매우 닮은 t분포를 따르게 된다.</p>
<p><code>-</code> 신뢰구간이란?</p>
<p>표본오차의 확률분포는 얼마나 큰 오차가 어느 정도의 확률로 나타나는가를 알 수 있다.</p>
<p>간단하게 오차를 정량화하기 위해서, <strong>신뢰구간(confidence interval)</strong> 이라는 개념을 도입</p>
<blockquote class="blockquote">
<p>정규분포의 성질에서 <img src="https://latex.codecogs.com/png.latex?%ED%8F%89%EA%B7%A0%EA%B0%92%20%5Cpm"> 2 <img src="https://latex.codecogs.com/png.latex?%5Ctimes%20%ED%91%9C%EC%A4%80%ED%8E%B8%EC%B0%A8"> 범위에 약 95%의 값을 포함하고 있었다. 즉, 정규분포에서 하나의 값을 무작위로 꺼내면 95%의 확률로 그 범위에 포함된다는 뜻</p>
</blockquote>
<p>이 개념을 그대로 표본오차의 정규분포에 적용해보면</p>
<p>표본오차의 약 95%는 <img src="https://latex.codecogs.com/png.latex?0-2%5Ctimes%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D%20%5Cleq%20%5Cbar%7Bx%7D%20-%20%5Cmu%20%5Cleq%200%20+%202%20%5Ctimes%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?%5Cmu"> 를 알고 싶기 때문에 이항하고 음수를 곱하면 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D%20-%202%20%5Ctimes%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D%20%5Cleq%20%5Cmu%20%5Cleq%20%5Cbar%7Bx%7D%20+%202%20%5Ctimes%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D"></p>
<ul>
<li>신뢰구간의 해석</li>
</ul>
<p>OO% 신뢰구간을 해석하면 “OO%의 확률로 이 구간에 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 있다.” 가 된다.</p>
<p>단, 확률변수는 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 아니라 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">(또는 신뢰구간)이다.</p>
<blockquote class="blockquote">
<p>즉 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 확률적으로 변화하여 그 구간에 포함되는 것이 아니라, 모집단에서 표본을 추출하여 OO% 신뢰구간을 구하는 작업을 100번 반복했을 때 평균적으로 그 구간에 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 포함되는 것이 OO번이란 뜻.</p>
</blockquote>
<p>하나의 표본에서 얻은 신뢰구간은 <img src="https://latex.codecogs.com/png.latex?%5Cmu">를 포함하거나 포함하지 않거나 둘 중 하나이다.</p>
<p>신뢰구간은 표본에서 구한 모집단 <img src="https://latex.codecogs.com/png.latex?%5Cmu">의 추정값을 어느 정도 신뢰할 수 있는지를 나타낸다고 할 수 있다.</p>
<p>신뢰구간이 좁다면 추정값 가까이에 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 있다고 생각할 수 있으므로, 추정값은 신뢰할 수 있는 값이다. 반대로 신뢰구간이 넓다면 추정값과 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">사이의 오차는 커지는 경향이 있으므로 신뢰도는 낮다.</p>
<p>OO% 신뢰구간에서 ’OO%’에는 일반적으로 95%를 사용한다. 이 숫자는 과학계에서 관례로 사용되어 온 것으로, 필연성은 없다.</p>
<p>가설검정에서 유의수준 5%는 95% 신뢰구간과 동전의 양면과 같은 관계이다.</p>
<p>95% 신뢰구간이란 평균적으로 20번 중 1번 정도 벗어난다는, 달리 말하면 20번 중 19번은 구간에 모집단평균을 포함한다는 뜻이다.</p>
<p><code>-</code> t분포와 95% 신뢰구간</p>
<p>정규분포의 성질을 “<img src="https://latex.codecogs.com/png.latex?%ED%8F%89%EA%B7%A0%EA%B0%92%5Cpm%202%5Ctimes%20%ED%91%9C%EC%A4%80%ED%8E%B8%EC%B0%A8">”안에 95%라고 대략적으로 말해왔지만 정확하게는 “<img src="https://latex.codecogs.com/png.latex?%ED%8F%89%EA%B7%A0%EA%B0%92%5Cpm%201.96%5Ctimes%20%ED%91%9C%EC%A4%80%ED%8E%B8%EC%B0%A8">”의 범위가 95%가 된다.</p>
<p>문제가 되는 것은 중심극한정리는 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 근사적으로 성립하기에 실제 데이터 분석에서 볼 수 있는 작은 표본크기의 경우 표본오차가 정규분포를 따른다고 말할 수 없다는 것과 모집단의 <img src="https://latex.codecogs.com/png.latex?%5Csigma"> 대신 <img src="https://latex.codecogs.com/png.latex?s">를 써야만 한다는 것.</p>
<p>이때 활약하는 것이 <strong><img src="https://latex.codecogs.com/png.latex?t">분포</strong></p>
<p><strong><img src="https://latex.codecogs.com/png.latex?t">분포</strong>는 모집단이 정규분포라는 가정하에 미지의 모집단 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">를 표본으로 계산한 비편향표준편차 <img src="https://latex.codecogs.com/png.latex?s">로 대용했을 때, <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">를 표준오차 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">로 나누어 표준화한 값이 따르는 분포이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cbar%7Bx%7D-%5Cmu%7D%7B%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D%7D"></p>
<p>이 값은 표준오차 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">를 단위로 표본오차 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">가 몇 개분인지를 나타낸다.(3장의 표준화와 마찬가지)</p>
<p>복잡하다고 느낄 수도 있겠으나, <img src="https://latex.codecogs.com/png.latex?t">분포 자체는 정규분포와 매우 비슷한 형태이며 표본크기 <img src="https://latex.codecogs.com/png.latex?n">에 따라 모양이 조금 달라질 뿐, 신뢰구간을 구하는 논리는 그대로이다.</p>
<p>95%라는 엄밀한 값을 얻고자 미세 조정하는 것으로 생각하면 된다.</p>
<p>아울러 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커짐에 따라, <img src="https://latex.codecogs.com/png.latex?t">분포는 정규분포에 가까워진다.</p>
<p><img src="https://latex.codecogs.com/png.latex?t">분포에서 표본크기 <img src="https://latex.codecogs.com/png.latex?n=10">인 경우에는 평균 0, 표준편차 1인 정규분포보다 조금 넓어져 하위 2.5%, 상위 2.5%인 지점이 -2.26과 +2.26이 된다 (정규분포는 -1.96, +1.96)</p>
<p>그러므로 신뢰구간을 구하는 식에서는 <img src="https://latex.codecogs.com/png.latex?%5Cpm%202">나 <img src="https://latex.codecogs.com/png.latex?%5Cpm%201.96">이 아닌 <img src="https://latex.codecogs.com/png.latex?%5Cpm%202.26">을 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">에 곱해 계산한다.</p>
<ul>
<li>정밀도를 높이려면</li>
</ul>
<p>보다 신뢰 가능한 평균값을 추정하고 싶을 때는 어떻게 할까?</p>
<p>오차분포의 너비를 나타내는 <strong>표준오차 </strong>에 주목해보면 이를 작게 만들기 위해서는 분자인 비편향표준편차 <img src="https://latex.codecogs.com/png.latex?s">를 작게 하거나, 분모인 표본크기 <img src="https://latex.codecogs.com/png.latex?n">을 크게 하는 두 가지 방법이 있다.</p>
<p><img src="https://latex.codecogs.com/png.latex?s">(또는 <img src="https://latex.codecogs.com/png.latex?%5Csigma">)는 모집단 데이터 퍼짐이라는 모집단 그 자체의 성질에서 유래하기에 작게 만들기 어렵지만, 측정한 데이터 퍼짐(변동) 정도를 줄일 수는 있다. 데이터 퍼짐이 증가하면 결과적으로 <img src="https://latex.codecogs.com/png.latex?s">(또는 <img src="https://latex.codecogs.com/png.latex?%5Csigma">)가 커지기 때문에, 측정을 한층 정밀하게 실시하는 식으로 대처 가능한 경우도 있다.</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">에 관해서는, <img src="https://latex.codecogs.com/png.latex?n">을 크게 만듦으로써 더 높은 정밀도로 추정할 수 있다.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?t">분포를 사용할 때 주의할 점</li>
</ul>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 작아도 적용 가능한 <img src="https://latex.codecogs.com/png.latex?t">분포에는 ’정규분포에서 얻은 데이터’라는 가정이 필요하다. 즉, <img src="https://latex.codecogs.com/png.latex?t">분포는 데이터 <img src="https://latex.codecogs.com/png.latex?x_1,%20x_2,%20...%20,%20x_n">을 정규분포라는 모형에서 얻었을 때의 (표준화된) 표본오차가 따르는 분포이다. 데이터의 배경에 잇는 모집단분포가 완벽한 정규분포일 수는 없으므로, 얻은 95% 신뢰구간은 정확한 95%가 아니라는 점에 주의.</p>
<p>특히 문제가 되는 것은 정규분포와 현저하게 다른 분포에서 데이터를 얻었을 때이다. 이 경우 95% 신뢰구간을 구해도 95%에서 벗어날 수 있어 주의해야 한다.</p>
<p>단, 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 클 때는 중심극한정리에 따라 모집단이 정규분포가 아니더라도 표본평균을 정규분포로 근사할 수 있으므로 신뢰구간은 정확해진다.</p>
</section>
</section>
<section id="가설검정-정리-必" class="level1">
<h1>5. 가설검정 (정리 必)</h1>
<section id="가설검정의-원리" class="level2">
<h2 class="anchored" data-anchor-id="가설검정의-원리">5.1 가설검정의 원리</h2>
</section>
<section id="가설검정-시행" class="level2">
<h2 class="anchored" data-anchor-id="가설검정-시행">5.2 가설검정 시행</h2>
</section>
<section id="가설검정-관련-그래프" class="level2">
<h2 class="anchored" data-anchor-id="가설검정-관련-그래프">5.3 가설검정 관련 그래프</h2>
</section>
<section id="제1종-오류와-제2종-오류" class="level2">
<h2 class="anchored" data-anchor-id="제1종-오류와-제2종-오류">5.4 제1종 오류와 제2종 오류</h2>
<hr>
</section>
</section>
<section id="다양한-가설검정" class="level1 page-columns page-full">
<h1>6. 다양한 가설검정</h1>
<p>p.151 ~</p>
<ul>
<li><p>모수검정 : 모집단이 특정분포를 따른다는 가정을 둔 가설검정</p>
<ul>
<li><p>정규분포로부터 얻어졌다고 간주할 수 있는 성질 (정규성 normality를 가졌다.)</p></li>
<li><p>반대는 특정분포로 가정을 못하는 경우가 있다. ex) 좌우 비대칭 분포, 이상값이 있는 분포라면 평균이나 표준편차는 도움이 되지 않음, 모수검정 이용이 적절하지 않다. 그 대신 평균, 표준펴나 등의 파라미터에 기반을 두지 않는 ’비모수 검정’으로 분류되는 방법을 이용</p></li>
</ul></li>
<li><p>정규성 조사 (귀무가설에 정규성 가정)</p>
<p>모수검정에서는 각 집단의 데이터에 정규성이 있어야한다.</p>
<ul>
<li><p>정규성 조사법 :</p>
<ul>
<li>Q-Q플롯(분위수-분위수 그림)</li>
<li>샤피로-윌크 검정 (가설검정으로 조사)</li>
<li>콜모고로프-스미르노프 (K-S) 검정</li>
</ul></li>
</ul></li>
<li><p>등분산성 조사 (귀무가설에 등분산 가정)</p>
<p>t검정, 분산분석 =&gt; 분산이 같은 모집단으로부터 획득되었다는 가정이 필요</p>
<ul>
<li>등분산성 조사법 :
<ul>
<li>바틀렛 검정</li>
<li>레빈 검정</li>
</ul></li>
</ul></li>
<li><p>데이터에 정규성이 없는 경우? → 비모수검정 (평균값 대신 분포의 위치를 나타내는 대푯값에 주목하여 해석)</p>
<ul>
<li><strong>윌콕슨 순위합 검정</strong>(wil-coxon rank sum test) : 평균값 대신 각 데이터 값의 순위에 기반하여 검정</li>
<li>맨-휘트니 U 검정
<ul>
<li>비교할 2개 집단의 분포 모양 자체가 같아야함</li>
</ul></li>
<li>플리그너-폴리셀로 검정</li>
<li>브루너-문첼 검정</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>여기까지는 2개 표본 비교</p>
</blockquote>
<ul>
<li>분산분석(ANOVA, Analysis of variance) : 3개 집단 이상의 평균값 비교
<ul>
<li>귀무가설 : 모든 집단의 평균이 같다 (<img src="https://latex.codecogs.com/png.latex?%5Cmu_A%20=%20%5Cmu_B%20=%20%5Cmu_C">)</li>
<li>대립가설 : 적어도 한 쌍에는 차이가 있다.</li>
</ul></li>
<li>F값 = (평균적인 집단간 변동) / (평균적인 집단 내 변동)
<ul>
<li>집단 내 변동 = 오차에 따른 변동</li>
<li>집단 간 변동 = 효과에 따른 변동</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://star77sa.github.io/posts/Statistics/통계_101_X_데이터_분석_files/figure-html/cell-83-1-image.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">image.png</figcaption>
</figure>
</div>
<ul>
<li><p>자유도(degree of freedom) : 자유로이 움직일 수 있는 변수의 수</p>
<p>ex) 표본크기가 n=10인 표본이라면 자유도는 10이지만 표본평균을 계산한 이후의 자유도는 9가 된다.</p>
<p>표본평균이 확정되었기에 9개의 데이터가 정해지면 남은 1개의 값을 확정할 수 있기 때문</p></li>
<li><p>일표본 t검정 (가정) vs 이표본 t검정</p></li>
<li><p>정규분포 ㅡ t분포 ㅡ t검정 관계</p></li>
</ul>
<p>p.164 ~</p>
<ul>
<li><p>분산분석의 대립가설은 “적어도 한 쌍에는 차이가 있다.” 이기에 <img src="https://latex.codecogs.com/png.latex?p%3C0.05"> 로 대립가설을 채택하더라도 어느쌍에 차이가 있는지까지는 알 수 없다. 어느 쌍에 차이가 있는지 알고싶다면 “다중 비교”라 불리는 방법을 사용해야 한다.</p></li>
<li><p>집단이 셋 이상일 때 각 쌍의 차이를 조사하기 위해 유의수준 <img src="https://latex.codecogs.com/png.latex?%5Calpha=0.05">에서 이표본 t검정을 반복해 실행하면 제 1종 오류가 증가하고 마는 문제가 생김</p>
<ul>
<li>ex) 3개 집단, t검정 3번, 적어도 한 쌍에서 제 1종 오류가 일어날 확률 : <img src="https://latex.codecogs.com/png.latex?1-">(어느 쌍에서도 제 1종 오류가 일어나지 않을 확률)<img src="https://latex.codecogs.com/png.latex?%5E3%20=%200.143"></li>
</ul></li>
<li><p>집단의 수가 늘어날수록 제 1종 오류가 일어나기 쉬워진다.</p></li>
</ul>
<div id="cell-88" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-2">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Malgun Gothic'</span></span>
<span id="cb1-3">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'axes.unicode_minus'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb1-4"></span>
<span id="cb1-5">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-6">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>x</span>
<span id="cb1-7">plt.plot(x,y)</span>
<span id="cb1-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"검정횟수"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>Text(0.5, 0, '검정횟수')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://star77sa.github.io/posts/Statistics/통계_101_X_데이터_분석_files/figure-html/cell-2-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>다중비교의 기본 아이디어 : 검정을 반복하는 만큼, 유의수준을 엄격한 값으로 변경하는 것</p>
<ul>
<li>본페로니 교정, 튜키 검정, 던넷 검정, 윌리엄스 검정</li>
</ul></li>
<li><p>3집단 이상의 비모수 검정 : 크러스컬 - 월리스 검정, 스틸-드와스 검정(&lt;-&gt; 튜키 검정), 스틸 검정(&lt;-&gt; 던넷 검정)</p></li>
<li><p>양적변수는 모집단의 평균값을 추정하거나 모집단을 대상으로 가설을 세워 가설검정을 한다.</p></li>
<li><p>범주형변수는 사건이 일어날 확률 P를 추정하거나 확률 P에 관련된 가설을 세워 검정한다.</p></li>
</ul>
<p>이항분포 <img src="https://latex.codecogs.com/png.latex?_nC_mp%5Em(1-p)%5E%7BN-m%7D"> - 이항검정 -&gt; 범주가 2개일때만 이용가능. - 범주가 여러개거나 일반적인 이산확률분포에 이항검정의 방식을 적용하고 싶을 때 =&gt; 카이제곱검정(<img src="https://latex.codecogs.com/png.latex?%5Cchi%5E2"> chi-squard test)의 일종인 적합도 검정 이용</p>
<p>카이제곱검정의 적합도 검정 해석 - 귀무가설 : 모집단은 상정한 이산확률분포이다. - 대립가설 : 모집단은 상정한 이산확률분포가 아니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cchi%5E2%20=%20%5Cfrac%7B(%EC%8B%A4%EC%A0%9C%20%EC%B6%9C%ED%98%84%EB%8F%84%EC%88%98-%EA%B8%B0%EB%8C%80%EB%8F%84%EC%88%98)%5E2%7D%7B%EA%B8%B0%EB%8C%80%EB%8F%84%EC%88%98%7D"></p>
<ul>
<li>귀무가설이 옳다면 이는 <img src="https://latex.codecogs.com/png.latex?%5Cchi%5E2">분포라는 확률분포를 따른다.</li>
<li>이 분포 안에서 실제로 얻은 <img src="https://latex.codecogs.com/png.latex?%5Cchi%5E2">의 위치를 구해 p값을 도출한다</li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://star77sa.github.io/posts/Statistics/통계_101_X_데이터_분석_files/figure-html/cell-93-1-image.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">image.png</figcaption>
</figure>
</div>
<ul>
<li><p>이항검정, 카이제곱 검정의 적합도 검정 : ’데이터 vs 모집단’의 확률 분포를 비교</p></li>
<li><p>범주형 변수에서도 두 개 변수의 관계를 조사해야 할 때가 있다. - 카이제곱의 독립성 검정 (그 밖에는 초기하분포 이용 피셔의 정확검정 등)</p></li>
<li><p>분할표에서 비율을 유지? -&gt; 독립</p></li>
</ul>


</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/Statistics/통계_101_X_데이터_분석.html</guid>
  <pubDate>Wed, 13 Sep 2023 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
