<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Time Series</title>
<link>https://star77sa.github.io/</link>
<atom:link href="https://star77sa.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.4.540</generator>
<lastBuildDate>Tue, 16 Jan 2024 15:00:00 GMT</lastBuildDate>
<item>
  <title>2024 GIST-NVAITC Korea 강연 내용</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/etc/NVIDIA초청강연.html</link>
  <description><![CDATA[ 





<ul>
<li>TinyLlama
<ul>
<li>A compact 1.1B language model (↔︎ 거대 언어 모델) pretrained on around 1 trillion tokens for approximately 3 epochs.</li>
</ul></li>
<li>PEFT
<ul>
<li>PEFT: huggingface.co/docs/transformers/main/en/peft</li>
<li>Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware</li>
<li>문제점 1 : 모델이 점점 커짐에 따라 시판 그래픽카드로 모델 전체를 파인튜닝하는것은 불가능해져가고있다.</li>
<li>문제점 2 : 파인튜닝된 모델이 파인튜닝하기 이전의 사전학습된 모델과 똑같은 크기이기 때문에 파인튜닝된 모델을 사용하는 것 또한 (시간, 경제적으로) 비용이 많이 드는 일</li>
<li>대부분의 파라미터를 프리징하고 일부의 파라미터만을 파인튜닝함으로써 저장공간과 계산을 대폭 줄였다. 파인튜닝할때 발생하는 문제점 중 하나인 catastrophic forgetting 또한 극복</li>
<li>적은 데이터 체제(low-data-regime)에서 파인튜닝할때나 도메인 밖의 데이터(out-of-domain scenario)를 일반화할때 더욱 좋은 성능</li>
<li><strong>PEFT는 적은 수의 파라미터를 학습하는것만으로 모델 전체를 파인튜닝하는 것과 유사한 효과를 누릴 수 있도록 해준다.</strong></li>
</ul></li>
</ul>
<section id="library" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="library">Library</h3>
<ul class="page-columns page-full">
<li><p>bitsandbytes</p>
<ul>
<li>model을 8-bit 포맷으로 set up하여 큰 gpu가 필요하지 않음.</li>
<li>행렬 곱을 연산할 때 각 벡터를 독립적으로 처리하는 Vector-wise Quantization 방법을 적용하고 중요한 벡터는 16-bit로 표현하여 손실을 최소화 하는 등 8-bit와 16-bit를 혼용하는 기법을 통해 모델의 성능은 유지하면서 크기는 줄이는 성과를 보였다.</li>
</ul></li>
<li><p>accelerate</p>
<ul>
<li><p>기본 pytorch 코드를 통해 multi gpu를 사용하면 (DDP) 0번 gpu만 100% 사용되고 나머지 gpu는 예를 들어 60% 정도씩 덜 활용된다.</p>
<p>각 gpu에서 loss를 계산하고 각 결과를 합해서 최종 loss를 구해야 하는데 합하는 연산을 0번 device에서 하기 때문에 0번의 소모만 커지기 때문.</p>
<p>accelerate를 사용하면 이러한 문제를 해결할 수 있다.</p></li>
</ul></li>
<li><p>DeepSpeed</p>
<ul>
<li>스케일링 등을 통해 학습 속도를 가속화하는 라이브러리</li>
<li>floating point를 32에서 16으로 줄이는 등의 스케일을 적용하여 학습 속도를 줄이지만 성능이 저하된다. 예를 들어 하루종일 걸리는 학습을 30분 정도(stage 3)로 단축하지만 성능도 그만큼 감수해야 한다. 때문에 분류 문제처럼 acc가 중요한 문제에는 DeepSpeed를 덜 사용하거나 사용하지 않는게 좋고, 텍스트 생성모델처럼 정량적 평가가 크게 중요하지 않은 문제(정성적 평가의 비중이 큰 문제)에는 DeepSpeed를 써도 감수할 만 하다</li>
</ul></li>
<li><p>from transformers import pipeline</p>
<ul>
<li>여러 모델을 묶어준다.</li>
</ul>
<pre><code>pipe = pipeline("text-generation",
            model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
            torch_dtype=torch.bfloat16,
            device_map="auto")</code></pre></li>
<li class="page-columns page-full"><p>bf16: brainfloat16</p>
<ul>
<li>장점:넓은 수의 표현 범위 / 단점 : 표현 정밀도가 떨어지기 때문에 예를 들어 0에 가까운 수가 모조리 0으로 표현될 수 있음. 이 단점은 단지 숫자가 0이 되는것보다도 어떤 수를 0으로 나누는 상황이 생길 가능성을 높여서 문제이다.</li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://star77sa.github.io/posts/etc/NVIDIA초청강연_files/figure-html/cell-4-1-image.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">image.png</figcaption>
</figure>
</div></li>
<li><p>chatgpt guidance 공개 안해줌.</p></li>
<li><p>causal을 사용하기에 prompt를 유저에게 보여주지 않기 위해 삭제 replace(prompt, “”)</p></li>
<li><p>chatgpt에서는 사용자와의 대화 history까지 input으로 들어가 마치 기억하는 것처럼 보임. 여기서는 아니기 때문에 과거에 예시를 새로운 것으로 착각하여 중복된 output을 낼 가능성이 있음. 때문에 input을 할 때 token에 과거의 output을 넣어주어야 하는데 token에 넣을 수 있는 메모리가 가득 차면 더 이상 생성할 수 없는 limitation이 있음.</p></li>
<li><p>dp: import data_parallel as dp</p>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>DataParallel</th>
<th>DistributedDataParallel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>More overhead; model is replicated and destroyed at each forward pass</td>
<td>Model is replicated only once</td>
</tr>
<tr class="even">
<td>Only supports single-node parallelism</td>
<td>Supports scaling to multiple machines</td>
</tr>
<tr class="odd">
<td>Slower; uses multithreading on a single process and runs into Global Interpreter Lock (GIL) contention</td>
<td>Faster (no GIL contention) because it uses multiprocessing</td>
</tr>
</tbody>
</table></li>
<li><p>multi_node는 accelerater가 해줌.</p></li>
<li><p><strong>tinyllama로 peft를 켜서 모델을 생성 후 open dataset으로 실행 -&gt; instruction dataset으로 실행, dp, ddp 사용</strong></p></li>
<li><p>aica, GIST, nipa 등 연구원 전용 지원 혜택 받기</p></li>
<li><p>colab은 multi gpu가 안됨</p></li>
<li><p>colab pro + peft정도면 논문에 쓸 데이터 정도는 학습 가능</p></li>
</ul>


</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/etc/NVIDIA초청강연.html</guid>
  <pubDate>Tue, 16 Jan 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>데이터 과학</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/통계, 데이터분석/데이터_분석.html</link>
  <description><![CDATA[ 





<section id="데이터-분석" class="level1">
<h1>데이터 분석</h1>
<ul>
<li>데이터 과학 : 데이터를 사용하여 질문에 합리적인 답을 내릴 수 있게 해주는 활동</li>
</ul>
<p>데이터 분석에 있어 기초통계, 선형모형(회귀·분산 분석 포함)은 제대로 배울 것을 권장.</p>
<p>중요한 요소 : 협업할 수 있는 태도, 소통능력, 폭넓은 독서(논픽션 양서)</p>
<p>데이터 획득 : UCI, 머신러닝 리포, 캐글, 위키피디아 데이터 세트 리스트 등…</p>
<p>분석 순서 : 데이터 취득·데이터 정리 → 탐색적 자료 분석 EDA : 시각화·기초통계량 계산(데이터의 패턴, 이상치 탐색) → 확증적 자료 분석 CDA : 통계적 가설·가설검정·신뢰구간(통계적 모형화 statistical modeling)</p>
<section id="통계" class="level2">
<h2 class="anchored" data-anchor-id="통계">통계</h2>
<ul>
<li><p>특별한 이유를 제외하고는 양측검정 하는 것이 좋다.</p></li>
<li><p>p-value가 크다는 것은 귀무가설에 반하는 증거가 불충분하다는 것이지 귀무가설을 증명하는 증거가 있다는 것이 아니다.</p></li>
<li><p>1종 오류 : 귀무가설을 잘못 기각</p></li>
<li><p>2종 오류 : 대립가설을 잘못 기각</p></li>
<li><p>“유의수준 5%에서 유의하다” 라고만 하지말고 p-value 그 자체의 값도 알려야 한다.</p></li>
<li><p>모수는 상수다.(빈도주의자 관점)</p></li>
<li><p><code>높은 p-value를 귀무가설이 옳다는 증거로 이해하는 오류</code> : 높은 p-value는 대립가설을 입증하는 증거가 불충분함을 의미한다. 효과가 아주 강해도 데이터 관측치가 적으면 p-value가 높을 수 있다. 즉, 높은 p-value는 증거/데이터 불충분으로 이해해야 한다.</p></li>
<li><p><code>낮은 p-value가 항상 의미있다고 이해하는 오류</code> : 만약 표본크기가 너무 크고, 표본평균의 증가값 자체가 너무 적다면 낮은 p-value 자체로는 의미가 없다.</p></li>
<li><p>95% 신뢰구간의 정의 : 같은 모형에서 반복해서 표본을 얻고 신뢰구간을 얻을 때 신뢰구간이 참 모수값을 포함할 확률이 95%가 되도록 만들어진 구간</p></li>
<li><p>중심극한정리 : 어떤 분포든 표본평균은 대략 종모양을 따른다. 정규분포에 기반.</p></li>
<li><p>95% 신뢰구간의 크기는 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7D"> 이다. 즉, 표본의 크기가 커지면 커질수록 신뢰구간의 크기는 줄어들고 그 줄어드는 속도는 <img src="https://latex.codecogs.com/png.latex?%5Csqrt%7Bn%7D"> 이다.</p></li>
</ul>
<section id="통계-인터뷰-질문" class="level3">
<h3 class="anchored" data-anchor-id="통계-인터뷰-질문">통계 인터뷰 질문</h3>
<ul>
<li>p-value를 정의하라 : 귀무가설 하에서, 관찰된 통계량만큼 극단적인 값이 관찰될 확률</li>
<li>비전문가들이 이해하기 쉽게 p-value를 설명하라.</li>
</ul>
<hr>
</section>
<section id="모집단-모수-표본" class="level3">
<h3 class="anchored" data-anchor-id="모집단-모수-표본">모집단, 모수, 표본</h3>
<ul>
<li><p>모집단(population) : 데이터가 (랜덤하게) 표본화되었다고 가정하는 분포/집단</p></li>
<li><p>모수(population parameter) : 모집단을 정의하는 값을 모르는 상수</p></li>
<li><p>표본(sample) : 모집단으로부터 (랜덤하게) 추출된 일부 관측치</p></li>
<li><p>통계량(statistics) : 모수를 추정하기 위해 데이터로부터 계산된 값</p></li>
<li><p>귀무가설(null hypothesis) : 모수에 대한 기존(status quo)의 사실 혹은 디폴트 값</p></li>
<li><p>대립가설(alternative hypothesis) : 모수에 대해 귀무가설과 대립하여 증명하고 싶은 사실</p></li>
<li><p>가설검정(hypothesis testing) : 통계량을 사용해 귀무가설을 기각하는 절차</p></li>
<li><p>타입 1 오류(Type 1 error) : 가설검정 절차가 참인 귀무가설을 기각하는 사건</p></li>
<li><p>타입 2 오류(Type 2 error) : 가설검정 절차가 거짓인 귀무가설을 기각하지 않는 사건</p></li>
<li><p>유의수준(significance level) : 타입 1 오류를 범할 확률의 허용치</p></li>
<li><p>P-value : 만약 귀무가설이 참일 때 데이터가 보여준 정도로 특이한 값이 관측될 확률</p></li>
<li><p>더미 변수 : 통계 및 회귀 분석에서 사용되는 용어. 범주형 데이터를 처리하거나 특정 변수의 상태를 나타내기 위해 사용되는 가상의 이진 변수. 일반적으로, 머신 러닝 모델이나 통계 모델은 숫자형 데이터를 다루는 데 효과적. 그러나 범주형 데이터(예: 성별, 국적, 색상 등)는 이진 변수로 변환해야 한다. 이를 위해 더미 변수를 사용. 더미 변수는 원래 범주형 변수의 각 범주에 대해 0 또는 1의 값을 가지는 새로운 이진 변수. 예를 들어, 성별이라는 범주형 변수가 있을 때, 이를 더미 변수로 나타내려면 남성인 경우에는 1로, 여성인 경우에는 0으로 표현하거나 그 반대로 할 수 있다. 더미 변수를 사용하면 범주형 데이터를 포함한 모델에서 계산이 용이해지며, 해당 변수가 모델에 미치는 영향을 측정할 수 있다. 또한, 더미 변수를 사용함으로써 모델이 범주 간의 상대적인 영향을 학습할 수 있다.</p></li>
<li><p>t값 : <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cbar%7Bx%7D-%5Cmu_0%7D%7B%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D%7D"></p></li>
<li><p>PCA : 주성분 분석(Principal Component Analysis, PCA)는 다차원 데이터를 저차원으로 차원 축소하는 기술 중 하나다. 주로 데이터의 분산을 최대한 보존하면서 차원을 축소하는 데 사용된다. PCA의 목표는 데이터의 주성분(principal components)을 찾는 것인데, 주성분은 데이터의 분산이 최대가 되도록 하는 방향이 된다. 즉, 첫 번째 주성분은 데이터의 분산이 가장 큰 방향이며, 두 번째 주성분은 첫 번째 주성분과 직교하면서 데이터의 분산을 최대한 보존하는 방향이 된다. 이런 식으로 주성분은 데이터의 분산을 차례로 최대화하는 방향으로 정의된다. PCA를 통해 얻은 주성분들은 기존 변수들의 선형 조합으로 표현된다. 이를 통해 데이터를 표현하는 데 필요한 변수의 수를 줄일 수 있다. 이는 차원 축소의 효과를 가져오며, 중요한 정보를 유지하면서 데이터의 복잡성을 낮춘다. PCA는 주로 데이터 시각화, 노이즈 제거, 특성 추출 등 다양한 분야에서 활용된다. 또한, 다중공선성 문제를 해결하거나 머신러닝 모델의 학습 속도를 향상시키는 데에도 사용될 수 있다.</p></li>
<li><p>랜덤 변수(Random Variable)는 확률적인 실험 또는 현상의 결과를 수치적으로 나타내는 변수를 의미한다. 랜덤 변수는 표본 공간의 각 원소를 실수 값으로 매핑하는 함수로 정의되며, 확률 분포에 따라 그 값을 취합니다. 랜덤 변수는 확률 이론과 통계학에서 핵심 개념 중 하나이며, 확률 분포를 통해 랜덤 변수의 특성과 동작을 설명하고 예측하는 데 사용된다. 확률 변수를 이용하면 확률적인 현상을 수학적으로 모델링하고, 이를 통해 다양한 통계적 추론 및 예측을 수행할 수 있다.</p></li>
<li><p>랜덤프로세스 : 확률 변수의 시퀀스 또는 함수로, 시간 또는 공간에 따라 확률적으로 변하는 프로세스를 나타낸다. 랜덤 프로세스는 시간에 따른 랜덤한 변동을 모델링하거나 시공간에서의 랜덤한 현상을 분석하는 데 사용된다. 이는 확률론과 통계학, 시계열 분석, 통신 이론, 제어 이론 등 다양한 분야에서 응용된다.</p>
<p>랜덤 프로세스는 다음과 같은 주요 특징을 갖는다:</p>
<ul>
<li><p>확률 변수의 집합: 랜덤 프로세스는 각각의 시간 또는 위치에 대해 하나 이상의 확률 변수를 갖는다. 이 확률 변수들은 시간 또는 위치에 따라 변하는 값들을 나타낸다.</p></li>
<li><p>시간 또는 위치의 집합: 랜덤 프로세스는 정의된 시간 또는 위치의 집합에서 정의된다. 시간의 경우, 이를 시계열(random time series)이라고 부르기도 한다.</p></li>
<li><p>확률 분포의 변화: 랜덤 프로세스의 특정 시간 또는 위치에서의 값은 확률 분포를 따른다. 이 분포는 시간이나 위치에 따라 변할 수 있다.</p></li>
</ul>
<p>랜덤 프로세스의 예시로는 브라운 운동(Brownian motion), 마코프 체인(Markov chain), 확률 과정(Stochastic process) 등이 있다. 이러한 랜덤 프로세스는 자연 현상, 금융 모델링, 통신 시스템 등에서 모델링과 분석에 활용된다.</p></li>
<li><p>포아송 프로세스 :</p></li>
<li><p>포아송 어라이블 :</p></li>
<li><p>마르코프 과정 :</p></li>
<li><p>정보이론 :</p></li>
<li><p>신호 및 시스템 :</p></li>
<li><p>표준화(Standardization) : 표준화는 데이터의 평균을 0으로, 표준 편차를 1로 만드는 변환을 의미. 표준화된 값은 Z 점수 또는 표준 점수로 불리며 다음의 공식으로 계산 <img src="https://latex.codecogs.com/png.latex?z=%5Cfrac%7Bx-%5Cmu%7D%7B%5Csigma%7D"></p></li>
<li><p>정규화(Normalization) : 정규화는 데이터의 범위를 [0, 1] 또는 [-1, 1]로 조정하는 변환을 의미. Min-Max 정규화는 가장 일반적인 형태로 다음의 공식으로 계산 <img src="https://latex.codecogs.com/png.latex?x_%7Bnormalized%7D%20=%20%5Cfrac%7Bx-%5Cmin(X)%7D%7B%5Cmax(X)-%5Cmin(X)%7D"> 정규화는 다양한 변수 간의 스케일을 맞추어줌으로써 경사 하강법과 같은 최적화 알고리즘의 수렴 속도를 향상시키고, 학습 과정을 안정화 시킨다.</p></li>
</ul>
<p>*** <code>표준 정규 분포에서 정규와 정규화는 관련이 없음.. 정규분포인 데이터에 표준화를 해주면 그게 표준 정규분포!! 표준정규분포 = 평균이 0이고 표준편차가 1인 정규분포</code></p>
<ul>
<li><p>중심 극한 정리 :</p></li>
<li><p>부트스트랩 : 부트스트랩(Bootstrap)은 통계학과 머신 러닝에서 사용되는 샘플링 방법 중 하나로, 주어진 데이터로부터 중복을 허용하여 샘플을 추출하는 과정을 말한다. 일반적으로 데이터셋에서 일부를 무작위로 추출하는 과정에서는 원래 데이터셋에 존재하는 정보의 일부가 누락될 수 있다. 부트스트랩은 이러한 문제를 완화하기 위해 중복을 허용하여 여러 번의 샘플링을 수행한다.</p></li>
<li><p>iid(Independent and Identically Distributed) : 독립 동일 분포. 통계적 가정과 머신러닝 모델의 일부에서 사용된다. 예를 들어, 통계적 가설 검정에서 독립 동일 분포 가정은 검정 결과의 신뢰성을 보장하는 데 중요하다. 머신러닝에서는 iid 가정이 모델의 일반화 성능을 평가하는 데 사용된다. 훈련 데이터셋과 테스트 데이터셋이 iid를 만족한다면, 모델이 새로운 데이터에 대해 더 잘 일반화될 것으로 기대할 수 있다.</p>
<ul>
<li>Independent : 데이터 샘플들이 서로 독립적. 하나의 데이터 포인트나 관측치가 다른 것과 상관없이 독립적으로 발생했다는 것을 나타낸다. 예를 들어, 동일한 데이터셋에서 뽑은 두 개의 관측치는 서로 영향을 주지 않고 독립적으로 존재한다.</li>
<li>Identically Distributed : 데이터 샘플들이 같은 확률 분포에서 추출되었다는 것을 의미한다. 모든 데이터 포인트가 동일한 특성을 가지며, 동일한 확률 분포를 따르는 것을 의미한다.</li>
</ul></li>
<li><p>통계적 패턴인식 : 데이터에서 통계적 구조나 패턴을 추출하고 이를 활용하여 패턴을 인식하거나 분류하는 기술. 이는 주로 통계학, 머신 러닝, 인공 지능 분야에서 활용되며, 다양한 응용 분야에서 패턴을 감지하고 이해하는 데 사용된다.</p></li>
<li><p>Class imbalance를 고려한 모델 학습 방법 (Chat-GPT 답변)</p>
<ul>
<li>가중치 조절 : 적은 수의 클래스에 대해 더 높은 가중치를 부여하여 모델이 이러한 클래스에 더 집중하도록 유도</li>
<li>샘플링 기법 : 1. Under-sampling 다수 클래스의 데이터를 일부 제거하여 클래스간의 균형을 맞춘다. 하지만 정보 손실이 발생할 수 있다. // 2. Over-sampling 소수 클래스의 데이터를 복제하거나 합성하여 데이터를 늘린다. SMOTE(Synthetic Minority Over-sampling Technique)와 같은 기술을 사용할 수 있다.</li>
<li>앙상블 방법 : 다양한 모델을 조합하여 앙상블을 형성하는 것도 클래스 불균형을 해소하는데 도움이 될 수 있다. 예를 들어, 다수결 투표를 통해 예측을 결합할 수 있다.</li>
<li>평가 지표의 선택 : 정확도(accuracy)만을 평가 지표로 사용하지 말고, 클래스 불균형을 고려한 평가 지표를 선택. 정밀도(precision), 재현율(recall), F1-score 등이 유용할 수 있다.</li>
<li>다단계 학습(?) : 다단계 분류기를 사용하여 클래스 간의 계층적인 학습을 수행할 수 있다. 이를 통해 클래스 간의 계층 구조를 고려할 수 있다.</li>
<li>클래스 가중치 설정 : 일부 모델은 클래스에 대한 가중치를 설정할 수 있는 매개변수를 제공한다. 이를 조절하여 클래스 불균형을 고려할 수 있다.</li>
<li>사전 훈련된 모델 사용 : 사전 훈련된 모델을 사용하여 초기 가중치를 설정하면 클래스 불균형에 민감한 초기화 문제를 완화할 수 있다.</li>
<li>클래스 결합 : 비슷한 클래스를 하나로 결합하거나, 다수 클래스의 몇 개를 합쳐서 클래스의 수를 줄일 수도 있다.</li>
<li>전이학습</li>
<li>데이터 증강</li>
</ul></li>
<li><p>다단계 분류기(multi-class classifier) : 데이터를 둘 이상의 클래스로 분류하는 머신러닝 모델. 일대일/일대다/다중출력분류</p></li>
<li><p>SQL</p></li>
<li><p>유닉스 쉘</p></li>
<li><p>파이썬 코딩 스타일 : PEP 0008 (도움을 주는 pylint)</p></li>
<li><p>정보이론, 엔트로피</p></li>
<li><p>평가지표</p></li>
<li><p>손실함수</p></li>
<li><p>한계효용체감</p></li>
<li><p>Gapminder(http://www.gapminder.org/) :스웨덴의 비영리 통계 분석 서비스. 틈새주의(mind the gap)라는 지하철 경고문에서 영감을 얻은 이름은 세계관과 사실/데이터 간의 간극을 조심하고 좁히자는 이상을 반영</p></li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/통계, 데이터분석/데이터_분석.html</guid>
  <pubDate>Wed, 10 Jan 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>통계 101 X 데이터분석</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/통계, 데이터분석/통계_101_X_데이터_분석.html</link>
  <description><![CDATA[ 





<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/image.png" class="img-fluid"></p>
<section id="통계학이란" class="level1">
<h1>1. 통계학이란?</h1>
<section id="데이터를-분석하다" class="level2">
<h2 class="anchored" data-anchor-id="데이터를-분석하다">1.1 데이터를 분석하다</h2>
<ul>
<li>데이터 분석의 목적</li>
</ul>
<ol type="1">
<li>데이터를 <strong>요약</strong>하는 것</li>
<li>대상을 <strong>설명</strong>하는 것</li>
<li>새로 얻을 데이터를 <strong>예측</strong>하는 것</li>
</ol>
<ul>
<li><p>인과관계 : 2가지 중 하나(원인)을 변화시키면, 다른 하나(결과)도 바꿀 수 있는 관계. 인과관계를 알면 곧 원리(메커니즘)에 관한 지식을 얻는 것이기에 깊은 이해라고 할 수 있다.</p></li>
<li><p>상관관계 : 한쪽이 크면 다른 한쪽도 큰(또는 한쪽이 크면 다른 한쪽은 작은) 관계를 말한다. 한쪽을 ’변화시켰다’하더라도 다른 한쪽이 ’변한다’고 단정할 수 없다는 점에서 인과관계와 다르다. 원리에 관련된 몇 가지 가능성을 구별할 수 없으므로, 얕은 이해라 할 수 있다.</p></li>
<li><p>선형관계에는 사람이 다루기 쉽고, 해석하기도 쉽다는 특징. 한편, 해석이 어려운 복잡한 관계를 추출하고 예측하는 <strong>기계학습</strong>이란 방법도 있다.(12장)</p></li>
</ul>
</section>
<section id="통계학의-역할" class="level2">
<h2 class="anchored" data-anchor-id="통계학의-역할">1.2 통계학의 역할</h2>
<ul>
<li>통계학은 데이터 퍼짐 정도가 클수록 힘을 발휘한다.</li>
<li>데이터 분석에서 통계학의 중요한 역할은, <strong>퍼짐(산포, dispersion)</strong> 이 있는 데이터에 대해 설명이나 예측을 하는 것.</li>
<li>통계학은 이러한 데이터 퍼짐을 ’불확실성’이라 평가하고, 통계학의 목적인 ’대상의 설명과 예측’을 수행</li>
<li>통계학은 데이터 퍼짐이나 불확실성에 대처하는 방법을 제공. 그 근거가 되는 것이 데이터 퍼짐이나 불확실성을 확률로 나타내는 <strong>확률론</strong>이다.</li>
</ul>
</section>
<section id="통계학의-전체-모습" class="level2">
<h2 class="anchored" data-anchor-id="통계학의-전체-모습">1.3 통계학의 전체 모습</h2>
<p><code>-</code> 기술통계와 추론통계</p>
<ul>
<li><p><strong>기술통계(descriptive statistics)</strong> : 수집한 데이터를 정리하고 요약하는 방법. 확보한 데이터에만 집중하면서, 데이터 자체의 성질을 이해하는 것을 목표로 한다는 점에 주의.</p></li>
<li><p><strong>추론통계(inferential statistics)</strong> : 수집한 데이터로부터 데이터의 발생원을 추정하는 방법</p></li>
</ul>
<p><code>-</code> 통계적 추론과 가설검정</p>
<p>추론통계는 크게 2가지가 있다.</p>
<ol type="1">
<li><p>통계적 추론(statistical inference) : 데이터에서 가정한 확률 모형의 성질을 추정하는 방법. 예를 들어, 모서리가 닳아버린 주사위라면 각 눈이 나올 확률이 1/6이 아닐지도 모른다. 이럴 때 통계적 추론을 이용하여, 얻은 데이터로부터 각 눈이 어떤 확률로 나오는 주사위인가를 추정할 수 있다.</p></li>
<li><p>가설검정(statistical test) : 세운 가설과 얻은 데이터가 얼마나 들어맞는지를 평가하여, 가설을 채택할 것인가를 판단하는 방법</p></li>
</ol>
<hr>
</section>
</section>
<section id="모집단과-표본" class="level1">
<h1>2. 모집단과 표본</h1>
<section id="데이터-분석의-목적과-알고자-하는-대상" class="level2">
<h2 class="anchored" data-anchor-id="데이터-분석의-목적과-알고자-하는-대상">2.1 데이터 분석의 목적과 알고자 하는 대상</h2>
<ol type="1">
<li>데이터 분석의 목적을 정하기.</li>
<li>알고자 하는 대상을 명확히 하기.</li>
</ol>
</section>
<section id="모집단" class="level2">
<h2 class="anchored" data-anchor-id="모집단">2.2 모집단</h2>
<ul>
<li>모집단 : 알고자 하는 대상 전체</li>
</ul>
<p>‘지금 알고자 하는 대상은 무엇인지’, ’무엇을 모집단으로 설정할 것인지’의 문제에는 항상 주의를 기울여야 한다.</p>
<ul>
<li>유한모집단</li>
<li>무한모집단</li>
</ul>
</section>
<section id="모집단의-성질을-알다" class="level2">
<h2 class="anchored" data-anchor-id="모집단의-성질을-알다">2.3 모집단의 성질을 알다</h2>
<ul>
<li>모집단은 데이터 분석에서 알고자 하는 대상 전체를 가리키기 때문에, <strong>모집단의 성질</strong>을 알 수 있다면 대상을 설명하거나 이해할 수 있고, 미지의 데이터를 예측할 수도 있게 된다.</li>
<li>모집단의 성질이란, 다음과 같이 모집단에 포함된 요소를 특징 짓는 값이다.</li>
</ul>
<ol type="1">
<li>한국인 남성의 평균 키는 172.5cm이다.</li>
<li>한국인 여성의 평균 키는 159.6cm이다.</li>
<li>신약을 복용한 사람의 최고 혈압 평균은 120mmHg이다.</li>
<li>이 주사위는 모든 눈이 균등하게 나온다.</li>
<li>이 주사위는 6의 눈이 1/4 확률로 나온다.</li>
</ol>
<ul>
<li>그렇다면 이러한 모집단의 성질을 알기 위해서는 어떻게 해야 할까?</li>
</ul>
<p><code>-</code> 전수조사 : 모집단에 포함된 모든 요소를 조사</p>
<ul>
<li><p>모집단에 포함된 요소의 개수가 한정된, 유한모집단일 때 선택할 수 있는 조사 방법.</p></li>
<li><p>전수조사의 경우 ‘분석할 데이터 = 모집단’. 그러므로 획득한 데이터의 특징을 파악하고 기술하기만 해도, 모집단의 성질을 설명하고 이해할 수 있다.</p></li>
<li><p>전수조사의 어려움 : 비용이나 시간 면에서 부담이 막대하여 실현 불가능할 때가 대부분.</p></li>
</ul>
<p><code>-</code> 표본조사 : 모집단의 일부를 분석하여 모집단 전체의 성질을 추정하는 <strong>추론통계(inferential statistics)</strong> 라는 분야가 있으며, 이것이야말로 통계학의 참모습이라 할 수 있다.</p>
<ul>
<li><p>표본(sample) : 추론통계에서 조사하는 모집단의 일부</p></li>
<li><p>표본추출(sampling) : 모집단에서 표본을 뽑는 것</p></li>
<li><p>표본조사 : 표본을 이용해 모집단의 성질을 조사하는 것</p></li>
</ul>
<p>표본을 통해 모집단의 성질을 알 수 있는 잘 알려진 방법으로, 선거 출구조사를 들 수 있다. 일부의 표만으로도 당선확실 여부를 알 수 있다.</p>
<p>추론통계는 ’추론’이라는 말에서 알 수 있듯이 모집단의 성질을 100% 알아맞힐 수는 없으며, 어느 정도 불확실성을 염두에 두고 평가하게 된다.</p>
<ul>
<li><p>대상을 설명(이해)하고 예측하기 위해서는 모집단의 성질을 알아야 한다.</p></li>
<li><p>일반적으로 모집단을 대상으로 한 전수조사는 어렵다.</p></li>
<li><p>표본을 조사하면 모집단의 성질을 추정할 수 있다.</p></li>
<li><p>표본크기 : 표본에 포함된 요소의 개수를 표본크기(sample size)라 부르며, 보통 알파벳 <img src="https://latex.codecogs.com/png.latex?n">으로 나타낸다. 예를 들어 표본으로 30개를 추출했다면, <img src="https://latex.codecogs.com/png.latex?n">=30이라 표기한다.</p></li>
<li><p>통계학에서 샘플 수라고 하면 표본의 개수를 뜻한다. 예를 들어 20명으로 이루어진 표본A와 이와 별개로 30명으로 이루어진 표본B가 있는 경우, 표본은 A, B 2개이므로 샘플 수는 2가 된다. 이처럼 표본크기와 표본의 개수는 혼동하기 쉬우므로 주의.</p></li>
<li><p>표본크기는 모집단의 성질을 추정할 때의 확실성이나 가설검정의 결과에도 영향을 끼치기 때문에, 통계분석에 있어 중요한 요소 중 하나.</p></li>
</ul>
<hr>
</section>
</section>
<section id="통계분석의-기초" class="level1">
<h1>3. 통계분석의 기초</h1>
<section id="데이터-유형" class="level2">
<h2 class="anchored" data-anchor-id="데이터-유형">3.1 데이터 유형</h2>
<p><code>-</code> 모집단과 표본</p>
<p><code>-</code> 변수 : 데이터 중 공통의 측정 방법으로 얻은 같은 성질의 값</p>
<p>예를 들어, 키는 하나의 변수이다. 변수는 각각 다른 값을 취할 수 있으므로 변수라고 불린다.</p>
<p>변수가 여러 개인 경우, 변수 간의 관계를 밝히고자 데이터를 분석할 수 있다.</p>
<p>통계학에서 변수의 개수는 ’차원’이라 표현되기도 한다.</p>
<p>여러 개의 변수를 포함한 데이터는 ’고차원 데이터’라 한다.</p>
<p><code>-</code> 다양한 데이터 유형</p>
<p>변수의 유형마다 분석 방법이 달라지기 때문에, 데이터를 수집할 때나 분석을 실행할 때는 변수가 어떤 유형인지 주의 깊게 고려하는 것이 중요</p>
<ol type="1">
<li>양적 변수 (수치형 변수)</li>
</ol>
<p>수치로 나타낼 수 있는 변수를 양적 변수라 한다. 양적 변수는 다시 이산형과 연속형으로 나눌 수 있다.</p>
<ul>
<li>이산형</li>
</ul>
<p>얻을 수 있는 값이 점점이 있는 변수를 <strong>이산형 양적 변수(이산변수)</strong> 라 한다. ex) 주사위의 눈은 나오는 값이 1부터 6까지의 정수</p>
<ul>
<li>연속형</li>
</ul>
<p>키 173.4cm나 몸무게 65.8kg 같이 간격 없이 이어지는 값으로 나타낼 수 있는 변수를 <strong>연속형 양적 변수 (연속변수)</strong> 라 한다.</p>
<p>이는 정밀도가 높은 측정 방법을 이용하면, 원리상으로는 소수점 아래 몇 자리든 나타낼 수 있다는 점에서 이산형과는 다르다.</p>
<p>이산형과 연속형의 차이점은 확률분포의 종류와 밀접한 관계가 있으므로, 데이터를 다룰 때는 주의</p>
<ol start="2" type="1">
<li>질적 변수 (범주형 변수)</li>
</ol>
<p>숫자가 아닌 범주로 변수를 나타낼 때, 이를 질적 변수 또는 범주형 변수라 한다. ex) 설문조사의 예/아니오, 동전의 앞/뒤</p>
<p>숫자인 양적 변수와 달리, 변수 사이에 대소 관계는 없다.</p>
<p>또한 범주형 변수는 숫자가 아니므로, 평균값 등의 수치 역시 정의할 수 없다.</p>
</section>
<section id="데이터-분포" class="level2">
<h2 class="anchored" data-anchor-id="데이터-분포">3.2 데이터 분포</h2>
<p><code>-</code> 그림으로 데이터 분포 표현하기</p>
<p>’데이터가 어떻게 분포되어 있는지’를 그래프 등으로 시각화하여, 대략적인 데이터 경향을 파악하는 것이 데이터 분석의 첫 단계</p>
<p>데이터 분포를 그림으로 나타내는 데는 어떤 값이 데이터에 몇 개 포함되어 있는가(도수, 빈도, 횟수)를 나타내는 그래프인 <strong>도수분포도(히스토그램)</strong> 를 자주 사용</p>
<p><code>-</code> 히스토그램은 그림으로 나타낸 것일 뿐</p>
<p>히스토그램은 대략적인 데이터 구성을 파악하는 것이 목적이지, 무엇인가 결론을 내기 위한 것이 아니라는 점을 명심</p>
</section>
<section id="통계량" class="level2">
<h2 class="anchored" data-anchor-id="통계량">3.3 통계량</h2>
<p><code>-</code> 데이터 특징 짓기</p>
<p>수집한 데이터로 이런저런 계산을 수행하여 얻은 값을 일반적으로 <strong>통계량</strong> 이라 한다.</p>
<p>데이터 그 자체의 성질을 기술하고 요약하는 통계량을, <strong>기술통계량</strong> 또는 <strong>요약통계량</strong> 이라 부른다.</p>
<ul>
<li>통계량과 정보</li>
</ul>
<p>1개 또는 몇 개의 통계량으로 요약한다는 것은, 데이터에 있는 정보 중 버리는 부분이 있다는 것을 뜻한다. 예를 들어 평균값에는 ’어느 정도 데이터가 퍼져 있는지’의 정보는 포함되지 않습니다. 다른 예로 데이터에 포함된 가장 큰 값인 최댓값도 하나의 통계량이지만 여기에는 데이터 전체의 경향을 알 수 있는 정보가 없다. 이처럼 최댓값은 분포의 중심 위치나 분포 형태에 관한 정보가 주어지지 않으므로, 분포를 파악하는 데는 적합한 통계량이 아니다.</p>
<p><code>-</code> 다양한 기술통계량</p>
<p>대략적인 분포 위치를 나타내는 대푯값 : 평균값, 중앙값, 최빈값</p>
<p>데이터 퍼짐 정도를 나타내는 값 : 분산, 표준편차</p>
<ul>
<li>평균값(mean)</li>
</ul>
<p>표본의 평균값은 표본에서 얻었다는 점에서 ’표본평균’이라고도 한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbar%7Bx%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D(x_1+x_2+...+x_n)%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum%5En_%7Bi=1%7D%20x_i%20"></p>
<p>평균값은 계산 시 모든 값을 고려하기 때문에 이상값의 영향을 받기 쉽다는 특징이 있다.</p>
<ul>
<li>중앙값(median)</li>
</ul>
<p>‘크기 순으로 값을 정렬했을 때 한가운데 위치한 값’</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 홀수라면 가운데 값은 1개이므로 이 값이 중앙값이다. 한편 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 짝수일 때는 가운데에 있는 값이 2개이므로, 두 값의 평균값을 중앙값으로 한다.</p>
<p>중앙값은 수치 자체의 정보가 아닌 순서에만 주목하기에, 극단적으로 크거나 작은 값이 있어도 영향을 받지 않는다는 특징이 있다.</p>
<ul>
<li>최빈값(mode)</li>
</ul>
<p>‘데이터 중 가장 자주 나타나는 값’</p>
<p>처음에 히스토그램을 그려 대략적인 파악을 한 다음, 대푯값으로 적절하게 분포를 특징 지을 수 있는지 확인하는 것이 중요한 데이터 분석 작업 순서라는 점을 꼭 기억</p>
<p><code>-</code> 분산과 표준편차</p>
<p>데이터 퍼짐을 평가하기 위해서는 <strong>분산(variance)</strong> 혹은 <strong>표준편차(standard deviation, S.D.)</strong> 라는 통계량을 계산.</p>
<p>표본에서 구하고, 표본을 평가한다는 점을 강조하여 ’표본분산(sample variance)’이나 ’표본표준편차(sample standard deviation)’라 부르기도 한다.</p>
<p><strong>표본분산</strong> 은 표본의 각 값과 표본평균이 어느 정도 떨어져 있는지를 평가하는 것으로, 데이터 퍼짐 상태를 정량화한 통계량이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20s%5E2%20=%20%5Cfrac%7B1%7D%7Bn%7D%5C%7B(x_1-%5Cbar%7Bx%7D)%5E2%20+%20(x_2-%5Cbar%7Bx%7D)%5E2+...+(x_n-%5Cbar%7Bx%7D)%5E2%5C%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum%5En_%7Bi=1%7D(x_i-%5Cbar%7Bx%7D)%5E2%20"></p>
<ul>
<li>표본분산의 성질</li>
</ul>
<ol type="1">
<li><p><img src="https://latex.codecogs.com/png.latex?s%5E2%20%5Cgeqq%200"></p></li>
<li><p>모든 값이 같다면 0</p></li>
<li><p>데이터 퍼짐 정도가 크면 <img src="https://latex.codecogs.com/png.latex?s%5E2">이 커짐</p></li>
</ol>
<p>표본표준편차 <img src="https://latex.codecogs.com/png.latex?s">는, 이 표본분산의 제곱근을 취한 값이다.</p>
<p>계산상 분산과 표준편차에는 제곱근인지 아닌지의 차이만 있으며, 포함하는 정보에는 차이가 없다. 분산 단위는 원래 값 단위의 제곱이 되지만, 표준편차는 제곱근을 취하므로 원래 단위와 일치한다. 따라서 데이터 퍼짐 정도를 정량화한 지표로는 표준편차 쪽이 감각적으로 더 알기 쉽게 느껴진다.</p>
<p><code>-</code> 분산을 확인할 수 있는 상자 수염 그림</p>
<p>이름처럼 상자와 수염으로 구성되며, 각각은 데이터의 분포를 특징 짓는 통계량을 나타낸다.</p>
<p>제1 사분위수(Q1) : 데이터의 25%가 이 값보다 작거나 같음</p>
<p>제2 사분위수(Q2) : 중앙값</p>
<p>제3 사분위수(Q3) : 데이터의 75%가 이 값보다 작거나 같음</p>
<p>사분위간 범위 : 제1 사분위수와 제3 사분위수 간의 거리(Q3-Q1). 상자로 나타낸 부분.</p>
<p>수염은 상자 길이(사분위간 범위)의 1.5배 길이를 상자로부터 늘인 범위 안에서, 최댓값 또는 최솟값을 가리킨다.</p>
<p>이 범위에 포함되지 않은 값은 이상값으로 정의된다.</p>
<p>상자 수염 그림은 중앙값이나 사분위수, 최댓값, 최솟값 등의 통계량은 나타내는 반면, 히스토그램에서 볼 수 있는 상세한 분포 형태 정보는 포함하지 않는다.</p>
<p><code>-</code> 분포를 시각화하는 다양한 방법</p>
<ul>
<li><p>막대그래프(평균값) + 오차 막대(S.D. or S.E.)</p></li>
<li><p>바이올린 플롯</p></li>
<li><p>스웜 플롯</p></li>
<li><p>상자 수염 그림 + 스웜 플롯</p></li>
</ul>
<section id="p.-3장-나머지-정리-必" class="level3">
<h3 class="anchored" data-anchor-id="p.-3장-나머지-정리-必">~ 67p. 3장 나머지 정리 必</h3>
<hr>
</section>
</section>
</section>
<section id="추론통계-신뢰구간" class="level1 page-columns page-full">
<h1>4. 추론통계 ~ 신뢰구간</h1>
<ul>
<li>데이터로 모집단의 성질을 추정한다.</li>
</ul>
<section id="추론통계를-배우기-전에" class="level2">
<h2 class="anchored" data-anchor-id="추론통계를-배우기-전에">4.1 추론통계를 배우기 전에</h2>
<p><code>-</code> 전수조사와 표본조사</p>
<p>전수조사 : 모집단의 모든 요소를 조사</p>
<p>표본조사 : 모집단의 일부인 표본으로 모집단의 성질을 추정</p>
<p><code>-</code> 데이터를 얻는다는 것</p>
<p>” 데이터(표본)를 얻는다는 것은 무엇인가? ” : 모집단에 포함된 전체 값으로 구성된 분포에서 일부를 추출하는 것</p>
<p>모집단분포를 특징 짓는 양을 <strong>모수</strong> 또는 <strong>파라미터</strong> 라 부른다</p>
<p>확률분포와 실현값의 관계는 모집단과 표본의 관계와 매우 비슷</p>
<p>‘모집단 = 확률분포, 표본 = 확률분포를 따르는 실현값’ 이라고 생각하자</p>
<p>” 얻은 실현값으로 이 값을 발생시킨 확률분포를 추정한다 ” 라는 목표로 바꾸어 말할 수 있다.</p>
<ul>
<li>모집단분포 모형화</li>
</ul>
<p>ex) 성인 남성 키의 분포는 정규분포와 매우 비슷하지만, 엄밀한 의미에서 정규분포가 되는 일은 있을 수 없다.</p>
<p>그러나 있는 그대로를 바로 수학적으로 다룰 수 없을 때가 잦기 때문에, 3장에서 배운 것과 같은 <strong>수식</strong> 으로 기술하게 된다.</p>
<p>그러면 수학적으로 다룰 수 있는 확률분포(모형)에 근사하여 작업을 진행할 수 있게 되어, 모집단의 추정이 용이해진다.</p>
<p>수학적인 확률분포로 모집단 분포를 근사하는 것을 여기서는 <strong>모형화(modeling)</strong> 라 부르도록 하자</p>
<p>예를 들어 정규분포로 근사할 수 있다면, 평균과 표준편차 같은 2가지 파라미터만으로 분포를 기술할 수 있으며, 다룰 수도 있게된다.</p>
<p>이 장 후반에 등장하는 t분포는, 이와 같이 모집단이 정규분포라는 가정하에 이용할 수 있는 분포이다.</p>
<ul>
<li>무작위추출</li>
</ul>
<p>모집단에서 표본을 얻을 때 중요한 것이 <strong>무작위추출(random sampling)</strong> 이다.</p>
<p>데이터를 얻을 때 모집단에 포함된 요소를 무작위로 선택하여 추출하는 방식</p>
<p>독립적이지 않은 선택방식도 적절하지 않다.</p>
<ul>
<li>무작위추출 방법</li>
</ul>
<p>이상적인 무작위추출 방법은 표본에 있을 수 있는 모든 요소를 목록으로 만들고, 난수를 이용하여 표본을 정하는 것. 이를 <strong>단순무작위추출법</strong> 이라 한다.</p>
<p>실제로 자주 사용하는 방법은 <strong>층화추출법</strong> 이다. 이는 모집단을 몇개의 층(집단)으로 미리 나눈 뒤, 각 층에서 필요한 수의 조사대상을 무작위로 추출하는 방법이다.</p>
<p>그 밖에도 계통추출법, 군집추출법 등 다양한 방법이 있다.</p>
<ul>
<li>편향된 추출로는 올바른 추정이 어려움</li>
</ul>
</section>
<section id="표본오차와-신뢰구간" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="표본오차와-신뢰구간">4.2 표본오차와 신뢰구간</h2>
<p>모집단의 평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">나 <img src="https://latex.codecogs.com/png.latex?%5Csigma"> 등은 고정된 값이지만, 모집단분포에서 얻은 표본 <img src="https://latex.codecogs.com/png.latex?x_1,%20x_2,%20...%20x_n">은 확률적으로 변하는 확률변수라는 사실을 염두에 둘 것</p>
<p><code>확률변수의 정확한 의미는?</code></p>
<p>일반적으로 표본평균은 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">와 일치하지 않는다. 즉 ’정말로 알고 싶은 것’과 ’실제로 손 안에 있는 데이터’에는 어긋남(오차)가 생기는 것. 이런 오차를 <strong>표본오차(표집오차, sampling error)</strong> 라고 한다.</p>
<p>표본오차는 표본을 추출할 때의 인위적인 실수나 잘못으로 생기는 오차가 아니라, 데이터 퍼짐이 있는 모집단에서 확률적으로 무작위 표본을 고르는 데서 발생하는, 피할 수 없는 오차라는 점에 주의</p>
<ul>
<li>큰 수의 법칙</li>
</ul>
<p>표본평균과 모집단평균의 관계에는 <strong>큰 수의 법칙(law of large numbers)</strong> 이 성립한다.</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">가 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">에 한없이 가까워진다는 법칙.</p>
<p>다시 말해 표본오차 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">가 <img src="https://latex.codecogs.com/png.latex?0">에 한없이 가까워진다는 뜻이기도 하다.</p>
<p><code>-</code> 표본오차의 확률분포</p>
<p>표본오차의 확률분포를 알면 어느 정도 크기의 오차가, 어느 정도의 확률로 나타나는지를 알 수 있게 된다.</p>
<ul>
<li>중심극한정리</li>
</ul>
<p>표본오차의 분포에 관해 중요한 정보를 제공하는 것이 <strong>중심극한정리(central limit theorem)</strong> 이다.</p>
<p>모집단이 어떤 분포이든 간에, 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">의 분포는 정규분포로 근사할 수 있다는 것을 의미</p>
<p>’표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">의 분포? : 표본크기 <img src="https://latex.codecogs.com/png.latex?n">으로 표본을 추출하고 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">를 계산하는 작업을 몇 번이고 반복해서, 표본평균을 한데 모아 히스토그램을 그린다는 것.</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 표본평균의 분포는 다음과 같은 정규분포로 근사할 수 있다.</p>
<p>평균 : 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu"></p>
<p>표준편차 : <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D"></p>
<blockquote class="blockquote">
<p>Chat GPT : 중심극한정리와 대수의 법칙의 차이점이 뭐야?</p>
</blockquote>
<ol type="1">
<li>중심극한정리 (Central Limit Theorem):</li>
</ol>
<p>중심극한정리는 확률론의 기본 개념 중 하나로, 독립적인 확률 변수들의 합 또는 평균이 정규분포에 근사하는 현상을 설명합니다. 중심극한정리는 다음과 같은 특징을 가집니다:</p>
<p>독립적인 확률 변수들의 합 또는 평균은 표본 크기가 충분히 크면 정규분포에 근사한다.</p>
<p>중심극한정리는 모집단의 분포에 상관 없이 적용될 수 있으며, 모집단이 어떤 분포를 따르더라도 표본 평균의 분포는 정규분포에 가까워진다.</p>
<ol start="2" type="1">
<li>대수의 법칙 (Law of Large Numbers):</li>
</ol>
<p>대수의 법칙은 표본 크기가 커질수록 표본 평균이 모집단의 평균에 가까워진다는 원리를 설명합니다. 대수의 법칙은 다음과 같은 특징을 가집니다:</p>
<p>대수의 법칙은 표본 크기가 커질수록 표본 평균이 모집단 평균에 수렴한다.</p>
<p>대수의 법칙은 표본 크기가 충분히 크다면 모집단의 분포에 상관 없이 적용될 수 있으며, 모집단이 어떤 분포를 따르더라도 표본 평균은 모집단 평균에 가까워진다.</p>
<p>차이점:</p>
<p>중심극한정리는 확률 변수들의 합 또는 평균의 분포에 대한 이론을 다루는 것이며, 주로 정규분포와 관련이 있습니다.</p>
<p>대수의 법칙은 표본 크기가 커질 때 표본 평균이 모집단 평균으로 수렴하는 원리를 설명하며, 분포에 대한 특별한 가정이 필요하지 않습니다. 이는 큰 표본 크기를 가지고 있는 경우에는 표본의 평균이 모집단 평균과 거의 같아질 것이라는 것을 의미합니다.</p>
<p>중심극한정리와 대수의 법칙은 통계 분석과 데이터 분석에서 중요한 개념으로 사용되며, 표본 크기와 확률 분포에 대한 이해를 높이는 데 도움을 줍니다.</p>
<ul>
<li>추정량</li>
</ul>
<p>모집단의 성질을 추정하는 데 사용하는 통계량을 <strong>추정량</strong> 이라 한다.</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">을 무한대로 했을 때, 모집단의 성질과 일치하는 추정량을 <strong>일치추정량</strong> 이라 하고, 추정량의 평균값(기댓값)이 모집단의 성질과 일치할 때의 추정량은 <strong>비편향추정량</strong> 이라 한다.</p>
<p>비편향추정량은 매번 얻을 때마다 확률적으로 다른 값이 되지만, 평균으로 보면 모집단의 성질을 과대하지도 과소하지도 않게 나타내는 양을 뜻한다.</p>
<p>모집단의 성질을 추정할 때 편향된 추정은 바람직하지 않다. 그러므로 비편향추정량은 바람직한 추정량이다.</p>
<p><code>비편향추정량, 일치추정량 ??</code></p>
<p>추정량 하나하나는 모집단의 성질(여기서는 <img src="https://latex.codecogs.com/png.latex?%5Cmu">)에서 벗어나지만, 이를 모아 구한 평균값이 <img src="https://latex.codecogs.com/png.latex?%5Cmu">와 일치하는 경우 이를 비편향추정량이라 부른다.</p>
<p>중심극한정리에서 본 것 처럼 표본평균의 분포의 평균은 모집단의 성질인 <img src="https://latex.codecogs.com/png.latex?%5Cmu">와 일치하므로, 표본평균은 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">를 편향되지 않게 추정하는 비편향추정량이다.</p>
<p>한편 표본표준편차 <img src="https://latex.codecogs.com/png.latex?s">(또는 표본분산 <img src="https://latex.codecogs.com/png.latex?s%5E2">)는 사정이 조금 다르다.</p>
<p>표본표준편차 <img src="https://latex.codecogs.com/png.latex?s">의 정의에서 루트 안의 분모는 <img src="https://latex.codecogs.com/png.latex?n">이었다. 기술통계에서 데이터 퍼짐 정도를 평가할 때는 문제가 없지만, 모집단의 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">를 과소평가한다는 문제가 있다.</p>
<p>올바르게는 <img src="https://latex.codecogs.com/png.latex?n-1">로 나눈 다음 식이, 모집단 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">의 비편향추정량이 된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?s%20=%20%5Csqrt%7Bs%5E2%7D%20=%20%5Csqrt%7B%5Cfrac%7B1%7D%7Bn-1%7D%5Csum%5En_%7Bi=1%7D(x_i-%5Cbar%7Bx%7D)%5E2%7D"></p>
<blockquote class="blockquote">
<p><img src="https://latex.codecogs.com/png.latex?n">으로 나누면 왜 과소평가가 되는가?</p>
</blockquote>
<p>각 값 <img src="https://latex.codecogs.com/png.latex?x_i">와 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">의 차이를 제곱하여 값이 얼마나 퍼졌는지를 측정하지만 원래 <img src="https://latex.codecogs.com/png.latex?(x_i-%5Cmu)%5E2">로 계산해야 하는 것을 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 미지수이므로 <img src="https://latex.codecogs.com/png.latex?(x_i-%5Cbar%7Bx%7D)%5E2">로 바꾼 것이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">는 <img src="https://latex.codecogs.com/png.latex?%5Cmu">와 일치하지 않으며, 각 값 <img src="https://latex.codecogs.com/png.latex?x_i">와 <img src="https://latex.codecogs.com/png.latex?%5Cmu">의 위치 관계 또는 각 값 <img src="https://latex.codecogs.com/png.latex?x_i">와 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">의 위치 관계를 생각하면 <img src="https://latex.codecogs.com/png.latex?x_i">는 <img src="https://latex.codecogs.com/png.latex?%5Cmu">보다도 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">에 가까이 있을 것이다.</p>
<p>그러므로 <img src="https://latex.codecogs.com/png.latex?(x_i-%5Cbar%7Bx%7D)%5E2">의 합은 <img src="https://latex.codecogs.com/png.latex?(x_i-%5Cmu)%5E2">보다도 작은 값이 된다.</p>
<p>따라서 <img src="https://latex.codecogs.com/png.latex?n">으로 나누지 않고 <img src="https://latex.codecogs.com/png.latex?n-1">로 나누어 과소평가를 보정하는 것</p>
<ul>
<li>표본오차의 분포</li>
</ul>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 표본오차 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">의 분포는 다음 정규분포로 근사할 수 있다.</p>
<p>평균 : 0</p>
<p>표준편차 : <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D"></p>
<p>표본오차 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">의 분포는 모집단의 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">와 표본크기 <img src="https://latex.codecogs.com/png.latex?n"> 등 2개의 값만 정해지면 알 수 있다는 것. 이 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D">을 <strong>표준오차(standard error)</strong> 라 한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma">는 모집단의 성질이므로 보통 우리로선 알 수 없는 미지의 숫자이다. 그러므로 앞서 살펴본 표본에서 추정한 비편향표준편차 <img src="https://latex.codecogs.com/png.latex?s">를 <img src="https://latex.codecogs.com/png.latex?%5Csigma"> 대신 사용한 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">를 표준오차로 삼는다.</p>
<p>이때 표본오차(단 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">으로 나눔)는 정규분포가 아니라 정규분포와 매우 닮은 t분포를 따르게 된다.</p>
<p><code>-</code> 신뢰구간이란?</p>
<p>표본오차의 확률분포는 얼마나 큰 오차가 어느 정도의 확률로 나타나는가를 알 수 있다.</p>
<p>간단하게 오차를 정량화하기 위해서, <strong>신뢰구간(confidence interval)</strong> 이라는 개념을 도입</p>
<blockquote class="blockquote">
<p>정규분포의 성질에서 <img src="https://latex.codecogs.com/png.latex?%ED%8F%89%EA%B7%A0%EA%B0%92%20%5Cpm"> 2 <img src="https://latex.codecogs.com/png.latex?%5Ctimes%20%ED%91%9C%EC%A4%80%ED%8E%B8%EC%B0%A8"> 범위에 약 95%의 값을 포함하고 있었다. 즉, 정규분포에서 하나의 값을 무작위로 꺼내면 95%의 확률로 그 범위에 포함된다는 뜻</p>
</blockquote>
<p>이 개념을 그대로 표본오차의 정규분포에 적용해보면</p>
<p>표본오차의 약 95%는 <img src="https://latex.codecogs.com/png.latex?0-2%5Ctimes%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D%20%5Cleq%20%5Cbar%7Bx%7D%20-%20%5Cmu%20%5Cleq%200%20+%202%20%5Ctimes%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?%5Cmu"> 를 알고 싶기 때문에 이항하고 음수를 곱하면 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D%20-%202%20%5Ctimes%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D%20%5Cleq%20%5Cmu%20%5Cleq%20%5Cbar%7Bx%7D%20+%202%20%5Ctimes%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D"></p>
<ul>
<li>신뢰구간의 해석</li>
</ul>
<p>OO% 신뢰구간을 해석하면 “OO%의 확률로 이 구간에 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 있다.” 가 된다.</p>
<p>단, 확률변수는 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 아니라 표본평균 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D">(또는 신뢰구간)이다.</p>
<blockquote class="blockquote">
<p>즉 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 확률적으로 변화하여 그 구간에 포함되는 것이 아니라, 모집단에서 표본을 추출하여 OO% 신뢰구간을 구하는 작업을 100번 반복했을 때 평균적으로 그 구간에 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 포함되는 것이 OO번이란 뜻.</p>
</blockquote>
<p>하나의 표본에서 얻은 신뢰구간은 <img src="https://latex.codecogs.com/png.latex?%5Cmu">를 포함하거나 포함하지 않거나 둘 중 하나이다.</p>
<p>신뢰구간은 표본에서 구한 모집단 <img src="https://latex.codecogs.com/png.latex?%5Cmu">의 추정값을 어느 정도 신뢰할 수 있는지를 나타낸다고 할 수 있다.</p>
<p>신뢰구간이 좁다면 추정값 가까이에 <img src="https://latex.codecogs.com/png.latex?%5Cmu">가 있다고 생각할 수 있으므로, 추정값은 신뢰할 수 있는 값이다. 반대로 신뢰구간이 넓다면 추정값과 모집단평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu">사이의 오차는 커지는 경향이 있으므로 신뢰도는 낮다.</p>
<p>OO% 신뢰구간에서 ’OO%’에는 일반적으로 95%를 사용한다. 이 숫자는 과학계에서 관례로 사용되어 온 것으로, 필연성은 없다.</p>
<p>가설검정에서 유의수준 5%는 95% 신뢰구간과 동전의 양면과 같은 관계이다.</p>
<p>95% 신뢰구간이란 평균적으로 20번 중 1번 정도 벗어난다는, 달리 말하면 20번 중 19번은 구간에 모집단평균을 포함한다는 뜻이다.</p>
<p><code>-</code> t분포와 95% 신뢰구간</p>
<p>정규분포의 성질을 “<img src="https://latex.codecogs.com/png.latex?%ED%8F%89%EA%B7%A0%EA%B0%92%5Cpm%202%5Ctimes%20%ED%91%9C%EC%A4%80%ED%8E%B8%EC%B0%A8">”안에 95%라고 대략적으로 말해왔지만 정확하게는 “<img src="https://latex.codecogs.com/png.latex?%ED%8F%89%EA%B7%A0%EA%B0%92%5Cpm%201.96%5Ctimes%20%ED%91%9C%EC%A4%80%ED%8E%B8%EC%B0%A8">”의 범위가 95%가 된다.</p>
<p>문제가 되는 것은 중심극한정리는 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커질수록 근사적으로 성립하기에 실제 데이터 분석에서 볼 수 있는 작은 표본크기의 경우 표본오차가 정규분포를 따른다고 말할 수 없다는 것과 모집단의 <img src="https://latex.codecogs.com/png.latex?%5Csigma"> 대신 <img src="https://latex.codecogs.com/png.latex?s">를 써야만 한다는 것.</p>
<p>이때 활약하는 것이 <strong><img src="https://latex.codecogs.com/png.latex?t">분포</strong></p>
<p><strong><img src="https://latex.codecogs.com/png.latex?t">분포</strong>는 모집단이 정규분포라는 가정하에 미지의 모집단 표준편차 <img src="https://latex.codecogs.com/png.latex?%5Csigma">를 표본으로 계산한 비편향표준편차 <img src="https://latex.codecogs.com/png.latex?s">로 대용했을 때, <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">를 표준오차 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">로 나누어 표준화한 값이 따르는 분포이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cbar%7Bx%7D-%5Cmu%7D%7B%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D%7D"></p>
<p>이 값은 표준오차 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">를 단위로 표본오차 <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D-%5Cmu">가 몇 개분인지를 나타낸다.(3장의 표준화와 마찬가지)</p>
<p>복잡하다고 느낄 수도 있겠으나, <img src="https://latex.codecogs.com/png.latex?t">분포 자체는 정규분포와 매우 비슷한 형태이며 표본크기 <img src="https://latex.codecogs.com/png.latex?n">에 따라 모양이 조금 달라질 뿐, 신뢰구간을 구하는 논리는 그대로이다.</p>
<p>95%라는 엄밀한 값을 얻고자 미세 조정하는 것으로 생각하면 된다.</p>
<p>아울러 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 커짐에 따라, <img src="https://latex.codecogs.com/png.latex?t">분포는 정규분포에 가까워진다.</p>
<p><img src="https://latex.codecogs.com/png.latex?t">분포에서 표본크기 <img src="https://latex.codecogs.com/png.latex?n=10">인 경우에는 평균 0, 표준편차 1인 정규분포보다 조금 넓어져 하위 2.5%, 상위 2.5%인 지점이 -2.26과 +2.26이 된다 (정규분포는 -1.96, +1.96)</p>
<p>그러므로 신뢰구간을 구하는 식에서는 <img src="https://latex.codecogs.com/png.latex?%5Cpm%202">나 <img src="https://latex.codecogs.com/png.latex?%5Cpm%201.96">이 아닌 <img src="https://latex.codecogs.com/png.latex?%5Cpm%202.26">을 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D">에 곱해 계산한다.</p>
<ul>
<li>정밀도를 높이려면</li>
</ul>
<p>보다 신뢰 가능한 평균값을 추정하고 싶을 때는 어떻게 할까?</p>
<p>오차분포의 너비를 나타내는 <strong>표준오차 </strong>에 주목해보면 이를 작게 만들기 위해서는 분자인 비편향표준편차 <img src="https://latex.codecogs.com/png.latex?s">를 작게 하거나, 분모인 표본크기 <img src="https://latex.codecogs.com/png.latex?n">을 크게 하는 두 가지 방법이 있다.</p>
<p><img src="https://latex.codecogs.com/png.latex?s">(또는 <img src="https://latex.codecogs.com/png.latex?%5Csigma">)는 모집단 데이터 퍼짐이라는 모집단 그 자체의 성질에서 유래하기에 작게 만들기 어렵지만, 측정한 데이터 퍼짐(변동) 정도를 줄일 수는 있다. 데이터 퍼짐이 증가하면 결과적으로 <img src="https://latex.codecogs.com/png.latex?s">(또는 <img src="https://latex.codecogs.com/png.latex?%5Csigma">)가 커지기 때문에, 측정을 한층 정밀하게 실시하는 식으로 대처 가능한 경우도 있다.</p>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">에 관해서는, <img src="https://latex.codecogs.com/png.latex?n">을 크게 만듦으로써 더 높은 정밀도로 추정할 수 있다.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?t">분포를 사용할 때 주의할 점</li>
</ul>
<p>표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 작아도 적용 가능한 %t$분포에는 ’정규분포에서 얻은 데이터’라는 가정이 필요하다. 즉, <img src="https://latex.codecogs.com/png.latex?t">분포는 데이터 <img src="https://latex.codecogs.com/png.latex?x_1,%20x_2,%20...%20,%20x_n">을 정규분포라는 모형에서 얻었을 때의 (표준화된) 표본오차가 따르는 분포이다. 데이터의 배경에 잇는 모집단분포가 완벽한 정규분포일 수는 없으므로, 얻은 95% 신뢰구간은 정확한 95%가 아니라는 점에 주의.</p>
<p>특히 문제가 되는 것은 정규분포와 현저하게 다른 분포에서 데이터를 얻었을 때이다. 이 경우 95% 신뢰구간을 구해도 95%에서 벗어날 수 있어 주의해야 한다.</p>
<p>단, 표본크기 <img src="https://latex.codecogs.com/png.latex?n">이 클 때는 중심극한정리에 따라 모집단이 정규분포가 아니더라도 표본평균을 정규분포로 근사할 수 있으므로 신뢰구간은 정확해진다.</p>
<hr>
<p>p.151 ~</p>
<ul>
<li><p>모수검정 : 모집단이 특정분포를 따른다는 가정을 둔 가설검정</p>
<ul>
<li><p>정규분포로부터 얻어졌다고 간주할 수 있는 성질 (정규성 normality를 가졌다.)</p></li>
<li><p>반대는 특정분포로 가정을 못하는 경우가 있다. ex) 좌우 비대칭 분포, 이상값이 있는 분포라면 평균이나 표준편차는 도움이 되지 않음, 모수검정 이용이 적절하지 않다. 그 대신 평균, 표준펴나 등의 파라미터에 기반을 두지 않는 ’비모수 검정’으로 분류되는 방법을 이용</p></li>
</ul></li>
<li><p>정규성 조사 (귀무가설에 정규성 가정)</p>
<p>모수검정에서는 각 집단의 데이터에 정규성이 있어야한다.</p>
<ul>
<li><p>정규성 조사법 :</p>
<ul>
<li>Q-Q플롯(분위수-분위수 그림)</li>
<li>샤피로-윌크 검정 (가설검정으로 조사)</li>
<li>콜모고로프-스미르노프 (K-S) 검정</li>
</ul></li>
</ul></li>
<li><p>등분산성 조사 (귀무가설에 등분산 가정)</p>
<p>t검정, 분산분석 =&gt; 분산이 같은 모집단으로부터 획득되었다는 가정이 필요</p>
<ul>
<li>등분산성 조사법 :
<ul>
<li>바틀렛 검정</li>
<li>레빈 검정</li>
</ul></li>
</ul></li>
<li><p>데이터에 정규성이 없는 경우? → 비모수검정 (평균값 대신 분포의 위치를 나타내는 대푯값에 주목하여 해석)</p>
<ul>
<li><strong>윌콕슨 순위합 검정</strong>(wil-coxon rank sum test) : 평균값 대신 각 데이터 값의 순위에 기반하여 검정</li>
<li>맨-휘트니 U 검정
<ul>
<li>비교할 2개 집단의 분포 모양 자체가 같아야함</li>
</ul></li>
<li>플리그너-폴리셀로 검정</li>
<li>브루너-문첼 검정</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>여기까지는 2개 표본 비교</p>
</blockquote>
<ul>
<li>분산분석(ANOVA, Analysis of variance) : 3개 집단 이상의 평균값 비교
<ul>
<li>귀무가설 : 모든 집단의 평균이 같다 (<img src="https://latex.codecogs.com/png.latex?%5Cmu_A%20=%20%5Cmu_B%20=%20%5Cmu_C">)</li>
<li>대립가설 : 적어도 한 쌍에는 차이가 있다.</li>
</ul></li>
<li>F값 = (평균적인 집단간 변동) / (평균적인 집단 내 변동)
<ul>
<li>집단 내 변동 = 오차에 따른 변동</li>
<li>집단 간 변동 = 효과에 따른 변동</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/통계_101_X_데이터_분석_files/figure-html/cell-82-1-image.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">image.png</figcaption>
</figure>
</div>
<ul>
<li><p>자유도(degree of freedom) : 자유로이 움직일 수 있는 변수의 수</p>
<p>ex) 표본크기가 n=10인 표본이라면 자유도는 10이지만 표본평균을 계산한 이후의 자유도는 9가 된다.</p>
<p>표본평균이 확정되었기에 9개의 데이터가 정해지면 남은 1개의 값을 확정할 수 있기 때문</p></li>
<li><p>일표본 t검정 (가정) vs 이표본 t검정</p></li>
<li><p>정규분포 ㅡ t분포 ㅡ t검정 관계</p></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/통계, 데이터분석/통계_101_X_데이터_분석.html</guid>
  <pubDate>Wed, 13 Sep 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>[확률론] 1. Probability and counting</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting.html</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-1-1-image.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Introduction to Probability Second Edition</figcaption>
</figure>
</div>
<section id="probability-and-counting" class="level1 page-columns page-full">
<h1>1.Probability and counting</h1>
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-3-1-image.png" class="img-fluid"></p>
<section id="why-study-probability" class="level2">
<h2 class="anchored" data-anchor-id="why-study-probability">1.1 Why study probability?</h2>
<p>수학은 확실성의 논리이며 확률은 불확실성의 논리이다.</p>
<p>list of applications:</p>
<ul>
<li><p>statistics : 확률은 통계를 위한 기초이자 언어이다. 데이터를 사용하여 세상에 대해 배울 수 있는 다양한 강력한 방법을 가능하게 한다.</p></li>
<li><p>computer science: Randomized algorithms은 실행되는 동안 무작위 선택을 하며, 많은 중요한 응용 분야에서 현재 알려진 결정론적 대안(deterministic alternatives)보다 더 간단하고 효율적이다. 확률은 또한 알고리즘의 성능을 연구하는 데 필수적인 역할을 하며, 머신러닝, 인공지능에서 중요한 역할을 한다.</p></li>
<li><p>Life: 인생은 불확실하고 확률은 불확실성의 논리이다. 인생에서 결정되는 모든 결정에 대해 공식적인 확률 계산을 수행하는 것은 실용적이지 않지만, 확률에 대해 열심히 생각하는 것은 우리가 몇 가지 흔한 오류를 피하고, 우연을 조명하고, 더 나은 예측을 하는 데 도움이 될 수 있다.</p></li>
<li><p>Physics, Biology, Meteorology, Gambling, Finance, Political science, Medicine….</p></li>
</ul>
</section>
<section id="sample-spaces-and-pebble-world" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sample-spaces-and-pebble-world">1.2 Sample spaces and Pebble World</h2>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-7-1-image.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Figure 1.1</figcaption>
</figure>
</div>
<ul>
<li><p>sample space S: 실험의 모든 가능한 경우의 집합</p></li>
<li><p>event A: sample space S의 부분 집합</p></li>
<li><p>표본 공간은 finite, countably infinite, uncountably infinite 할 수 있다. 표본공간이 finite(유한)할 때, 우리는 Pebble World로 시각화 할 수 있으며 Figure 1.1과 같이 나타낼 수 있다. 각각의 pebble은 결과를 나타내며 event는 pebbles의 집합이다.</p></li>
<li><p>만약 모든 pebble이 같은 질량을 가지면 pebble은 동일한 확률로 선택되어진다. 이러한 특별한 경우가 다음 두 Section에서 다뤄지며 Section 1.6에서는 질량이 다른 경우에 대해 다룬다.</p></li>
<li><p>집합 이론은 확률에서 매우 유용하다(각 사건을 표현). 이러한 방식은 사건을 한 가지 이상의 방법으로 표현 가능하게 해준다. 어떠한 한 가지 표현은 다른 표현보다 더 쉽다.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-9-1-image.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">ex) De Morgan’s laws</figcaption>
</figure>
</div>
</section>
<section id="naive-definition-of-probability" class="level2">
<h2 class="anchored" data-anchor-id="naive-definition-of-probability">1.3 Naive definition of probability</h2>
<p><strong>Naive definition of probability</strong></p>
<ul>
<li>A를 사건이라 하고 S를 유한한 표본공간이라 하자. 이때 The naive probability of A는</li>
</ul>
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-12-1-image.png" class="img-fluid"></p>
<p>예시로, Figure 1.1의 상황에서</p>
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-14-1-image.png" class="img-fluid"></p>
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-15-1-image.png" class="img-fluid"></p>
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-16-1-image.png" class="img-fluid"></p>
<ul>
<li><p>The naive definition은 매우 제한적. S가 유한해야하며 각각의 pebble들의 질량이 동일해야 한다. 이것은 종종 잘못 적용되는데, justification 없이 그것이 50:50이라고 주장하는 것(예를 들어, 화성에 지적 생명체가 산다를 50:50이라고 함.)</p></li>
<li><p>The naive difinition이 적용 가능한 중요한 케이스들이 존재한다.</p>
<ol type="1">
<li><p>문제에 symmetry(대칭)이 있는 경우 등확률이다. ex) 동전이 50% 확률로 앞면이 나올 수 있다. -&gt; 동전이 물리적으로 symmetry.</p></li>
<li><p>설계에 의한 등확률. ex) N명의 인구 중 설문조사를 위해 n명의 사람을 랜덤하게 뽑는 경우. 성공한다면 나이브한 정의를 적용가능하지만, 다양한 문제로 인해 달성이 어려울 수 있다.</p></li>
<li><p>영가설에서의 모형</p></li>
</ol></li>
</ul>
</section>
<section id="how-to-count" class="level2">
<h2 class="anchored" data-anchor-id="how-to-count">1.4 How to count</h2>
<p><strong>Multiplication rule</strong></p>
<ul>
<li>2개의 하위 실험 A, B로 구성된 복합실험을 생각해보자. 실험 A는 a개 가능한 경우의 수가 있고 실험 B는 b개의 가능한 경우의 수가 있다. 이런 경우 복합 실험은 a*b의 가능한 경우를 갖는다.</li>
</ul>
<p><img src="https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting_files/figure-html/cell-21-1-image.png" class="img-fluid"></p>
<p>※ 실험이 시간순서로 진행된다고 생각하기 쉬우나 A가 B보다 먼저 실행된다는 요건은 없다. <code>주어진 내용이 없으면 순차적으로 실행된다고 생각하지 말 것?</code></p>


</section>
</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/통계, 데이터분석/1_probability_and_counting.html</guid>
  <pubDate>Wed, 23 Aug 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>2023.08.28 블로그 구축</title>
  <dc:creator>고경수 </dc:creator>
  <link>https://star77sa.github.io/posts/etc/2023-08-28-블로그.html</link>
  <description><![CDATA[ 





<p>깃허브를 이용한 블로그, 네이버 블로그 등 다양한 블로그를 사용해보다가 fastpage 블로그에 정착을 했었습니다.</p>
<p>주피터노트북 파일을 만들면 그대로 포스팅을 해주어서 용이하였기 때문이었는데,</p>
<p>해당 블로그의 서비스가 종료되고 Quarto 사용을 권장한다고 하였으나 블로그 개설이 복잡한 것 같아 티스토리를 한동안 사용해보았습니다. 다만 역시 코드 기록이 불편하여 Quarto 블로그를 제작하여 이 블로그로 옮기게 되었습니다.</p>
<p>다른 블로그들의 포스팅은 복습하는 겸 조금씩 옮길 예정입니다.</p>
<section id="블로그-제작-quarto" class="level3">
<h3 class="anchored" data-anchor-id="블로그-제작-quarto">블로그 제작 (Quarto)</h3>
<ul>
<li><a href="https://quarto.org/docs/websites/website-blog.html">Quarto</a></li>
<li><a href="https://www.youtube.com/watch?v=YoKjBcuUP0s&amp;ab_channel=Crump%27sComputationalCognitionLab">참고영상</a></li>
</ul>
<hr>
<ul>
<li><a href="https://icons.getbootstrap.com/">설정가능 icon</a></li>
</ul>
</section>
<section id="rss-피드" class="level3">
<h3 class="anchored" data-anchor-id="rss-피드">RSS 피드</h3>
<ul>
<li><a href="https://quarto.org/docs/websites/website-listings.html#feeds">quarto feed</a></li>
<li><a href="https://pypi.org/project/feedparser/">feed parser</a></li>
<li><a href="https://www.tutorialspoint.com/python/time_strptime.htm">날짜 포맷</a></li>
</ul>
</section>
<section id="블로그-검색엔진-등록" class="level3">
<h3 class="anchored" data-anchor-id="블로그-검색엔진-등록">블로그 검색엔진 등록</h3>
<ul>
<li><a href="https://1-woori.tistory.com/entry/%EB%82%B4-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84%EC%97%90-%EB%93%B1%EB%A1%9D%ED%95%98%EA%B8%B0-%EB%8B%A4%EC%9D%8C-%EB%84%A4%EC%9D%B4%EB%B2%84-%EA%B5%AC%EA%B8%80-%EB%B9%99-%EC%A4%8C">검색엔진 등록</a></li>
</ul>
</section>
<section id="jupyter-notebook" class="level3">
<h3 class="anchored" data-anchor-id="jupyter-notebook">Jupyter Notebook</h3>
<ul>
<li>노트북의 첫 번째 셀은 문서제목, 작성자 및 지정해야하는 기타 옵션이 포함된 <strong>RAW Cell</strong>이어야 한다. <a href="https://quarto.org/docs/tools/jupyter-lab.html">https://quarto.org/docs/tools/jupyter-lab.html</a></li>
</ul>


</section>

 ]]></description>
  <guid>https://star77sa.github.io/posts/etc/2023-08-28-블로그.html</guid>
  <pubDate>Tue, 31 Dec 2019 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
